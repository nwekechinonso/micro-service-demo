{
  "version": 4,
  "terraform_version": "1.9.5",
  "serial": 30,
  "lineage": "e090ad72-3579-b29f-33ec-1d05997abd20",
  "outputs": {
    "kube_config": {
      "value": "",
      "type": "string",
      "sensitive": true
    },
    "sp_credentials": {
      "value": {
        "app_id": "f81aa1f5-6513-46be-8a5e-4b8c9958e30c",
        "password": "S%FUY*ZgVlfzo6OJt6s{obd-Tp7@-sx_"
      },
      "type": [
        "object",
        {
          "app_id": "string",
          "password": "string"
        }
      ],
      "sensitive": true
    }
  },
  "resources": [
    {
      "mode": "managed",
      "type": "azuread_application",
      "name": "sp",
      "provider": "provider[\"registry.terraform.io/hashicorp/azuread\"]",
      "instances": [
        {
          "schema_version": 2,
          "attributes": {
            "api": [
              {
                "known_client_applications": [],
                "mapped_claims_enabled": false,
                "oauth2_permission_scope": [],
                "requested_access_token_version": 1
              }
            ],
            "app_role": [],
            "app_role_ids": {},
            "application_id": "f81aa1f5-6513-46be-8a5e-4b8c9958e30c",
            "client_id": "f81aa1f5-6513-46be-8a5e-4b8c9958e30c",
            "description": "",
            "device_only_auth_enabled": false,
            "disabled_by_microsoft": "\u003cnil\u003e",
            "display_name": "cert-manager-dnssp",
            "fallback_public_client_enabled": false,
            "feature_tags": [
              {
                "custom_single_sign_on": false,
                "enterprise": false,
                "gallery": false,
                "hide": false
              }
            ],
            "group_membership_claims": [],
            "id": "/applications/80169b30-c4bc-46e4-b2aa-9fd0f88e73c9",
            "identifier_uris": [],
            "logo_image": "",
            "logo_url": "",
            "marketing_url": "",
            "notes": "",
            "oauth2_permission_scope_ids": {},
            "oauth2_post_response_required": false,
            "object_id": "80169b30-c4bc-46e4-b2aa-9fd0f88e73c9",
            "optional_claims": [
              {
                "access_token": [],
                "id_token": [],
                "saml2_token": []
              }
            ],
            "owners": [],
            "password": [],
            "prevent_duplicate_names": false,
            "privacy_statement_url": "",
            "public_client": [
              {
                "redirect_uris": []
              }
            ],
            "publisher_domain": "nsanty55gmail.onmicrosoft.com",
            "required_resource_access": [],
            "service_management_reference": "",
            "sign_in_audience": "AzureADMyOrg",
            "single_page_application": [
              {
                "redirect_uris": []
              }
            ],
            "support_url": "",
            "tags": [],
            "template_id": "",
            "terms_of_service_url": "",
            "timeouts": null,
            "web": [
              {
                "homepage_url": "",
                "implicit_grant": [
                  {
                    "access_token_issuance_enabled": false,
                    "id_token_issuance_enabled": false
                  }
                ],
                "logout_url": "",
                "redirect_uris": []
              }
            ]
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MzAwMDAwMDAwMDAwLCJyZWFkIjozMDAwMDAwMDAwMDAsInVwZGF0ZSI6NjAwMDAwMDAwMDAwfSwic2NoZW1hX3ZlcnNpb24iOiIyIn0="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "azuread_service_principal",
      "name": "sp",
      "provider": "provider[\"registry.terraform.io/hashicorp/azuread\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "account_enabled": true,
            "alternative_names": [],
            "app_role_assignment_required": false,
            "app_role_ids": {},
            "app_roles": [],
            "application_id": "f81aa1f5-6513-46be-8a5e-4b8c9958e30c",
            "application_tenant_id": "34ea182a-acca-40ce-b226-803d6dc7617b",
            "client_id": "f81aa1f5-6513-46be-8a5e-4b8c9958e30c",
            "description": "",
            "display_name": "cert-manager-dnssp",
            "feature_tags": [
              {
                "custom_single_sign_on": false,
                "enterprise": false,
                "gallery": false,
                "hide": false
              }
            ],
            "features": [
              {
                "custom_single_sign_on_app": false,
                "enterprise_application": false,
                "gallery_application": false,
                "visible_to_users": true
              }
            ],
            "homepage_url": "",
            "id": "999772b6-1b5a-4baf-916c-485d61068803",
            "login_url": "",
            "logout_url": "",
            "notes": "",
            "notification_email_addresses": [],
            "oauth2_permission_scope_ids": {},
            "oauth2_permission_scopes": [],
            "object_id": "999772b6-1b5a-4baf-916c-485d61068803",
            "owners": [],
            "preferred_single_sign_on_mode": "",
            "redirect_uris": [],
            "saml_metadata_url": "",
            "saml_single_sign_on": [
              {
                "relay_state": ""
              }
            ],
            "service_principal_names": [],
            "sign_in_audience": "AzureADMyOrg",
            "tags": [],
            "timeouts": null,
            "type": "Application",
            "use_existing": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MzAwMDAwMDAwMDAwLCJyZWFkIjozMDAwMDAwMDAwMDAsInVwZGF0ZSI6NjAwMDAwMDAwMDAwfX0=",
          "dependencies": [
            "azuread_application.sp"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "azurerm_kubernetes_cluster",
      "name": "main",
      "provider": "provider[\"registry.terraform.io/hashicorp/azurerm\"]",
      "instances": [
        {
          "schema_version": 2,
          "attributes": {
            "aci_connector_linux": [],
            "api_server_access_profile": [],
            "auto_scaler_profile": [],
            "automatic_upgrade_channel": "",
            "azure_active_directory_role_based_access_control": [],
            "azure_policy_enabled": null,
            "confidential_computing": [],
            "cost_analysis_enabled": false,
            "current_kubernetes_version": "1.29.7",
            "default_node_pool": [
              {
                "auto_scaling_enabled": false,
                "capacity_reservation_group_id": "",
                "fips_enabled": false,
                "gpu_instance": "",
                "host_encryption_enabled": false,
                "host_group_id": "",
                "kubelet_config": [],
                "kubelet_disk_type": "OS",
                "linux_os_config": [],
                "max_count": 0,
                "max_pods": 110,
                "min_count": 0,
                "name": "default",
                "node_count": 2,
                "node_labels": {},
                "node_network_profile": [],
                "node_public_ip_enabled": false,
                "node_public_ip_prefix_id": "",
                "only_critical_addons_enabled": false,
                "orchestrator_version": "1.29",
                "os_disk_size_gb": 128,
                "os_disk_type": "Managed",
                "os_sku": "Ubuntu",
                "pod_subnet_id": "",
                "proximity_placement_group_id": "",
                "scale_down_mode": "Delete",
                "snapshot_id": "",
                "tags": {},
                "temporary_name_for_rotation": "",
                "type": "VirtualMachineScaleSets",
                "ultra_ssd_enabled": false,
                "upgrade_settings": [
                  {
                    "drain_timeout_in_minutes": 0,
                    "max_surge": "10%",
                    "node_soak_duration_in_minutes": 0
                  }
                ],
                "vm_size": "Standard_DS2_v2",
                "vnet_subnet_id": "",
                "workload_runtime": "",
                "zones": []
              }
            ],
            "disk_encryption_set_id": "",
            "dns_prefix": "socks-shop-cluster",
            "dns_prefix_private_cluster": "",
            "edge_zone": "",
            "fqdn": "socks-shop-cluster-k0jr64yb.hcp.northeurope.azmk8s.io",
            "http_application_routing_enabled": null,
            "http_application_routing_zone_name": null,
            "http_proxy_config": [],
            "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.ContainerService/managedClusters/socks-shop-cluster",
            "identity": [
              {
                "identity_ids": [],
                "principal_id": "e38f1c1a-7274-49b9-aa94-ad6bc6324068",
                "tenant_id": "34ea182a-acca-40ce-b226-803d6dc7617b",
                "type": "SystemAssigned"
              }
            ],
            "image_cleaner_enabled": null,
            "image_cleaner_interval_hours": null,
            "ingress_application_gateway": [],
            "key_management_service": [],
            "key_vault_secrets_provider": [],
            "kube_admin_config": [],
            "kube_admin_config_raw": "",
            "kube_config": [
              {
                "client_certificate": "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",
                "client_key": "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",
                "cluster_ca_certificate": "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",
                "host": "https://socks-shop-cluster-k0jr64yb.hcp.northeurope.azmk8s.io:443",
                "password": "3837s8devhzxe66wc6pj79tye7zzdeotrobr6jzb26vm3q9b5qp6ywdxsma1st5c0kphiiv4txj33terp7ueswa99x65kyx1f3bbnpllas64useghhcc5xuot38gww5o",
                "username": "clusterUser_socks-shop-resources_socks-shop-cluster"
              }
            ],
            "kube_config_raw": "apiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: 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\n    server: https://socks-shop-cluster-k0jr64yb.hcp.northeurope.azmk8s.io:443\n  name: socks-shop-cluster\ncontexts:\n- context:\n    cluster: socks-shop-cluster\n    user: clusterUser_socks-shop-resources_socks-shop-cluster\n  name: socks-shop-cluster\ncurrent-context: socks-shop-cluster\nkind: Config\npreferences: {}\nusers:\n- name: clusterUser_socks-shop-resources_socks-shop-cluster\n  user:\n    client-certificate-data: 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\n    client-key-data: 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\n    token: 3837s8devhzxe66wc6pj79tye7zzdeotrobr6jzb26vm3q9b5qp6ywdxsma1st5c0kphiiv4txj33terp7ueswa99x65kyx1f3bbnpllas64useghhcc5xuot38gww5o\n",
            "kubelet_identity": [
              {
                "client_id": "e7172e54-e38b-4143-9f72-e1d06565287e",
                "object_id": "c7ce678f-14b5-472e-9d47-ce538d225f59",
                "user_assigned_identity_id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/MC_socks-shop-resources_socks-shop-cluster_northeurope/providers/Microsoft.ManagedIdentity/userAssignedIdentities/socks-shop-cluster-agentpool"
              }
            ],
            "kubernetes_version": "1.29",
            "linux_profile": [],
            "local_account_disabled": false,
            "location": "northeurope",
            "maintenance_window": [],
            "maintenance_window_auto_upgrade": [],
            "maintenance_window_node_os": [],
            "microsoft_defender": [],
            "monitor_metrics": [],
            "name": "socks-shop-cluster",
            "network_profile": [
              {
                "dns_service_ip": "10.0.0.10",
                "ip_versions": [
                  "IPv4"
                ],
                "load_balancer_profile": [
                  {
                    "effective_outbound_ips": [
                      "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/MC_socks-shop-resources_socks-shop-cluster_northeurope/providers/Microsoft.Network/publicIPAddresses/c84727b6-7f6c-4c14-bd48-36bc119abb0d"
                    ],
                    "idle_timeout_in_minutes": 0,
                    "managed_outbound_ip_count": 1,
                    "managed_outbound_ipv6_count": 0,
                    "outbound_ip_address_ids": [],
                    "outbound_ip_prefix_ids": [],
                    "outbound_ports_allocated": 0
                  }
                ],
                "load_balancer_sku": "standard",
                "nat_gateway_profile": [],
                "network_data_plane": "azure",
                "network_mode": "",
                "network_plugin": "kubenet",
                "network_plugin_mode": "",
                "network_policy": "",
                "outbound_type": "loadBalancer",
                "pod_cidr": "10.244.0.0/16",
                "pod_cidrs": [
                  "10.244.0.0/16"
                ],
                "service_cidr": "10.0.0.0/16",
                "service_cidrs": [
                  "10.0.0.0/16"
                ]
              }
            ],
            "node_os_upgrade_channel": "NodeImage",
            "node_resource_group": "MC_socks-shop-resources_socks-shop-cluster_northeurope",
            "node_resource_group_id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/MC_socks-shop-resources_socks-shop-cluster_northeurope",
            "oidc_issuer_enabled": false,
            "oidc_issuer_url": "",
            "oms_agent": [],
            "open_service_mesh_enabled": null,
            "portal_fqdn": "socks-shop-cluster-k0jr64yb.portal.hcp.northeurope.azmk8s.io",
            "private_cluster_enabled": false,
            "private_cluster_public_fqdn_enabled": false,
            "private_dns_zone_id": "",
            "private_fqdn": "",
            "resource_group_name": "socks-shop-resources",
            "role_based_access_control_enabled": true,
            "run_command_enabled": true,
            "service_mesh_profile": [],
            "service_principal": [],
            "sku_tier": "Free",
            "storage_profile": [],
            "support_plan": "KubernetesOfficial",
            "tags": {},
            "timeouts": null,
            "web_app_routing": [],
            "windows_profile": [],
            "workload_autoscaler_profile": [],
            "workload_identity_enabled": false
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "kube_admin_config"
              }
            ],
            [
              {
                "type": "get_attr",
                "value": "kube_config_raw"
              }
            ],
            [
              {
                "type": "get_attr",
                "value": "kube_admin_config_raw"
              }
            ],
            [
              {
                "type": "get_attr",
                "value": "kube_config"
              }
            ]
          ],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo1NDAwMDAwMDAwMDAwLCJkZWxldGUiOjU0MDAwMDAwMDAwMDAsInJlYWQiOjMwMDAwMDAwMDAwMCwidXBkYXRlIjo1NDAwMDAwMDAwMDAwfSwic2NoZW1hX3ZlcnNpb24iOiIyIn0=",
          "dependencies": [
            "azurerm_resource_group.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "azurerm_resource_group",
      "name": "main",
      "provider": "provider[\"registry.terraform.io/hashicorp/azurerm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources",
            "location": "northeurope",
            "managed_by": "",
            "name": "socks-shop-resources",
            "tags": {},
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo1NDAwMDAwMDAwMDAwLCJkZWxldGUiOjU0MDAwMDAwMDAwMDAsInJlYWQiOjMwMDAwMDAwMDAwMCwidXBkYXRlIjo1NDAwMDAwMDAwMDAwfX0="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "azurerm_role_assignment",
      "name": "aks_contributor",
      "provider": "provider[\"registry.terraform.io/hashicorp/azurerm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "condition": "",
            "condition_version": "",
            "delegated_managed_identity_resource_id": "",
            "description": "",
            "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.ContainerService/managedClusters/socks-shop-cluster/providers/Microsoft.Authorization/roleAssignments/48811f41-e6e3-44a6-0413-38e55bde2d5b",
            "name": "48811f41-e6e3-44a6-0413-38e55bde2d5b",
            "principal_id": "e38f1c1a-7274-49b9-aa94-ad6bc6324068",
            "principal_type": "ServicePrincipal",
            "role_definition_id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/providers/Microsoft.Authorization/roleDefinitions/b24988ac-6180-42a0-ab88-20f7382dd24c",
            "role_definition_name": "Contributor",
            "scope": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.ContainerService/managedClusters/socks-shop-cluster",
            "skip_service_principal_aad_check": null,
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxODAwMDAwMDAwMDAwLCJkZWxldGUiOjE4MDAwMDAwMDAwMDAsInJlYWQiOjMwMDAwMDAwMDAwMH19",
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "azurerm_role_assignment",
      "name": "aks_network_contributor",
      "provider": "provider[\"registry.terraform.io/hashicorp/azurerm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "condition": "",
            "condition_version": "",
            "delegated_managed_identity_resource_id": "",
            "description": "",
            "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.Network/virtualNetworks/socks-shop-vnet/subnets/subnet-a/providers/Microsoft.Authorization/roleAssignments/7ce96953-c0c9-c100-9dc5-2deb4f52b6e5",
            "name": "7ce96953-c0c9-c100-9dc5-2deb4f52b6e5",
            "principal_id": "e38f1c1a-7274-49b9-aa94-ad6bc6324068",
            "principal_type": "ServicePrincipal",
            "role_definition_id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/providers/Microsoft.Authorization/roleDefinitions/4d97b98b-1d4f-4787-a291-c67834d212e7",
            "role_definition_name": "Network Contributor",
            "scope": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.Network/virtualNetworks/socks-shop-vnet/subnets/subnet-a",
            "skip_service_principal_aad_check": null,
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxODAwMDAwMDAwMDAwLCJkZWxldGUiOjE4MDAwMDAwMDAwMDAsInJlYWQiOjMwMDAwMDAwMDAwMH19",
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main",
            "azurerm_subnet.subnet_a",
            "azurerm_virtual_network.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "azurerm_role_assignment",
      "name": "dns_zone_contributor",
      "provider": "provider[\"registry.terraform.io/hashicorp/azurerm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "condition": "",
            "condition_version": "",
            "delegated_managed_identity_resource_id": "",
            "description": "",
            "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.Authorization/roleAssignments/b9280c72-9cb2-2ba2-a562-ff71f3057373",
            "name": "b9280c72-9cb2-2ba2-a562-ff71f3057373",
            "principal_id": "999772b6-1b5a-4baf-916c-485d61068803",
            "principal_type": "ServicePrincipal",
            "role_definition_id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/providers/Microsoft.Authorization/roleDefinitions/befefa01-2a29-4197-83a8-272ff33ce314",
            "role_definition_name": "DNS Zone Contributor",
            "scope": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources",
            "skip_service_principal_aad_check": null,
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxODAwMDAwMDAwMDAwLCJkZWxldGUiOjE4MDAwMDAwMDAwMDAsInJlYWQiOjMwMDAwMDAwMDAwMH19",
          "dependencies": [
            "azuread_application.sp",
            "azuread_service_principal.sp",
            "azurerm_resource_group.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "azurerm_subnet",
      "name": "subnet_a",
      "provider": "provider[\"registry.terraform.io/hashicorp/azurerm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "address_prefixes": [
              "10.0.1.0/24"
            ],
            "default_outbound_access_enabled": true,
            "delegation": [],
            "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.Network/virtualNetworks/socks-shop-vnet/subnets/subnet-a",
            "name": "subnet-a",
            "private_endpoint_network_policies": "Disabled",
            "private_link_service_network_policies_enabled": true,
            "resource_group_name": "socks-shop-resources",
            "service_endpoint_policy_ids": [],
            "service_endpoints": [],
            "timeouts": null,
            "virtual_network_name": "socks-shop-vnet"
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxODAwMDAwMDAwMDAwLCJkZWxldGUiOjE4MDAwMDAwMDAwMDAsInJlYWQiOjMwMDAwMDAwMDAwMCwidXBkYXRlIjoxODAwMDAwMDAwMDAwfX0=",
          "dependencies": [
            "azurerm_resource_group.main",
            "azurerm_virtual_network.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "azurerm_subnet",
      "name": "subnet_b",
      "provider": "provider[\"registry.terraform.io/hashicorp/azurerm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "address_prefixes": [
              "10.0.2.0/24"
            ],
            "default_outbound_access_enabled": true,
            "delegation": [],
            "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.Network/virtualNetworks/socks-shop-vnet/subnets/subnet-b",
            "name": "subnet-b",
            "private_endpoint_network_policies": "Disabled",
            "private_link_service_network_policies_enabled": true,
            "resource_group_name": "socks-shop-resources",
            "service_endpoint_policy_ids": [],
            "service_endpoints": [],
            "timeouts": null,
            "virtual_network_name": "socks-shop-vnet"
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxODAwMDAwMDAwMDAwLCJkZWxldGUiOjE4MDAwMDAwMDAwMDAsInJlYWQiOjMwMDAwMDAwMDAwMCwidXBkYXRlIjoxODAwMDAwMDAwMDAwfX0=",
          "dependencies": [
            "azurerm_resource_group.main",
            "azurerm_virtual_network.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "azurerm_virtual_network",
      "name": "main",
      "provider": "provider[\"registry.terraform.io/hashicorp/azurerm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "address_space": [
              "10.0.0.0/16"
            ],
            "bgp_community": "",
            "ddos_protection_plan": [],
            "dns_servers": [],
            "edge_zone": "",
            "encryption": [],
            "flow_timeout_in_minutes": 0,
            "guid": "2d7a51b4-e310-4c57-b451-ddc5ba795009",
            "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.Network/virtualNetworks/socks-shop-vnet",
            "location": "northeurope",
            "name": "socks-shop-vnet",
            "resource_group_name": "socks-shop-resources",
            "subnet": [
              {
                "address_prefixes": [
                  "10.0.1.0/24"
                ],
                "default_outbound_access_enabled": true,
                "delegation": [],
                "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.Network/virtualNetworks/socks-shop-vnet/subnets/subnet-a",
                "name": "subnet-a",
                "private_endpoint_network_policies": "Disabled",
                "private_link_service_network_policies_enabled": true,
                "route_table_id": "",
                "security_group": "",
                "service_endpoint_policy_ids": [],
                "service_endpoints": []
              },
              {
                "address_prefixes": [
                  "10.0.2.0/24"
                ],
                "default_outbound_access_enabled": true,
                "delegation": [],
                "id": "/subscriptions/1f0ec4ef-e180-4466-9c30-2e149184e9ab/resourceGroups/socks-shop-resources/providers/Microsoft.Network/virtualNetworks/socks-shop-vnet/subnets/subnet-b",
                "name": "subnet-b",
                "private_endpoint_network_policies": "Disabled",
                "private_link_service_network_policies_enabled": true,
                "route_table_id": "",
                "security_group": "",
                "service_endpoint_policy_ids": [],
                "service_endpoints": []
              }
            ],
            "tags": {},
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxODAwMDAwMDAwMDAwLCJkZWxldGUiOjE4MDAwMDAwMDAwMDAsInJlYWQiOjMwMDAwMDAwMDAwMCwidXBkYXRlIjoxODAwMDAwMDAwMDAwfX0=",
          "dependencies": [
            "azurerm_resource_group.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "prometheus",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "kube-prometheus-stack",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "prometheus",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "v0.63.0",
                "chart": "kube-prometheus-stack",
                "first_deployed": 1726495434,
                "last_deployed": 1726495434,
                "name": "prometheus",
                "namespace": "prometheus",
                "notes": "kube-prometheus-stack has been installed. Check its status by running:\n  kubectl --namespace prometheus get pods -l \"release=prometheus\"\n\nVisit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create \u0026 configure Alertmanager and Prometheus instances using the Operator.\n\n1. Get the application URL by running these commands:\n  export POD_NAME=$(kubectl get pods --namespace prometheus -l \"app.kubernetes.io/name=prometheus-node-exporter,app.kubernetes.io/instance=prometheus\" -o jsonpath=\"{.items[0].metadata.name}\")\n  echo \"Visit http://127.0.0.1:9100 to use your application\"\n  kubectl port-forward --namespace prometheus $POD_NAME 9100\n1. Get your 'admin' user password by running:\n\n   kubectl get secret --namespace prometheus prometheus-grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n\n\n2. The Grafana server can be accessed via port 80 on the following DNS name from within your cluster:\n\n   prometheus-grafana.prometheus.svc.cluster.local\n\n   Get the Grafana URL to visit by running these commands in the same shell:\n     export POD_NAME=$(kubectl get pods --namespace prometheus -l \"app.kubernetes.io/name=grafana,app.kubernetes.io/instance=prometheus\" -o jsonpath=\"{.items[0].metadata.name}\")\n     kubectl --namespace prometheus port-forward $POD_NAME 3000\n\n3. Login with the password from step 1 and the username: admin\n#################################################################################\n######   WARNING: Persistence is disabled!!! You will lose your data when   #####\n######            the Grafana pod is terminated.                            #####\n#################################################################################\n\nkube-state-metrics is a simple service that listens to the Kubernetes API server and generates metrics about the state of the objects.\nThe exposed metrics can be found here:\nhttps://github.com/kubernetes/kube-state-metrics/blob/master/docs/README.md#exposed-metrics\n\nThe metrics are exported on the HTTP endpoint /metrics on the listening port.\nIn your case, prometheus-kube-state-metrics.prometheus.svc.cluster.local:8080/metrics\n\nThey are served either as plaintext or protobuf depending on the Accept header.\nThey are designed to be consumed either by Prometheus itself or by a scraper that is compatible with scraping a Prometheus client endpoint.\n",
                "revision": 1,
                "values": "{\"additionalPrometheusRulesMap\":{},\"alertmanager\":{\"alertmanagerSpec\":{\"additionalConfig\":{},\"additionalConfigString\":\"\",\"additionalPeers\":[],\"affinity\":{},\"alertmanagerConfigMatcherStrategy\":{},\"alertmanagerConfigNamespaceSelector\":{},\"alertmanagerConfigSelector\":{},\"alertmanagerConfiguration\":{},\"automountServiceAccountToken\":true,\"clusterAdvertiseAddress\":false,\"clusterGossipInterval\":\"\",\"clusterPeerTimeout\":\"\",\"clusterPushpullInterval\":\"\",\"configMaps\":[],\"containers\":[],\"externalUrl\":null,\"forceEnableClusterMode\":false,\"image\":{\"registry\":\"quay.io\",\"repository\":\"prometheus/alertmanager\",\"sha\":\"\",\"tag\":\"v0.27.0\"},\"initContainers\":[],\"listenLocal\":false,\"logFormat\":\"logfmt\",\"logLevel\":\"info\",\"minReadySeconds\":0,\"nodeSelector\":{},\"paused\":false,\"podAntiAffinity\":\"\",\"podAntiAffinityTopologyKey\":\"kubernetes.io/hostname\",\"podMetadata\":{},\"portName\":\"http-web\",\"priorityClassName\":\"\",\"replicas\":1,\"resources\":{},\"retention\":\"120h\",\"routePrefix\":\"/\",\"scheme\":\"\",\"secrets\":[],\"securityContext\":{\"fsGroup\":2000,\"runAsGroup\":2000,\"runAsNonRoot\":true,\"runAsUser\":1000,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"storage\":{},\"tlsConfig\":{},\"tolerations\":[],\"topologySpreadConstraints\":[],\"useExistingSecret\":false,\"volumeMounts\":[],\"volumes\":[],\"web\":{}},\"annotations\":{},\"apiVersion\":\"v2\",\"config\":{\"global\":{\"resolve_timeout\":\"5m\"},\"inhibit_rules\":[{\"equal\":[\"namespace\",\"alertname\"],\"source_matchers\":[\"severity = critical\"],\"target_matchers\":[\"severity =~ warning|info\"]},{\"equal\":[\"namespace\",\"alertname\"],\"source_matchers\":[\"severity = warning\"],\"target_matchers\":[\"severity = info\"]},{\"equal\":[\"namespace\"],\"source_matchers\":[\"alertname = InfoInhibitor\"],\"target_matchers\":[\"severity = info\"]},{\"target_matchers\":[\"alertname = InfoInhibitor\"]}],\"receivers\":[{\"name\":\"null\"}],\"route\":{\"group_by\":[\"namespace\"],\"group_interval\":\"5m\",\"group_wait\":\"30s\",\"receiver\":\"null\",\"repeat_interval\":\"12h\",\"routes\":[{\"matchers\":[\"alertname = \\\"Watchdog\\\"\"],\"receiver\":\"null\"}]},\"templates\":[\"/etc/alertmanager/config/*.tmpl\"]},\"enableFeatures\":[],\"enabled\":true,\"extraSecret\":{\"annotations\":{},\"data\":{}},\"ingress\":{\"annotations\":{},\"enabled\":false,\"hosts\":[],\"labels\":{},\"paths\":[],\"tls\":[]},\"ingressPerReplica\":{\"annotations\":{},\"enabled\":false,\"hostDomain\":\"\",\"hostPrefix\":\"\",\"labels\":{},\"paths\":[],\"tlsSecretName\":\"\",\"tlsSecretPerReplica\":{\"enabled\":false,\"prefix\":\"alertmanager\"}},\"podDisruptionBudget\":{\"enabled\":false,\"maxUnavailable\":\"\",\"minAvailable\":1},\"secret\":{\"annotations\":{}},\"service\":{\"additionalPorts\":[],\"annotations\":{},\"clusterIP\":\"\",\"externalIPs\":[],\"externalTrafficPolicy\":\"Cluster\",\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"labels\":{},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":30903,\"port\":9093,\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{\"clientIP\":{\"timeoutSeconds\":10800}},\"targetPort\":9093,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"serviceMonitor\":{\"additionalEndpoints\":[],\"additionalLabels\":{},\"bearerTokenFile\":null,\"enableHttp2\":true,\"interval\":\"\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"scheme\":\"\",\"selfMonitor\":true,\"targetLimit\":0,\"tlsConfig\":{}},\"servicePerReplica\":{\"annotations\":{},\"enabled\":false,\"externalTrafficPolicy\":\"Cluster\",\"loadBalancerSourceRanges\":[],\"nodePort\":30904,\"port\":9093,\"targetPort\":9093,\"type\":\"ClusterIP\"},\"stringConfig\":\"\",\"templateFiles\":{},\"tplConfig\":false},\"cleanPrometheusOperatorObjectNames\":false,\"commonLabels\":{},\"coreDns\":{\"enabled\":true,\"service\":{\"enabled\":true,\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"port\":9153,\"targetPort\":9153},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":true,\"interval\":\"\",\"jobLabel\":\"jobLabel\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"port\":\"http-metrics\",\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"selector\":{},\"targetLimit\":0}},\"crds\":{\"enabled\":true},\"customRules\":{},\"defaultRules\":{\"additionalAggregationLabels\":[],\"additionalRuleAnnotations\":{},\"additionalRuleGroupAnnotations\":{\"alertmanager\":{},\"configReloaders\":{},\"etcd\":{},\"general\":{},\"k8sContainerCpuUsageSecondsTotal\":{},\"k8sContainerMemoryCache\":{},\"k8sContainerMemoryRss\":{},\"k8sContainerMemorySwap\":{},\"k8sContainerResource\":{},\"k8sPodOwner\":{},\"kubeApiserverAvailability\":{},\"kubeApiserverBurnrate\":{},\"kubeApiserverHistogram\":{},\"kubeApiserverSlos\":{},\"kubeControllerManager\":{},\"kubePrometheusGeneral\":{},\"kubePrometheusNodeRecording\":{},\"kubeProxy\":{},\"kubeSchedulerAlerting\":{},\"kubeSchedulerRecording\":{},\"kubeStateMetrics\":{},\"kubelet\":{},\"kubernetesApps\":{},\"kubernetesResources\":{},\"kubernetesStorage\":{},\"kubernetesSystem\":{},\"network\":{},\"node\":{},\"nodeExporterAlerting\":{},\"nodeExporterRecording\":{},\"prometheus\":{},\"prometheusOperator\":{}},\"additionalRuleGroupLabels\":{\"alertmanager\":{},\"configReloaders\":{},\"etcd\":{},\"general\":{},\"k8sContainerCpuUsageSecondsTotal\":{},\"k8sContainerMemoryCache\":{},\"k8sContainerMemoryRss\":{},\"k8sContainerMemorySwap\":{},\"k8sContainerResource\":{},\"k8sPodOwner\":{},\"kubeApiserverAvailability\":{},\"kubeApiserverBurnrate\":{},\"kubeApiserverHistogram\":{},\"kubeApiserverSlos\":{},\"kubeControllerManager\":{},\"kubePrometheusGeneral\":{},\"kubePrometheusNodeRecording\":{},\"kubeProxy\":{},\"kubeSchedulerAlerting\":{},\"kubeSchedulerRecording\":{},\"kubeStateMetrics\":{},\"kubelet\":{},\"kubernetesApps\":{},\"kubernetesResources\":{},\"kubernetesStorage\":{},\"kubernetesSystem\":{},\"network\":{},\"node\":{},\"nodeExporterAlerting\":{},\"nodeExporterRecording\":{},\"prometheus\":{},\"prometheusOperator\":{}},\"additionalRuleLabels\":{},\"annotations\":{},\"appNamespacesTarget\":\".*\",\"create\":true,\"disabled\":{},\"keepFiringFor\":\"\",\"labels\":{},\"node\":{\"fsSelector\":\"fstype!=\\\"\\\"\"},\"rules\":{\"alertmanager\":true,\"configReloaders\":true,\"etcd\":true,\"general\":true,\"k8sContainerCpuUsageSecondsTotal\":true,\"k8sContainerMemoryCache\":true,\"k8sContainerMemoryRss\":true,\"k8sContainerMemorySwap\":true,\"k8sContainerMemoryWorkingSetBytes\":true,\"k8sContainerResource\":true,\"k8sPodOwner\":true,\"kubeApiserverAvailability\":true,\"kubeApiserverBurnrate\":true,\"kubeApiserverHistogram\":true,\"kubeApiserverSlos\":true,\"kubeControllerManager\":true,\"kubePrometheusGeneral\":true,\"kubePrometheusNodeRecording\":true,\"kubeProxy\":true,\"kubeSchedulerAlerting\":true,\"kubeSchedulerRecording\":true,\"kubeStateMetrics\":true,\"kubelet\":true,\"kubernetesApps\":true,\"kubernetesResources\":true,\"kubernetesStorage\":true,\"kubernetesSystem\":true,\"network\":true,\"node\":true,\"nodeExporterAlerting\":true,\"nodeExporterRecording\":true,\"prometheus\":true,\"prometheusOperator\":true,\"windows\":true},\"runbookUrl\":\"https://runbooks.prometheus-operator.dev/runbooks\"},\"extraManifests\":[],\"fullnameOverride\":\"\",\"global\":{\"imagePullSecrets\":[],\"imageRegistry\":\"\",\"rbac\":{\"create\":true,\"createAggregateClusterRoles\":false,\"pspAnnotations\":{},\"pspEnabled\":false}},\"grafana\":{\"additionalDataSources\":[],\"adminPassword\":\"prom-operator\",\"defaultDashboardsEditable\":true,\"defaultDashboardsEnabled\":true,\"defaultDashboardsTimezone\":\"utc\",\"deleteDatasources\":[],\"enabled\":true,\"extraConfigmapMounts\":[],\"forceDeployDashboards\":false,\"forceDeployDatasources\":false,\"ingress\":{\"annotations\":{},\"enabled\":false,\"hosts\":[],\"labels\":{},\"path\":\"/\",\"tls\":[]},\"namespaceOverride\":\"\",\"prune\":false,\"rbac\":{\"pspEnabled\":false},\"service\":{\"ipFamilies\":[],\"ipFamilyPolicy\":\"\",\"portName\":\"http-web\"},\"serviceAccount\":{\"autoMount\":true,\"create\":true},\"serviceMonitor\":{\"enabled\":true,\"interval\":\"\",\"labels\":{},\"path\":\"/metrics\",\"relabelings\":[],\"scheme\":\"http\",\"scrapeTimeout\":\"30s\",\"tlsConfig\":{}},\"sidecar\":{\"dashboards\":{\"annotations\":{},\"enableNewTablePanelSyntax\":false,\"enabled\":true,\"label\":\"grafana_dashboard\",\"labelValue\":\"1\",\"multicluster\":{\"etcd\":{\"enabled\":false},\"global\":{\"enabled\":false}},\"provider\":{\"allowUiUpdates\":false},\"searchNamespace\":\"ALL\"},\"datasources\":{\"alertmanager\":{\"enabled\":true,\"handleGrafanaManagedAlerts\":false,\"implementation\":\"prometheus\",\"name\":\"Alertmanager\",\"uid\":\"alertmanager\"},\"annotations\":{},\"createPrometheusReplicasDatasources\":false,\"defaultDatasourceEnabled\":true,\"enabled\":true,\"exemplarTraceIdDestinations\":{},\"httpMethod\":\"POST\",\"isDefaultDatasource\":true,\"label\":\"grafana_datasource\",\"labelValue\":\"1\",\"name\":\"Prometheus\",\"uid\":\"prometheus\"}}},\"kube-state-metrics\":{\"namespaceOverride\":\"\",\"prometheus\":{\"monitor\":{\"enabled\":true,\"honorLabels\":true,\"interval\":\"\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"scrapeTimeout\":\"\",\"targetLimit\":0}},\"rbac\":{\"create\":true},\"releaseLabel\":true,\"selfMonitor\":{\"enabled\":false}},\"kubeApiServer\":{\"enabled\":true,\"serviceMonitor\":{\"additionalLabels\":{},\"interval\":\"\",\"jobLabel\":\"component\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[{\"action\":\"drop\",\"regex\":\"apiserver_request_duration_seconds_bucket;(0.15|0.2|0.3|0.35|0.4|0.45|0.6|0.7|0.8|0.9|1.25|1.5|1.75|2|3|3.5|4|4.5|6|7|8|9|15|25|40|50)\",\"sourceLabels\":[\"__name__\",\"le\"]}],\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"selector\":{\"matchLabels\":{\"component\":\"apiserver\",\"provider\":\"kubernetes\"}},\"targetLimit\":0},\"tlsConfig\":{\"insecureSkipVerify\":false,\"serverName\":\"kubernetes\"}},\"kubeControllerManager\":{\"enabled\":true,\"endpoints\":[],\"service\":{\"enabled\":true,\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"port\":null,\"targetPort\":null},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":true,\"https\":null,\"insecureSkipVerify\":null,\"interval\":\"\",\"jobLabel\":\"jobLabel\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"port\":\"http-metrics\",\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"selector\":{},\"serverName\":null,\"targetLimit\":0}},\"kubeDns\":{\"enabled\":false,\"service\":{\"dnsmasq\":{\"port\":10054,\"targetPort\":10054},\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"skydns\":{\"port\":10055,\"targetPort\":10055}},\"serviceMonitor\":{\"additionalLabels\":{},\"dnsmasqMetricRelabelings\":[],\"dnsmasqRelabelings\":[],\"interval\":\"\",\"jobLabel\":\"jobLabel\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"selector\":{},\"targetLimit\":0}},\"kubeEtcd\":{\"enabled\":true,\"endpoints\":[],\"service\":{\"enabled\":true,\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"port\":2381,\"targetPort\":2381},\"serviceMonitor\":{\"additionalLabels\":{},\"caFile\":\"\",\"certFile\":\"\",\"enabled\":true,\"insecureSkipVerify\":false,\"interval\":\"\",\"jobLabel\":\"jobLabel\",\"keyFile\":\"\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"port\":\"http-metrics\",\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"scheme\":\"http\",\"selector\":{},\"serverName\":\"\",\"targetLimit\":0}},\"kubeProxy\":{\"enabled\":true,\"endpoints\":[],\"service\":{\"enabled\":true,\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"port\":10249,\"targetPort\":10249},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":true,\"https\":false,\"interval\":\"\",\"jobLabel\":\"jobLabel\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"port\":\"http-metrics\",\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"selector\":{},\"targetLimit\":0}},\"kubeScheduler\":{\"enabled\":true,\"endpoints\":[],\"service\":{\"enabled\":true,\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"port\":null,\"targetPort\":null},\"serviceMonitor\":{\"additionalLabels\":{},\"enabled\":true,\"https\":null,\"insecureSkipVerify\":null,\"interval\":\"\",\"jobLabel\":\"jobLabel\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"port\":\"http-metrics\",\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"selector\":{},\"serverName\":null,\"targetLimit\":0}},\"kubeStateMetrics\":{\"enabled\":true},\"kubeTargetVersionOverride\":\"\",\"kubeVersionOverride\":\"\",\"kubelet\":{\"enabled\":true,\"namespace\":\"kube-system\",\"serviceMonitor\":{\"additionalLabels\":{},\"attachMetadata\":{\"node\":false},\"cAdvisor\":true,\"cAdvisorMetricRelabelings\":[{\"action\":\"drop\",\"regex\":\"container_cpu_(cfs_throttled_seconds_total|load_average_10s|system_seconds_total|user_seconds_total)\",\"sourceLabels\":[\"__name__\"]},{\"action\":\"drop\",\"regex\":\"container_fs_(io_current|io_time_seconds_total|io_time_weighted_seconds_total|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)\",\"sourceLabels\":[\"__name__\"]},{\"action\":\"drop\",\"regex\":\"container_memory_(mapped_file|swap)\",\"sourceLabels\":[\"__name__\"]},{\"action\":\"drop\",\"regex\":\"container_(file_descriptors|tasks_state|threads_max)\",\"sourceLabels\":[\"__name__\"]},{\"action\":\"drop\",\"regex\":\"container_spec.*\",\"sourceLabels\":[\"__name__\"]},{\"action\":\"drop\",\"regex\":\".+;\",\"sourceLabels\":[\"id\",\"pod\"]}],\"cAdvisorRelabelings\":[{\"action\":\"replace\",\"sourceLabels\":[\"__metrics_path__\"],\"targetLabel\":\"metrics_path\"}],\"honorLabels\":true,\"honorTimestamps\":true,\"https\":true,\"insecureSkipVerify\":true,\"interval\":\"\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"probes\":true,\"probesMetricRelabelings\":[],\"probesRelabelings\":[{\"action\":\"replace\",\"sourceLabels\":[\"__metrics_path__\"],\"targetLabel\":\"metrics_path\"}],\"proxyUrl\":\"\",\"relabelings\":[{\"action\":\"replace\",\"sourceLabels\":[\"__metrics_path__\"],\"targetLabel\":\"metrics_path\"}],\"resource\":false,\"resourcePath\":\"/metrics/resource/v1alpha1\",\"resourceRelabelings\":[{\"action\":\"replace\",\"sourceLabels\":[\"__metrics_path__\"],\"targetLabel\":\"metrics_path\"}],\"sampleLimit\":0,\"targetLimit\":0}},\"kubernetesServiceMonitors\":{\"enabled\":true},\"nameOverride\":\"\",\"namespaceOverride\":\"\",\"nodeExporter\":{\"enabled\":true,\"forceDeployDashboards\":false,\"operatingSystems\":{\"darwin\":{\"enabled\":true},\"linux\":{\"enabled\":true}}},\"podSecurityPolicy\":{\"enabled\":true},\"prometheus\":{\"additionalPodMonitors\":[],\"additionalRulesForClusterRole\":[],\"additionalServiceMonitors\":[],\"agentMode\":false,\"annotations\":{},\"enabled\":true,\"extraSecret\":{\"annotations\":{},\"data\":{}},\"ingress\":{\"annotations\":{},\"enabled\":false,\"hosts\":[],\"labels\":{},\"paths\":[],\"tls\":[]},\"ingressPerReplica\":{\"annotations\":{},\"enabled\":false,\"hostDomain\":\"\",\"hostPrefix\":\"\",\"labels\":{},\"paths\":[],\"tlsSecretName\":\"\",\"tlsSecretPerReplica\":{\"enabled\":false,\"prefix\":\"prometheus\"}},\"networkPolicy\":{\"enabled\":false,\"flavor\":\"kubernetes\"},\"podDisruptionBudget\":{\"enabled\":false,\"maxUnavailable\":\"\",\"minAvailable\":1},\"podSecurityPolicy\":{\"allowedCapabilities\":[],\"allowedHostPaths\":[],\"volumes\":[]},\"prometheusSpec\":{\"additionalAlertManagerConfigs\":[],\"additionalAlertManagerConfigsSecret\":{},\"additionalAlertRelabelConfigs\":[],\"additionalAlertRelabelConfigsSecret\":{},\"additionalArgs\":[],\"additionalConfig\":{},\"additionalConfigString\":\"\",\"additionalPrometheusSecretsAnnotations\":{},\"additionalRemoteRead\":[],\"additionalRemoteWrite\":[],\"additionalScrapeConfigs\":[],\"additionalScrapeConfigsSecret\":{},\"affinity\":{},\"alertingEndpoints\":[],\"allowOverlappingBlocks\":false,\"apiserverConfig\":{},\"arbitraryFSAccessThroughSMs\":false,\"automountServiceAccountToken\":true,\"configMaps\":[],\"containers\":[],\"disableCompaction\":false,\"enableAdminAPI\":false,\"enableFeatures\":[],\"enableRemoteWriteReceiver\":false,\"enforcedKeepDroppedTargets\":0,\"enforcedLabelLimit\":false,\"enforcedLabelNameLengthLimit\":false,\"enforcedLabelValueLengthLimit\":false,\"enforcedNamespaceLabel\":\"\",\"enforcedSampleLimit\":false,\"enforcedTargetLimit\":false,\"evaluationInterval\":\"\",\"excludedFromEnforcement\":[],\"exemplars\":\"\",\"externalLabels\":{},\"externalUrl\":\"\",\"hostAliases\":[],\"hostNetwork\":false,\"ignoreNamespaceSelectors\":false,\"image\":{\"registry\":\"quay.io\",\"repository\":\"prometheus/prometheus\",\"sha\":\"\",\"tag\":\"v2.54.1\"},\"initContainers\":[],\"listenLocal\":false,\"logFormat\":\"logfmt\",\"logLevel\":\"info\",\"maximumStartupDurationSeconds\":0,\"minReadySeconds\":0,\"nodeSelector\":{},\"overrideHonorLabels\":false,\"overrideHonorTimestamps\":false,\"paused\":false,\"persistentVolumeClaimRetentionPolicy\":{},\"podAntiAffinity\":\"\",\"podAntiAffinityTopologyKey\":\"kubernetes.io/hostname\",\"podMetadata\":{},\"podMonitorNamespaceSelector\":{},\"podMonitorSelector\":{},\"podMonitorSelectorNilUsesHelmValues\":true,\"portName\":\"http-web\",\"priorityClassName\":\"\",\"probeNamespaceSelector\":{},\"probeSelector\":{},\"probeSelectorNilUsesHelmValues\":true,\"prometheusExternalLabelName\":\"\",\"prometheusExternalLabelNameClear\":false,\"prometheusRulesExcludedFromEnforce\":[],\"query\":{},\"queryLogFile\":false,\"remoteRead\":[],\"remoteWrite\":[],\"remoteWriteDashboards\":false,\"replicaExternalLabelName\":\"\",\"replicaExternalLabelNameClear\":false,\"replicas\":1,\"resources\":{},\"retention\":\"10d\",\"retentionSize\":\"\",\"routePrefix\":\"/\",\"ruleNamespaceSelector\":{},\"ruleSelector\":{},\"ruleSelectorNilUsesHelmValues\":true,\"sampleLimit\":false,\"scrapeClasses\":[],\"scrapeConfigNamespaceSelector\":{},\"scrapeConfigSelector\":{},\"scrapeConfigSelectorNilUsesHelmValues\":true,\"scrapeInterval\":\"\",\"scrapeTimeout\":\"\",\"secrets\":[],\"securityContext\":{\"fsGroup\":2000,\"runAsGroup\":2000,\"runAsNonRoot\":true,\"runAsUser\":1000,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"serviceDiscoveryRole\":\"\",\"serviceMonitorNamespaceSelector\":{},\"serviceMonitorSelector\":{},\"serviceMonitorSelectorNilUsesHelmValues\":true,\"shards\":1,\"storageSpec\":{},\"thanos\":{},\"tolerations\":[],\"topologySpreadConstraints\":[],\"tracingConfig\":{},\"tsdb\":{\"outOfOrderTimeWindow\":\"0s\"},\"version\":\"\",\"volumeMounts\":[],\"volumes\":[],\"walCompression\":true,\"web\":{}},\"service\":{\"additionalPorts\":[],\"annotations\":{},\"clusterIP\":\"\",\"externalIPs\":[],\"externalTrafficPolicy\":\"Cluster\",\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"labels\":{},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":30090,\"port\":9090,\"publishNotReadyAddresses\":false,\"reloaderWebPort\":8080,\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{\"clientIP\":{\"timeoutSeconds\":10800}},\"targetPort\":9090,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"serviceMonitor\":{\"additionalEndpoints\":[],\"additionalLabels\":{},\"bearerTokenFile\":null,\"interval\":\"\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"relabelings\":[],\"sampleLimit\":0,\"scheme\":\"\",\"selfMonitor\":true,\"targetLimit\":0,\"tlsConfig\":{}},\"servicePerReplica\":{\"annotations\":{},\"enabled\":false,\"externalTrafficPolicy\":\"Cluster\",\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"loadBalancerSourceRanges\":[],\"nodePort\":30091,\"port\":9090,\"targetPort\":9090,\"type\":\"ClusterIP\"},\"thanosIngress\":{\"annotations\":{},\"enabled\":false,\"hosts\":[],\"labels\":{},\"nodePort\":30901,\"paths\":[],\"servicePort\":10901,\"tls\":[]},\"thanosService\":{\"annotations\":{},\"clusterIP\":\"None\",\"enabled\":false,\"externalTrafficPolicy\":\"Cluster\",\"httpNodePort\":30902,\"httpPort\":10902,\"httpPortName\":\"http\",\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"labels\":{},\"nodePort\":30901,\"port\":10901,\"portName\":\"grpc\",\"targetHttpPort\":\"http\",\"targetPort\":\"grpc\",\"type\":\"ClusterIP\"},\"thanosServiceExternal\":{\"annotations\":{},\"enabled\":false,\"externalTrafficPolicy\":\"Cluster\",\"httpNodePort\":30902,\"httpPort\":10902,\"httpPortName\":\"http\",\"labels\":{},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":30901,\"port\":10901,\"portName\":\"grpc\",\"targetHttpPort\":\"http\",\"targetPort\":\"grpc\",\"type\":\"LoadBalancer\"},\"thanosServiceMonitor\":{\"additionalLabels\":{},\"bearerTokenFile\":null,\"enabled\":false,\"interval\":\"\",\"metricRelabelings\":[],\"relabelings\":[],\"scheme\":\"\",\"tlsConfig\":{}}},\"prometheus-node-exporter\":{\"extraArgs\":[\"--collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)\",\"--collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$\"],\"namespaceOverride\":\"\",\"podLabels\":{\"jobLabel\":\"node-exporter\"},\"prometheus\":{\"monitor\":{\"enabled\":true,\"interval\":\"\",\"jobLabel\":\"jobLabel\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"scrapeTimeout\":\"\",\"targetLimit\":0}},\"rbac\":{\"pspEnabled\":false},\"releaseLabel\":true,\"service\":{\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"labels\":{\"jobLabel\":\"node-exporter\"},\"portName\":\"http-metrics\"}},\"prometheus-windows-exporter\":{\"config\":\"collectors:\\n  enabled: '[defaults],memory,container'\",\"podLabels\":{\"jobLabel\":\"windows-exporter\"},\"prometheus\":{\"monitor\":{\"enabled\":true,\"jobLabel\":\"jobLabel\"}},\"releaseLabel\":true},\"prometheusOperator\":{\"admissionWebhooks\":{\"annotations\":{},\"caBundle\":\"\",\"certManager\":{\"admissionCert\":{\"duration\":\"\"},\"enabled\":false,\"rootCert\":{\"duration\":\"\"}},\"createSecretJob\":{\"securityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true}},\"deployment\":{\"affinity\":{},\"annotations\":{},\"automountServiceAccountToken\":true,\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true},\"dnsConfig\":{},\"enabled\":false,\"hostNetwork\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"quay.io\",\"repository\":\"prometheus-operator/admission-webhook\",\"sha\":\"\",\"tag\":\"\"},\"labels\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"nodeSelector\":{},\"podAnnotations\":{},\"podDisruptionBudget\":{},\"podLabels\":{},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicas\":1,\"resources\":{},\"revisionHistoryLimit\":10,\"securityContext\":{\"fsGroup\":65534,\"runAsGroup\":65534,\"runAsNonRoot\":true,\"runAsUser\":65534,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"service\":{\"additionalPorts\":[],\"annotations\":{},\"clusterIP\":\"\",\"externalIPs\":[],\"externalTrafficPolicy\":\"Cluster\",\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"labels\":{},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":31080,\"nodePortTls\":31443,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"automountServiceAccountToken\":false,\"create\":true,\"name\":\"\"},\"strategy\":{},\"tls\":{\"enabled\":true,\"internalPort\":10250,\"tlsMinVersion\":\"VersionTLS13\"},\"tolerations\":[]},\"enabled\":true,\"failurePolicy\":\"\",\"mutatingWebhookConfiguration\":{\"annotations\":{}},\"namespaceSelector\":{},\"objectSelector\":{},\"patch\":{\"affinity\":{},\"annotations\":{},\"enabled\":true,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"registry.k8s.io\",\"repository\":\"ingress-nginx/kube-webhook-certgen\",\"sha\":\"\",\"tag\":\"v20221220-controller-v1.5.1-58-g787ea74b6\"},\"nodeSelector\":{},\"podAnnotations\":{},\"priorityClassName\":\"\",\"resources\":{},\"securityContext\":{\"runAsGroup\":2000,\"runAsNonRoot\":true,\"runAsUser\":2000,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"serviceAccount\":{\"automountServiceAccountToken\":true,\"create\":true},\"tolerations\":[],\"ttlSecondsAfterFinished\":60},\"patchWebhookJob\":{\"securityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true}},\"timeoutSeconds\":10,\"validatingWebhookConfiguration\":{\"annotations\":{}}},\"affinity\":{},\"alertmanagerConfigNamespaces\":[],\"alertmanagerInstanceNamespaces\":[],\"alertmanagerInstanceSelector\":\"\",\"annotations\":{},\"automountServiceAccountToken\":true,\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true},\"denyNamespaces\":[],\"dnsConfig\":{},\"enabled\":true,\"env\":{\"GOGC\":\"30\"},\"extraVolumeMounts\":[],\"extraVolumes\":[],\"fullnameOverride\":\"\",\"hostNetwork\":false,\"image\":{\"pullPolicy\":\"IfNotPresent\",\"registry\":\"quay.io\",\"repository\":\"prometheus-operator/prometheus-operator\",\"sha\":\"\",\"tag\":\"\"},\"kubeletService\":{\"enabled\":true,\"name\":\"\",\"namespace\":\"kube-system\",\"selector\":\"\"},\"labels\":{},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":0,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"namespaces\":{},\"networkPolicy\":{\"enabled\":false,\"flavor\":\"kubernetes\"},\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"prometheusConfigReloader\":{\"enableProbe\":false,\"image\":{\"registry\":\"quay.io\",\"repository\":\"prometheus-operator/prometheus-config-reloader\",\"sha\":\"\",\"tag\":\"\"},\"resources\":{}},\"prometheusInstanceNamespaces\":[],\"prometheusInstanceSelector\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":0,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"resources\":{},\"revisionHistoryLimit\":10,\"secretFieldSelector\":\"type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1\",\"securityContext\":{\"fsGroup\":65534,\"runAsGroup\":65534,\"runAsNonRoot\":true,\"runAsUser\":65534,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"service\":{\"additionalPorts\":[],\"annotations\":{},\"clusterIP\":\"\",\"externalIPs\":[],\"externalTrafficPolicy\":\"Cluster\",\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"labels\":{},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":30080,\"nodePortTls\":30443,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"serviceMonitor\":{\"additionalLabels\":{},\"interval\":\"\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"relabelings\":[],\"sampleLimit\":0,\"scrapeTimeout\":\"\",\"selfMonitor\":true,\"targetLimit\":0},\"strategy\":{},\"thanosImage\":{\"registry\":\"quay.io\",\"repository\":\"thanos/thanos\",\"sha\":\"\",\"tag\":\"v0.36.1\"},\"thanosRulerInstanceNamespaces\":[],\"thanosRulerInstanceSelector\":\"\",\"tls\":{\"enabled\":true,\"internalPort\":10250,\"tlsMinVersion\":\"VersionTLS13\"},\"tolerations\":[],\"verticalPodAutoscaler\":{\"controlledResources\":[],\"enabled\":false,\"maxAllowed\":{},\"minAllowed\":{},\"updatePolicy\":{\"updateMode\":\"Auto\"}}},\"server\":{\"persistentVolume\":{\"enabled\":false}},\"server.resources\":\"\\\"limits\\\":\\n  \\\"cpu\\\": \\\"200m\\\"\\n  \\\"memory\\\": \\\"50Mi\\\"\\n\\\"requests\\\":\\n  \\\"cpu\\\": \\\"100m\\\"\\n  \\\"memory\\\": \\\"30Mi\\\"\\n\",\"thanosRuler\":{\"annotations\":{},\"enabled\":false,\"extraSecret\":{\"annotations\":{},\"data\":{}},\"ingress\":{\"annotations\":{},\"enabled\":false,\"hosts\":[],\"labels\":{},\"paths\":[],\"tls\":[]},\"podDisruptionBudget\":{\"enabled\":false,\"maxUnavailable\":\"\",\"minAvailable\":1},\"service\":{\"additionalPorts\":[],\"annotations\":{},\"clusterIP\":\"\",\"externalIPs\":[],\"externalTrafficPolicy\":\"Cluster\",\"ipDualStack\":{\"enabled\":false,\"ipFamilies\":[\"IPv6\",\"IPv4\"],\"ipFamilyPolicy\":\"PreferDualStack\"},\"labels\":{},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePort\":30905,\"port\":10902,\"targetPort\":10902,\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"create\":true,\"name\":\"\"},\"serviceMonitor\":{\"additionalEndpoints\":[],\"additionalLabels\":{},\"bearerTokenFile\":null,\"interval\":\"\",\"labelLimit\":0,\"labelNameLengthLimit\":0,\"labelValueLengthLimit\":0,\"metricRelabelings\":[],\"proxyUrl\":\"\",\"relabelings\":[],\"sampleLimit\":0,\"scheme\":\"\",\"selfMonitor\":true,\"targetLimit\":0,\"tlsConfig\":{}},\"thanosRulerSpec\":{\"additionalArgs\":[],\"additionalConfig\":{},\"additionalConfigString\":\"\",\"affinity\":{},\"alertDropLabels\":[],\"alertmanagersConfig\":{\"existingSecret\":{},\"secret\":{}},\"containers\":[],\"evaluationInterval\":\"\",\"externalPrefix\":null,\"externalPrefixNilUsesHelmValues\":true,\"image\":{\"registry\":\"quay.io\",\"repository\":\"thanos/thanos\",\"sha\":\"\",\"tag\":\"v0.36.1\"},\"initContainers\":[],\"labels\":{},\"listenLocal\":false,\"logFormat\":\"logfmt\",\"logLevel\":\"info\",\"nodeSelector\":{},\"objectStorageConfig\":{\"existingSecret\":{},\"secret\":{}},\"paused\":false,\"podAntiAffinity\":\"\",\"podAntiAffinityTopologyKey\":\"kubernetes.io/hostname\",\"podMetadata\":{},\"portName\":\"web\",\"priorityClassName\":\"\",\"queryConfig\":{\"existingSecret\":{},\"secret\":{}},\"queryEndpoints\":[],\"replicas\":1,\"resources\":{},\"retention\":\"24h\",\"routePrefix\":\"/\",\"ruleNamespaceSelector\":{},\"ruleSelector\":{},\"ruleSelectorNilUsesHelmValues\":true,\"securityContext\":{\"fsGroup\":2000,\"runAsGroup\":2000,\"runAsNonRoot\":true,\"runAsUser\":1000,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"storage\":{},\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[],\"volumes\":[],\"web\":{}}},\"windowsMonitoring\":{\"enabled\":false}}",
                "version": "45.7.1"
              }
            ],
            "name": "prometheus",
            "namespace": "prometheus",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://prometheus-community.github.io/helm-charts",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [
              {
                "name": "podSecurityPolicy.enabled",
                "type": "",
                "value": "true"
              },
              {
                "name": "server.persistentVolume.enabled",
                "type": "",
                "value": "false"
              },
              {
                "name": "server\\.resources",
                "type": "",
                "value": "\"limits\":\n  \"cpu\": \"200m\"\n  \"memory\": \"50Mi\"\n\"requests\":\n  \"cpu\": \"100m\"\n  \"memory\": \"30Mi\"\n"
              }
            ],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 2000,
            "upgrade_install": null,
            "values": [
              "# Default values for kube-prometheus-stack.\r\n# This is a YAML-formatted file.\r\n# Declare variables to be passed into your templates.\r\n\r\n## Provide a name in place of kube-prometheus-stack for `app:` labels\r\n##\r\nnameOverride: \"\"\r\n\r\n## Override the deployment namespace\r\n##\r\nnamespaceOverride: \"\"\r\n\r\n## Provide a k8s version to auto dashboard import script example: kubeTargetVersionOverride: 1.26.6\r\n##\r\nkubeTargetVersionOverride: \"\"\r\n\r\n## Allow kubeVersion to be overridden while creating the ingress\r\n##\r\nkubeVersionOverride: \"\"\r\n\r\n## Provide a name to substitute for the full names of resources\r\n##\r\nfullnameOverride: \"\"\r\n\r\n## Labels to apply to all resources\r\n##\r\ncommonLabels: {}\r\n# scmhash: abc123\r\n# myLabel: aakkmd\r\n\r\n## Install Prometheus Operator CRDs\r\n##\r\ncrds:\r\n  enabled: true\r\n\r\n## custom Rules to override \"for\" and \"severity\" in defaultRules\r\n##\r\ncustomRules: {}\r\n  # AlertmanagerFailedReload:\r\n  #   for: 3m\r\n  # AlertmanagerMembersInconsistent:\r\n  #   for: 5m\r\n  #   severity: \"warning\"\r\n\r\n## Create default rules for monitoring the cluster\r\n##\r\ndefaultRules:\r\n  create: true\r\n  rules:\r\n    alertmanager: true\r\n    etcd: true\r\n    configReloaders: true\r\n    general: true\r\n    k8sContainerCpuUsageSecondsTotal: true\r\n    k8sContainerMemoryCache: true\r\n    k8sContainerMemoryRss: true\r\n    k8sContainerMemorySwap: true\r\n    k8sContainerResource: true\r\n    k8sContainerMemoryWorkingSetBytes: true\r\n    k8sPodOwner: true\r\n    kubeApiserverAvailability: true\r\n    kubeApiserverBurnrate: true\r\n    kubeApiserverHistogram: true\r\n    kubeApiserverSlos: true\r\n    kubeControllerManager: true\r\n    kubelet: true\r\n    kubeProxy: true\r\n    kubePrometheusGeneral: true\r\n    kubePrometheusNodeRecording: true\r\n    kubernetesApps: true\r\n    kubernetesResources: true\r\n    kubernetesStorage: true\r\n    kubernetesSystem: true\r\n    kubeSchedulerAlerting: true\r\n    kubeSchedulerRecording: true\r\n    kubeStateMetrics: true\r\n    network: true\r\n    node: true\r\n    nodeExporterAlerting: true\r\n    nodeExporterRecording: true\r\n    prometheus: true\r\n    prometheusOperator: true\r\n    windows: true\r\n\r\n  ## Reduce app namespace alert scope\r\n  appNamespacesTarget: \".*\"\r\n\r\n  ## Set keep_firing_for for all alerts\r\n  keepFiringFor: \"\"\r\n\r\n  ## Labels for default rules\r\n  labels: {}\r\n  ## Annotations for default rules\r\n  annotations: {}\r\n\r\n  ## Additional labels for PrometheusRule alerts\r\n  additionalRuleLabels: {}\r\n\r\n  ## Additional annotations for PrometheusRule alerts\r\n  additionalRuleAnnotations: {}\r\n\r\n  ## Additional labels for specific PrometheusRule alert groups\r\n  additionalRuleGroupLabels:\r\n    alertmanager: {}\r\n    etcd: {}\r\n    configReloaders: {}\r\n    general: {}\r\n    k8sContainerCpuUsageSecondsTotal: {}\r\n    k8sContainerMemoryCache: {}\r\n    k8sContainerMemoryRss: {}\r\n    k8sContainerMemorySwap: {}\r\n    k8sContainerResource: {}\r\n    k8sPodOwner: {}\r\n    kubeApiserverAvailability: {}\r\n    kubeApiserverBurnrate: {}\r\n    kubeApiserverHistogram: {}\r\n    kubeApiserverSlos: {}\r\n    kubeControllerManager: {}\r\n    kubelet: {}\r\n    kubeProxy: {}\r\n    kubePrometheusGeneral: {}\r\n    kubePrometheusNodeRecording: {}\r\n    kubernetesApps: {}\r\n    kubernetesResources: {}\r\n    kubernetesStorage: {}\r\n    kubernetesSystem: {}\r\n    kubeSchedulerAlerting: {}\r\n    kubeSchedulerRecording: {}\r\n    kubeStateMetrics: {}\r\n    network: {}\r\n    node: {}\r\n    nodeExporterAlerting: {}\r\n    nodeExporterRecording: {}\r\n    prometheus: {}\r\n    prometheusOperator: {}\r\n\r\n  ## Additional annotations for specific PrometheusRule alerts groups\r\n  additionalRuleGroupAnnotations:\r\n    alertmanager: {}\r\n    etcd: {}\r\n    configReloaders: {}\r\n    general: {}\r\n    k8sContainerCpuUsageSecondsTotal: {}\r\n    k8sContainerMemoryCache: {}\r\n    k8sContainerMemoryRss: {}\r\n    k8sContainerMemorySwap: {}\r\n    k8sContainerResource: {}\r\n    k8sPodOwner: {}\r\n    kubeApiserverAvailability: {}\r\n    kubeApiserverBurnrate: {}\r\n    kubeApiserverHistogram: {}\r\n    kubeApiserverSlos: {}\r\n    kubeControllerManager: {}\r\n    kubelet: {}\r\n    kubeProxy: {}\r\n    kubePrometheusGeneral: {}\r\n    kubePrometheusNodeRecording: {}\r\n    kubernetesApps: {}\r\n    kubernetesResources: {}\r\n    kubernetesStorage: {}\r\n    kubernetesSystem: {}\r\n    kubeSchedulerAlerting: {}\r\n    kubeSchedulerRecording: {}\r\n    kubeStateMetrics: {}\r\n    network: {}\r\n    node: {}\r\n    nodeExporterAlerting: {}\r\n    nodeExporterRecording: {}\r\n    prometheus: {}\r\n    prometheusOperator: {}\r\n\r\n  additionalAggregationLabels: []\r\n\r\n  ## Prefix for runbook URLs. Use this to override the first part of the runbookURLs that is common to all rules.\r\n  runbookUrl: \"https://runbooks.prometheus-operator.dev/runbooks\"\r\n\r\n  node:\r\n    fsSelector: 'fstype!=\"\"'\r\n    # fsSelector: 'fstype=~\"ext[234]|btrfs|xfs|zfs\"'\r\n\r\n  ## Disabled PrometheusRule alerts\r\n  disabled: {}\r\n  # KubeAPIDown: true\r\n  # NodeRAIDDegraded: true\r\n\r\n## Deprecated way to provide custom recording or alerting rules to be deployed into the cluster.\r\n##\r\n# additionalPrometheusRules: []\r\n#  - name: my-rule-file\r\n#    groups:\r\n#      - name: my_group\r\n#        rules:\r\n#        - record: my_record\r\n#          expr: 100 * my_record\r\n\r\n## Provide custom recording or alerting rules to be deployed into the cluster.\r\n##\r\nadditionalPrometheusRulesMap: {}\r\n#  rule-name:\r\n#    groups:\r\n#    - name: my_group\r\n#      rules:\r\n#      - record: my_record\r\n#        expr: 100 * my_record\r\n\r\n##\r\nglobal:\r\n  rbac:\r\n    create: true\r\n\r\n    ## Create ClusterRoles that extend the existing view, edit and admin ClusterRoles to interact with prometheus-operator CRDs\r\n    ## Ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles\r\n    createAggregateClusterRoles: false\r\n    pspEnabled: false\r\n    pspAnnotations: {}\r\n      ## Specify pod annotations\r\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\r\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\r\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\r\n      ##\r\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\r\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\r\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\r\n\r\n  ## Global image registry to use if it needs to be overriden for some specific use cases (e.g local registries, custom images, ...)\r\n  ##\r\n  imageRegistry: \"\"\r\n\r\n  ## Reference to one or more secrets to be used when pulling images\r\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\r\n  ##\r\n  imagePullSecrets: []\r\n  # - name: \"image-pull-secret\"\r\n  # or\r\n  # - \"image-pull-secret\"\r\n\r\nwindowsMonitoring:\r\n  ## Deploys the windows-exporter and Windows-specific dashboards and rules (job name must be 'windows-exporter')\r\n  enabled: false\r\n\r\n## Configuration for prometheus-windows-exporter\r\n## ref: https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus-windows-exporter\r\n##\r\nprometheus-windows-exporter:\r\n  ## Enable ServiceMonitor and set Kubernetes label to use as a job label\r\n  ##\r\n  prometheus:\r\n    monitor:\r\n      enabled: true\r\n      jobLabel: jobLabel\r\n\r\n  releaseLabel: true\r\n\r\n  ## Set job label to 'windows-exporter' as required by the default Prometheus rules and Grafana dashboards\r\n  ##\r\n  podLabels:\r\n    jobLabel: windows-exporter\r\n\r\n  ## Enable memory and container metrics as required by the default Prometheus rules and Grafana dashboards\r\n  ##\r\n  config: |-\r\n    collectors:\r\n      enabled: '[defaults],memory,container'\r\n\r\n## Configuration for alertmanager\r\n## ref: https://prometheus.io/docs/alerting/alertmanager/\r\n##\r\nalertmanager:\r\n\r\n  ## Deploy alertmanager\r\n  ##\r\n  enabled: true\r\n\r\n  ## Annotations for Alertmanager\r\n  ##\r\n  annotations: {}\r\n\r\n  ## Api that prometheus will use to communicate with alertmanager. Possible values are v1, v2\r\n  ##\r\n  apiVersion: v2\r\n\r\n  ## @param alertmanager.enableFeatures Enable access to Alertmanager disabled features.\r\n  ##\r\n  enableFeatures: []\r\n\r\n  ## Service account for Alertmanager to use.\r\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\r\n  ##\r\n  serviceAccount:\r\n    create: true\r\n    name: \"\"\r\n    annotations: {}\r\n    automountServiceAccountToken: true\r\n\r\n  ## Configure pod disruption budgets for Alertmanager\r\n  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget\r\n  ##\r\n  podDisruptionBudget:\r\n    enabled: false\r\n    minAvailable: 1\r\n    maxUnavailable: \"\"\r\n\r\n  ## Alertmanager configuration directives\r\n  ## ref: https://prometheus.io/docs/alerting/configuration/#configuration-file\r\n  ##      https://prometheus.io/webtools/alerting/routing-tree-editor/\r\n  ##\r\n  config:\r\n    global:\r\n      resolve_timeout: 5m\r\n    inhibit_rules:\r\n      - source_matchers:\r\n          - 'severity = critical'\r\n        target_matchers:\r\n          - 'severity =~ warning|info'\r\n        equal:\r\n          - 'namespace'\r\n          - 'alertname'\r\n      - source_matchers:\r\n          - 'severity = warning'\r\n        target_matchers:\r\n          - 'severity = info'\r\n        equal:\r\n          - 'namespace'\r\n          - 'alertname'\r\n      - source_matchers:\r\n          - 'alertname = InfoInhibitor'\r\n        target_matchers:\r\n          - 'severity = info'\r\n        equal:\r\n          - 'namespace'\r\n      - target_matchers:\r\n          - 'alertname = InfoInhibitor'\r\n    route:\r\n      group_by: ['namespace']\r\n      group_wait: 30s\r\n      group_interval: 5m\r\n      repeat_interval: 12h\r\n      receiver: 'null'\r\n      routes:\r\n      - receiver: 'null'\r\n        matchers:\r\n          - alertname = \"Watchdog\"\r\n    receivers:\r\n    - name: 'null'\r\n    templates:\r\n    - '/etc/alertmanager/config/*.tmpl'\r\n\r\n  ## Alertmanager configuration directives (as string type, preferred over the config hash map)\r\n  ## stringConfig will be used only, if tplConfig is true\r\n  ## ref: https://prometheus.io/docs/alerting/configuration/#configuration-file\r\n  ##      https://prometheus.io/webtools/alerting/routing-tree-editor/\r\n  ##\r\n  stringConfig: \"\"\r\n\r\n  ## Pass the Alertmanager configuration directives through Helm's templating\r\n  ## engine. If the Alertmanager configuration contains Alertmanager templates,\r\n  ## they'll need to be properly escaped so that they are not interpreted by\r\n  ## Helm\r\n  ## ref: https://helm.sh/docs/developing_charts/#using-the-tpl-function\r\n  ##      https://prometheus.io/docs/alerting/configuration/#tmpl_string\r\n  ##      https://prometheus.io/docs/alerting/notifications/\r\n  ##      https://prometheus.io/docs/alerting/notification_examples/\r\n  tplConfig: false\r\n\r\n  ## Alertmanager template files to format alerts\r\n  ## By default, templateFiles are placed in /etc/alertmanager/config/ and if\r\n  ## they have a .tmpl file suffix will be loaded. See config.templates above\r\n  ## to change, add other suffixes. If adding other suffixes, be sure to update\r\n  ## config.templates above to include those suffixes.\r\n  ## ref: https://prometheus.io/docs/alerting/notifications/\r\n  ##      https://prometheus.io/docs/alerting/notification_examples/\r\n  ##\r\n  templateFiles: {}\r\n  #\r\n  ## An example template:\r\n  #   template_1.tmpl: |-\r\n  #       {{ define \"cluster\" }}{{ .ExternalURL | reReplaceAll \".*alertmanager\\\\.(.*)\" \"$1\" }}{{ end }}\r\n  #\r\n  #       {{ define \"slack.myorg.text\" }}\r\n  #       {{- $root := . -}}\r\n  #       {{ range .Alerts }}\r\n  #         *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`\r\n  #         *Cluster:* {{ template \"cluster\" $root }}\r\n  #         *Description:* {{ .Annotations.description }}\r\n  #         *Graph:* \u003c{{ .GeneratorURL }}|:chart_with_upwards_trend:\u003e\r\n  #         *Runbook:* \u003c{{ .Annotations.runbook }}|:spiral_note_pad:\u003e\r\n  #         *Details:*\r\n  #           {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`\r\n  #           {{ end }}\r\n  #       {{ end }}\r\n  #       {{ end }}\r\n\r\n  ingress:\r\n    enabled: false\r\n\r\n    # For Kubernetes \u003e= 1.18 you should specify the ingress-controller via the field ingressClassName\r\n    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\r\n    # ingressClassName: nginx\r\n\r\n    annotations: {}\r\n\r\n    labels: {}\r\n\r\n    ## Override ingress to a different defined port on the service\r\n    # servicePort: 8081\r\n    ## Override ingress to a different service then the default, this is useful if you need to\r\n    ## point to a specific instance of the alertmanager (eg kube-prometheus-stack-alertmanager-0)\r\n    # serviceName: kube-prometheus-stack-alertmanager-0\r\n\r\n    ## Hosts must be provided if Ingress is enabled.\r\n    ##\r\n    hosts: []\r\n      # - alertmanager.domain.com\r\n\r\n    ## Paths to use for ingress rules - one path should match the alertmanagerSpec.routePrefix\r\n    ##\r\n    paths: []\r\n    # - /\r\n\r\n    ## For Kubernetes \u003e= 1.18 you should specify the pathType (determines how Ingress paths should be matched)\r\n    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types\r\n    # pathType: ImplementationSpecific\r\n\r\n    ## TLS configuration for Alertmanager Ingress\r\n    ## Secret must be manually created in the namespace\r\n    ##\r\n    tls: []\r\n    # - secretName: alertmanager-general-tls\r\n    #   hosts:\r\n    #   - alertmanager.example.com\r\n\r\n  ## Configuration for Alertmanager secret\r\n  ##\r\n  secret:\r\n    annotations: {}\r\n\r\n  ## Configuration for creating an Ingress that will map to each Alertmanager replica service\r\n  ## alertmanager.servicePerReplica must be enabled\r\n  ##\r\n  ingressPerReplica:\r\n    enabled: false\r\n\r\n    # For Kubernetes \u003e= 1.18 you should specify the ingress-controller via the field ingressClassName\r\n    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\r\n    # ingressClassName: nginx\r\n\r\n    annotations: {}\r\n    labels: {}\r\n\r\n    ## Final form of the hostname for each per replica ingress is\r\n    ## {{ ingressPerReplica.hostPrefix }}-{{ $replicaNumber }}.{{ ingressPerReplica.hostDomain }}\r\n    ##\r\n    ## Prefix for the per replica ingress that will have `-$replicaNumber`\r\n    ## appended to the end\r\n    hostPrefix: \"\"\r\n    ## Domain that will be used for the per replica ingress\r\n    hostDomain: \"\"\r\n\r\n    ## Paths to use for ingress rules\r\n    ##\r\n    paths: []\r\n    # - /\r\n\r\n    ## For Kubernetes \u003e= 1.18 you should specify the pathType (determines how Ingress paths should be matched)\r\n    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types\r\n    # pathType: ImplementationSpecific\r\n\r\n    ## Secret name containing the TLS certificate for alertmanager per replica ingress\r\n    ## Secret must be manually created in the namespace\r\n    tlsSecretName: \"\"\r\n\r\n    ## Separated secret for each per replica Ingress. Can be used together with cert-manager\r\n    ##\r\n    tlsSecretPerReplica:\r\n      enabled: false\r\n      ## Final form of the secret for each per replica ingress is\r\n      ## {{ tlsSecretPerReplica.prefix }}-{{ $replicaNumber }}\r\n      ##\r\n      prefix: \"alertmanager\"\r\n\r\n  ## Configuration for Alertmanager service\r\n  ##\r\n  service:\r\n    annotations: {}\r\n    labels: {}\r\n    clusterIP: \"\"\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n\r\n    ## Port for Alertmanager Service to listen on\r\n    ##\r\n    port: 9093\r\n    ## To be used with a proxy extraContainer port\r\n    ##\r\n    targetPort: 9093\r\n    ## Port to expose on each node\r\n    ## Only used if service.type is 'NodePort'\r\n    ##\r\n    nodePort: 30903\r\n    ## List of IP addresses at which the Prometheus server service is available\r\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\r\n    ##\r\n\r\n    ## Additional ports to open for Alertmanager service\r\n    ##\r\n    additionalPorts: []\r\n    # - name: oauth-proxy\r\n    #   port: 8081\r\n    #   targetPort: 8081\r\n    # - name: oauth-metrics\r\n    #   port: 8082\r\n    #   targetPort: 8082\r\n\r\n    externalIPs: []\r\n    loadBalancerIP: \"\"\r\n    loadBalancerSourceRanges: []\r\n\r\n    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\r\n    ##\r\n    externalTrafficPolicy: Cluster\r\n\r\n    ## If you want to make sure that connections from a particular client are passed to the same Pod each time\r\n    ## Accepts 'ClientIP' or 'None'\r\n    ##\r\n    sessionAffinity: None\r\n\r\n    ## If you want to modify the ClientIP sessionAffinity timeout\r\n    ## The value must be \u003e0 \u0026\u0026 \u003c=86400(for 1 day) if ServiceAffinity == \"ClientIP\"\r\n    ##\r\n    sessionAffinityConfig:\r\n      clientIP:\r\n        timeoutSeconds: 10800\r\n\r\n    ## Service type\r\n    ##\r\n    type: ClusterIP\r\n\r\n  ## Configuration for creating a separate Service for each statefulset Alertmanager replica\r\n  ##\r\n  servicePerReplica:\r\n    enabled: false\r\n    annotations: {}\r\n\r\n    ## Port for Alertmanager Service per replica to listen on\r\n    ##\r\n    port: 9093\r\n\r\n    ## To be used with a proxy extraContainer port\r\n    targetPort: 9093\r\n\r\n    ## Port to expose on each node\r\n    ## Only used if servicePerReplica.type is 'NodePort'\r\n    ##\r\n    nodePort: 30904\r\n\r\n    ## Loadbalancer source IP ranges\r\n    ## Only used if servicePerReplica.type is \"LoadBalancer\"\r\n    loadBalancerSourceRanges: []\r\n\r\n    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\r\n    ##\r\n    externalTrafficPolicy: Cluster\r\n\r\n    ## Service type\r\n    ##\r\n    type: ClusterIP\r\n\r\n  ## Configuration for creating a ServiceMonitor for AlertManager\r\n  ##\r\n  serviceMonitor:\r\n    ## If true, a ServiceMonitor will be created for the AlertManager service.\r\n    ##\r\n    selfMonitor: true\r\n\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n\r\n    ## scheme: HTTP scheme to use for scraping. Can be used with `tlsConfig` for example if using istio mTLS.\r\n    scheme: \"\"\r\n\r\n    ## enableHttp2: Whether to enable HTTP2.\r\n    ## See https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#endpoint\r\n    enableHttp2: true\r\n\r\n    ## tlsConfig: TLS configuration to use when scraping the endpoint. For example if using istio mTLS.\r\n    ## Of type: https://github.com/coreos/prometheus-operator/blob/main/Documentation/api.md#tlsconfig\r\n    tlsConfig: {}\r\n\r\n    bearerTokenFile:\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## Additional Endpoints\r\n    ##\r\n    additionalEndpoints: []\r\n    # - port: oauth-metrics\r\n    #   path: /metrics\r\n\r\n  ## Settings affecting alertmanagerSpec\r\n  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#alertmanagerspec\r\n  ##\r\n  alertmanagerSpec:\r\n    ## Standard object's metadata. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata\r\n    ## Metadata Labels and Annotations gets propagated to the Alertmanager pods.\r\n    ##\r\n    podMetadata: {}\r\n\r\n    ## Image of Alertmanager\r\n    ##\r\n    image:\r\n      registry: quay.io\r\n      repository: prometheus/alertmanager\r\n      tag: v0.27.0\r\n      sha: \"\"\r\n\r\n    ## If true then the user will be responsible to provide a secret with alertmanager configuration\r\n    ## So when true the config part will be ignored (including templateFiles) and the one in the secret will be used\r\n    ##\r\n    useExistingSecret: false\r\n\r\n    ## Secrets is a list of Secrets in the same namespace as the Alertmanager object, which shall be mounted into the\r\n    ## Alertmanager Pods. The Secrets are mounted into /etc/alertmanager/secrets/.\r\n    ##\r\n    secrets: []\r\n\r\n    ## If false then the user will opt out of automounting API credentials.\r\n    ##\r\n    automountServiceAccountToken: true\r\n\r\n    ## ConfigMaps is a list of ConfigMaps in the same namespace as the Alertmanager object, which shall be mounted into the Alertmanager Pods.\r\n    ## The ConfigMaps are mounted into /etc/alertmanager/configmaps/.\r\n    ##\r\n    configMaps: []\r\n\r\n    ## ConfigSecret is the name of a Kubernetes Secret in the same namespace as the Alertmanager object, which contains configuration for\r\n    ## this Alertmanager instance. Defaults to 'alertmanager-' The secret is mounted into /etc/alertmanager/config.\r\n    ##\r\n    # configSecret:\r\n\r\n    ## WebTLSConfig defines the TLS parameters for HTTPS\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#alertmanagerwebspec\r\n    web: {}\r\n\r\n    ## AlertmanagerConfigs to be selected to merge and configure Alertmanager with.\r\n    ##\r\n    alertmanagerConfigSelector: {}\r\n    ## Example which selects all alertmanagerConfig resources\r\n    ## with label \"alertconfig\" with values any of \"example-config\" or \"example-config-2\"\r\n    # alertmanagerConfigSelector:\r\n    #   matchExpressions:\r\n    #     - key: alertconfig\r\n    #       operator: In\r\n    #       values:\r\n    #         - example-config\r\n    #         - example-config-2\r\n    #\r\n    ## Example which selects all alertmanagerConfig resources with label \"role\" set to \"example-config\"\r\n    # alertmanagerConfigSelector:\r\n    #   matchLabels:\r\n    #     role: example-config\r\n\r\n    ## Namespaces to be selected for AlertmanagerConfig discovery. If nil, only check own namespace.\r\n    ##\r\n    alertmanagerConfigNamespaceSelector: {}\r\n    ## Example which selects all namespaces\r\n    ## with label \"alertmanagerconfig\" with values any of \"example-namespace\" or \"example-namespace-2\"\r\n    # alertmanagerConfigNamespaceSelector:\r\n    #   matchExpressions:\r\n    #     - key: alertmanagerconfig\r\n    #       operator: In\r\n    #       values:\r\n    #         - example-namespace\r\n    #         - example-namespace-2\r\n\r\n    ## Example which selects all namespaces with label \"alertmanagerconfig\" set to \"enabled\"\r\n    # alertmanagerConfigNamespaceSelector:\r\n    #   matchLabels:\r\n    #     alertmanagerconfig: enabled\r\n\r\n    ## AlermanagerConfig to be used as top level configuration\r\n    ##\r\n    alertmanagerConfiguration: {}\r\n    ## Example with select a global alertmanagerconfig\r\n    # alertmanagerConfiguration:\r\n    #   name: global-alertmanager-Configuration\r\n\r\n    ## Defines the strategy used by AlertmanagerConfig objects to match alerts. eg:\r\n    ##\r\n    alertmanagerConfigMatcherStrategy: {}\r\n    ## Example with use OnNamespace strategy\r\n    # alertmanagerConfigMatcherStrategy:\r\n    #   type: OnNamespace\r\n\r\n    ## Define Log Format\r\n    # Use logfmt (default) or json logging\r\n    logFormat: logfmt\r\n\r\n    ## Log level for Alertmanager to be configured with.\r\n    ##\r\n    logLevel: info\r\n\r\n    ## Size is the expected size of the alertmanager cluster. The controller will eventually make the size of the\r\n    ## running cluster equal to the expected size.\r\n    replicas: 1\r\n\r\n    ## Time duration Alertmanager shall retain data for. Default is '120h', and must match the regular expression\r\n    ## [0-9]+(ms|s|m|h) (milliseconds seconds minutes hours).\r\n    ##\r\n    retention: 120h\r\n\r\n    ## Storage is the definition of how storage will be used by the Alertmanager instances.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md\r\n    ##\r\n    storage: {}\r\n    # volumeClaimTemplate:\r\n    #   spec:\r\n    #     storageClassName: gluster\r\n    #     accessModes: [\"ReadWriteOnce\"]\r\n    #     resources:\r\n    #       requests:\r\n    #         storage: 50Gi\r\n    #     selector: {}\r\n\r\n\r\n    ## The external URL the Alertmanager instances will be available under. This is necessary to generate correct URLs. This is necessary if Alertmanager is not served from root of a DNS name. string  false\r\n    ##\r\n    externalUrl:\r\n\r\n    ## The route prefix Alertmanager registers HTTP handlers for. This is useful, if using ExternalURL and a proxy is rewriting HTTP routes of a request, and the actual ExternalURL is still true,\r\n    ## but the server serves requests under a different route prefix. For example for use with kubectl proxy.\r\n    ##\r\n    routePrefix: /\r\n\r\n    ## scheme: HTTP scheme to use. Can be used with `tlsConfig` for example if using istio mTLS.\r\n    scheme: \"\"\r\n\r\n    ## tlsConfig: TLS configuration to use when connect to the endpoint. For example if using istio mTLS.\r\n    ## Of type: https://github.com/coreos/prometheus-operator/blob/main/Documentation/api.md#tlsconfig\r\n    tlsConfig: {}\r\n\r\n    ## If set to true all actions on the underlying managed objects are not going to be performed, except for delete actions.\r\n    ##\r\n    paused: false\r\n\r\n    ## Define which Nodes the Pods are scheduled on.\r\n    ## ref: https://kubernetes.io/docs/user-guide/node-selection/\r\n    ##\r\n    nodeSelector: {}\r\n\r\n    ## Define resources requests and limits for single Pods.\r\n    ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\r\n    ##\r\n    resources: {}\r\n    # requests:\r\n    #   memory: 400Mi\r\n\r\n    ## Pod anti-affinity can prevent the scheduler from placing Prometheus replicas on the same node.\r\n    ## The default value \"soft\" means that the scheduler should *prefer* to not schedule two replica pods onto the same node but no guarantee is provided.\r\n    ## The value \"hard\" means that the scheduler is *required* to not schedule two replica pods onto the same node.\r\n    ## The value \"\" will disable pod anti-affinity so that no anti-affinity rules will be configured.\r\n    ##\r\n    podAntiAffinity: \"\"\r\n\r\n    ## If anti-affinity is enabled sets the topologyKey to use for anti-affinity.\r\n    ## This can be changed to, for example, failure-domain.beta.kubernetes.io/zone\r\n    ##\r\n    podAntiAffinityTopologyKey: kubernetes.io/hostname\r\n\r\n    ## Assign custom affinity rules to the alertmanager instance\r\n    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\r\n    ##\r\n    affinity: {}\r\n    # nodeAffinity:\r\n    #   requiredDuringSchedulingIgnoredDuringExecution:\r\n    #     nodeSelectorTerms:\r\n    #     - matchExpressions:\r\n    #       - key: kubernetes.io/e2e-az-name\r\n    #         operator: In\r\n    #         values:\r\n    #         - e2e-az1\r\n    #         - e2e-az2\r\n\r\n    ## If specified, the pod's tolerations.\r\n    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\r\n    ##\r\n    tolerations: []\r\n    # - key: \"key\"\r\n    #   operator: \"Equal\"\r\n    #   value: \"value\"\r\n    #   effect: \"NoSchedule\"\r\n\r\n    ## If specified, the pod's topology spread constraints.\r\n    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\r\n    ##\r\n    topologySpreadConstraints: []\r\n    # - maxSkew: 1\r\n    #   topologyKey: topology.kubernetes.io/zone\r\n    #   whenUnsatisfiable: DoNotSchedule\r\n    #   labelSelector:\r\n    #     matchLabels:\r\n    #       app: alertmanager\r\n\r\n    ## SecurityContext holds pod-level security attributes and common container settings.\r\n    ## This defaults to non root user with uid 1000 and gid 2000. *v1.PodSecurityContext  false\r\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\r\n    ##\r\n    securityContext:\r\n      runAsGroup: 2000\r\n      runAsNonRoot: true\r\n      runAsUser: 1000\r\n      fsGroup: 2000\r\n      seccompProfile:\r\n        type: RuntimeDefault\r\n\r\n    ## ListenLocal makes the Alertmanager server listen on loopback, so that it does not bind against the Pod IP.\r\n    ## Note this is only for the Alertmanager UI, not the gossip communication.\r\n    ##\r\n    listenLocal: false\r\n\r\n    ## Containers allows injecting additional containers. This is meant to allow adding an authentication proxy to an Alertmanager pod.\r\n    ##\r\n    containers: []\r\n    # containers:\r\n    # - name: oauth-proxy\r\n    #   image: quay.io/oauth2-proxy/oauth2-proxy:v7.5.1\r\n    #   args:\r\n    #   - --upstream=http://127.0.0.1:9093\r\n    #   - --http-address=0.0.0.0:8081\r\n    #   - --metrics-address=0.0.0.0:8082\r\n    #   - ...\r\n    #   ports:\r\n    #   - containerPort: 8081\r\n    #     name: oauth-proxy\r\n    #     protocol: TCP\r\n    #   - containerPort: 8082\r\n    #     name: oauth-metrics\r\n    #     protocol: TCP\r\n    #   resources: {}\r\n\r\n    # Additional volumes on the output StatefulSet definition.\r\n    volumes: []\r\n\r\n    # Additional VolumeMounts on the output StatefulSet definition.\r\n    volumeMounts: []\r\n\r\n    ## InitContainers allows injecting additional initContainers. This is meant to allow doing some changes\r\n    ## (permissions, dir tree) on mounted volumes before starting prometheus\r\n    initContainers: []\r\n\r\n    ## Priority class assigned to the Pods\r\n    ##\r\n    priorityClassName: \"\"\r\n\r\n    ## AdditionalPeers allows injecting a set of additional Alertmanagers to peer with to form a highly available cluster.\r\n    ##\r\n    additionalPeers: []\r\n\r\n    ## PortName to use for Alert Manager.\r\n    ##\r\n    portName: \"http-web\"\r\n\r\n    ## ClusterAdvertiseAddress is the explicit address to advertise in cluster. Needs to be provided for non RFC1918 [1] (public) addresses. [1] RFC1918: https://tools.ietf.org/html/rfc1918\r\n    ##\r\n    clusterAdvertiseAddress: false\r\n\r\n    ## clusterGossipInterval determines interval between gossip attempts.\r\n    ## Needs to be specified as GoDuration, a time duration that can be parsed by Gos time.ParseDuration() (e.g. 45ms, 30s, 1m, 1h20m15s)\r\n    clusterGossipInterval: \"\"\r\n\r\n    ## clusterPeerTimeout determines timeout for cluster peering.\r\n    ## Needs to be specified as GoDuration, a time duration that can be parsed by Gos time.ParseDuration() (e.g. 45ms, 30s, 1m, 1h20m15s)\r\n    clusterPeerTimeout: \"\"\r\n\r\n    ## clusterPushpullInterval determines interval between pushpull attempts.\r\n    ## Needs to be specified as GoDuration, a time duration that can be parsed by Gos time.ParseDuration() (e.g. 45ms, 30s, 1m, 1h20m15s)\r\n    clusterPushpullInterval: \"\"\r\n\r\n    ## ForceEnableClusterMode ensures Alertmanager does not deactivate the cluster mode when running with a single replica.\r\n    ## Use case is e.g. spanning an Alertmanager cluster across Kubernetes clusters with a single replica in each.\r\n    forceEnableClusterMode: false\r\n\r\n    ## Minimum number of seconds for which a newly created pod should be ready without any of its container crashing for it to\r\n    ## be considered available. Defaults to 0 (pod will be considered available as soon as it is ready).\r\n    minReadySeconds: 0\r\n\r\n    ## Additional configuration which is not covered by the properties above. (passed through tpl)\r\n    additionalConfig: {}\r\n\r\n    ## Additional configuration which is not covered by the properties above.\r\n    ## Useful, if you need advanced templating inside alertmanagerSpec.\r\n    ## Otherwise, use alertmanager.alertmanagerSpec.additionalConfig (passed through tpl)\r\n    additionalConfigString: \"\"\r\n\r\n  ## ExtraSecret can be used to store various data in an extra secret\r\n  ## (use it for example to store hashed basic auth credentials)\r\n  extraSecret:\r\n    ## if not set, name will be auto generated\r\n    # name: \"\"\r\n    annotations: {}\r\n    data: {}\r\n  #   auth: |\r\n  #     foo:$apr1$OFG3Xybp$ckL0FHDAkoXYIlH9.cysT0\r\n  #     someoneelse:$apr1$DMZX2Z4q$6SbQIfyuLQd.xmo/P0m2c.\r\n\r\n## Using default values from https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml\r\n##\r\ngrafana:\r\n  enabled: true\r\n  namespaceOverride: \"\"\r\n\r\n  ## ForceDeployDatasources Create datasource configmap even if grafana deployment has been disabled\r\n  ##\r\n  forceDeployDatasources: false\r\n\r\n  ## ForceDeployDashboard Create dashboard configmap even if grafana deployment has been disabled\r\n  ##\r\n  forceDeployDashboards: false\r\n\r\n  ## Deploy default dashboards\r\n  ##\r\n  defaultDashboardsEnabled: true\r\n\r\n  ## Timezone for the default dashboards\r\n  ## Other options are: browser or a specific timezone, i.e. Europe/Luxembourg\r\n  ##\r\n  defaultDashboardsTimezone: utc\r\n\r\n  ## Editable flag for the default dashboards\r\n  ##\r\n  defaultDashboardsEditable: true\r\n\r\n  adminPassword: prom-operator\r\n\r\n  rbac:\r\n    ## If true, Grafana PSPs will be created\r\n    ##\r\n    pspEnabled: false\r\n\r\n  ingress:\r\n    ## If true, Grafana Ingress will be created\r\n    ##\r\n    enabled: false\r\n\r\n    ## IngressClassName for Grafana Ingress.\r\n    ## Should be provided if Ingress is enable.\r\n    ##\r\n    # ingressClassName: nginx\r\n\r\n    ## Annotations for Grafana Ingress\r\n    ##\r\n    annotations: {}\r\n      # kubernetes.io/ingress.class: nginx\r\n      # kubernetes.io/tls-acme: \"true\"\r\n\r\n    ## Labels to be added to the Ingress\r\n    ##\r\n    labels: {}\r\n\r\n    ## Hostnames.\r\n    ## Must be provided if Ingress is enable.\r\n    ##\r\n    # hosts:\r\n    #   - grafana.domain.com\r\n    hosts: []\r\n\r\n    ## Path for grafana ingress\r\n    path: /\r\n\r\n    ## TLS configuration for grafana Ingress\r\n    ## Secret must be manually created in the namespace\r\n    ##\r\n    tls: []\r\n    # - secretName: grafana-general-tls\r\n    #   hosts:\r\n    #   - grafana.example.com\r\n\r\n  # # To make Grafana persistent (Using Statefulset)\r\n  # #\r\n  # persistence:\r\n  #   enabled: true\r\n  #   type: sts\r\n  #   storageClassName: \"storageClassName\"\r\n  #   accessModes:\r\n  #     - ReadWriteOnce\r\n  #   size: 20Gi\r\n  #   finalizers:\r\n  #     - kubernetes.io/pvc-protection\r\n\r\n  serviceAccount:\r\n    create: true\r\n    autoMount: true\r\n\r\n  sidecar:\r\n    dashboards:\r\n      enabled: true\r\n      label: grafana_dashboard\r\n      labelValue: \"1\"\r\n      # Allow discovery in all namespaces for dashboards\r\n      searchNamespace: ALL\r\n\r\n      # Support for new table panels, when enabled grafana auto migrates the old table panels to newer table panels\r\n      enableNewTablePanelSyntax: false\r\n\r\n      ## Annotations for Grafana dashboard configmaps\r\n      ##\r\n      annotations: {}\r\n      multicluster:\r\n        global:\r\n          enabled: false\r\n        etcd:\r\n          enabled: false\r\n      provider:\r\n        allowUiUpdates: false\r\n    datasources:\r\n      enabled: true\r\n      defaultDatasourceEnabled: true\r\n      isDefaultDatasource: true\r\n\r\n      name: Prometheus\r\n      uid: prometheus\r\n\r\n      ## URL of prometheus datasource\r\n      ##\r\n      # url: http://prometheus-stack-prometheus:9090/\r\n\r\n      ## Prometheus request timeout in seconds\r\n      # timeout: 30\r\n\r\n      # If not defined, will use prometheus.prometheusSpec.scrapeInterval or its default\r\n      # defaultDatasourceScrapeInterval: 15s\r\n\r\n      ## Annotations for Grafana datasource configmaps\r\n      ##\r\n      annotations: {}\r\n\r\n      ## Set method for HTTP to send query to datasource\r\n      httpMethod: POST\r\n\r\n      ## Create datasource for each Pod of Prometheus StatefulSet;\r\n      ## this uses headless service `prometheus-operated` which is\r\n      ## created by Prometheus Operator\r\n      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/0fee93e12dc7c2ea1218f19ae25ec6b893460590/pkg/prometheus/statefulset.go#L255-L286\r\n      createPrometheusReplicasDatasources: false\r\n      label: grafana_datasource\r\n      labelValue: \"1\"\r\n\r\n      ## Field with internal link pointing to existing data source in Grafana.\r\n      ## Can be provisioned via additionalDataSources\r\n      exemplarTraceIdDestinations: {}\r\n        # datasourceUid: Jaeger\r\n        # traceIdLabelName: trace_id\r\n      alertmanager:\r\n        enabled: true\r\n        name: Alertmanager\r\n        uid: alertmanager\r\n        handleGrafanaManagedAlerts: false\r\n        implementation: prometheus\r\n\r\n  extraConfigmapMounts: []\r\n  # - name: certs-configmap\r\n  #   mountPath: /etc/grafana/ssl/\r\n  #   configMap: certs-configmap\r\n  #   readOnly: true\r\n\r\n  deleteDatasources: []\r\n  # - name: example-datasource\r\n  #   orgId: 1\r\n\r\n  ## Configure additional grafana datasources (passed through tpl)\r\n  ## ref: http://docs.grafana.org/administration/provisioning/#datasources\r\n  additionalDataSources: []\r\n  # - name: prometheus-sample\r\n  #   access: proxy\r\n  #   basicAuth: true\r\n  #   basicAuthPassword: pass\r\n  #   basicAuthUser: daco\r\n  #   editable: false\r\n  #   jsonData:\r\n  #       tlsSkipVerify: true\r\n  #   orgId: 1\r\n  #   type: prometheus\r\n  #   url: https://{{ printf \"%s-prometheus.svc\" .Release.Name }}:9090\r\n  #   version: 1\r\n\r\n  # Flag to mark provisioned data sources for deletion if they are no longer configured.\r\n  # It takes no effect if data sources are already listed in the deleteDatasources section.\r\n  # ref: https://grafana.com/docs/grafana/latest/administration/provisioning/#example-data-source-config-file\r\n  prune: false\r\n\r\n  ## Passed to grafana subchart and used by servicemonitor below\r\n  ##\r\n  service:\r\n    portName: http-web\r\n    ipFamilies: []\r\n    ipFamilyPolicy: \"\"\r\n\r\n  serviceMonitor:\r\n    # If true, a ServiceMonitor CRD is created for a prometheus operator\r\n    # https://github.com/coreos/prometheus-operator\r\n    #\r\n    enabled: true\r\n\r\n    # Path to use for scraping metrics. Might be different if server.root_url is set\r\n    # in grafana.ini\r\n    path: \"/metrics\"\r\n\r\n    #  namespace: monitoring  (defaults to use the namespace this chart is deployed to)\r\n\r\n    # labels for the ServiceMonitor\r\n    labels: {}\r\n\r\n    # Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    #\r\n    interval: \"\"\r\n    scheme: http\r\n    tlsConfig: {}\r\n    scrapeTimeout: 30s\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n## Flag to disable all the kubernetes component scrapers\r\n##\r\nkubernetesServiceMonitors:\r\n  enabled: true\r\n\r\n## Component scraping the kube api server\r\n##\r\nkubeApiServer:\r\n  enabled: true\r\n  tlsConfig:\r\n    serverName: kubernetes\r\n    insecureSkipVerify: false\r\n  serviceMonitor:\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n\r\n    jobLabel: component\r\n    selector:\r\n      matchLabels:\r\n        component: apiserver\r\n        provider: kubernetes\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings:\r\n      # Drop excessively noisy apiserver buckets.\r\n      - action: drop\r\n        regex: apiserver_request_duration_seconds_bucket;(0.15|0.2|0.3|0.35|0.4|0.45|0.6|0.7|0.8|0.9|1.25|1.5|1.75|2|3|3.5|4|4.5|6|7|8|9|15|25|40|50)\r\n        sourceLabels:\r\n          - __name__\r\n          - le\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels:\r\n    #     - __meta_kubernetes_namespace\r\n    #     - __meta_kubernetes_service_name\r\n    #     - __meta_kubernetes_endpoint_port_name\r\n    #   action: keep\r\n    #   regex: default;kubernetes;https\r\n    # - targetLabel: __address__\r\n    #   replacement: kubernetes.default.svc:443\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n    #  foo: bar\r\n\r\n## Component scraping the kubelet and kubelet-hosted cAdvisor\r\n##\r\nkubelet:\r\n  enabled: true\r\n  namespace: kube-system\r\n\r\n  serviceMonitor:\r\n    ## Attach metadata to discovered targets. Requires Prometheus v2.45 for endpoints created by the operator.\r\n    ##\r\n    attachMetadata:\r\n      node: false\r\n\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## If true, Prometheus use (respect) labels provided by exporter.\r\n    ##\r\n    honorLabels: true\r\n\r\n    ## If true, Prometheus ingests metrics with timestamp provided by exporter. If false, Prometheus ingests metrics with timestamp of scrape.\r\n    ##\r\n    honorTimestamps: true\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n\r\n    ## Enable scraping the kubelet over https. For requirements to enable this see\r\n    ## https://github.com/prometheus-operator/prometheus-operator/issues/926\r\n    ##\r\n    https: true\r\n\r\n    ## Skip TLS certificate validation when scraping.\r\n    ## This is enabled by default because kubelet serving certificate deployed by kubeadm is by default self-signed\r\n    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/#kubelet-serving-certs\r\n    ##\r\n    insecureSkipVerify: true\r\n\r\n    ## Enable scraping /metrics/cadvisor from kubelet's service\r\n    ##\r\n    cAdvisor: true\r\n\r\n    ## Enable scraping /metrics/probes from kubelet's service\r\n    ##\r\n    probes: true\r\n\r\n    ## Enable scraping /metrics/resource from kubelet's service\r\n    ## This is disabled by default because container metrics are already exposed by cAdvisor\r\n    ##\r\n    resource: false\r\n    # From kubernetes 1.18, /metrics/resource/v1alpha1 renamed to /metrics/resource\r\n    resourcePath: \"/metrics/resource/v1alpha1\"\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    cAdvisorMetricRelabelings:\r\n      # Drop less useful container CPU metrics.\r\n      - sourceLabels: [__name__]\r\n        action: drop\r\n        regex: 'container_cpu_(cfs_throttled_seconds_total|load_average_10s|system_seconds_total|user_seconds_total)'\r\n      # Drop less useful container / always zero filesystem metrics.\r\n      - sourceLabels: [__name__]\r\n        action: drop\r\n        regex: 'container_fs_(io_current|io_time_seconds_total|io_time_weighted_seconds_total|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)'\r\n      # Drop less useful / always zero container memory metrics.\r\n      - sourceLabels: [__name__]\r\n        action: drop\r\n        regex: 'container_memory_(mapped_file|swap)'\r\n      # Drop less useful container process metrics.\r\n      - sourceLabels: [__name__]\r\n        action: drop\r\n        regex: 'container_(file_descriptors|tasks_state|threads_max)'\r\n      # Drop container spec metrics that overlap with kube-state-metrics.\r\n      - sourceLabels: [__name__]\r\n        action: drop\r\n        regex: 'container_spec.*'\r\n      # Drop cgroup metrics with no pod.\r\n      - sourceLabels: [id, pod]\r\n        action: drop\r\n        regex: '.+;'\r\n    # - sourceLabels: [__name__, image]\r\n    #   separator: ;\r\n    #   regex: container_([a-z_]+);\r\n    #   replacement: $1\r\n    #   action: drop\r\n    # - sourceLabels: [__name__]\r\n    #   separator: ;\r\n    #   regex: container_(network_tcp_usage_total|network_udp_usage_total|tasks_state|cpu_load_average_10s)\r\n    #   replacement: $1\r\n    #   action: drop\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    probesMetricRelabelings: []\r\n    # - sourceLabels: [__name__, image]\r\n    #   separator: ;\r\n    #   regex: container_([a-z_]+);\r\n    #   replacement: $1\r\n    #   action: drop\r\n    # - sourceLabels: [__name__]\r\n    #   separator: ;\r\n    #   regex: container_(network_tcp_usage_total|network_udp_usage_total|tasks_state|cpu_load_average_10s)\r\n    #   replacement: $1\r\n    #   action: drop\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    ## metrics_path is required to match upstream rules and charts\r\n    cAdvisorRelabelings:\r\n      - action: replace\r\n        sourceLabels: [__metrics_path__]\r\n        targetLabel: metrics_path\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    probesRelabelings:\r\n      - action: replace\r\n        sourceLabels: [__metrics_path__]\r\n        targetLabel: metrics_path\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    resourceRelabelings:\r\n      - action: replace\r\n        sourceLabels: [__metrics_path__]\r\n        targetLabel: metrics_path\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings: []\r\n    # - sourceLabels: [__name__, image]\r\n    #   separator: ;\r\n    #   regex: container_([a-z_]+);\r\n    #   replacement: $1\r\n    #   action: drop\r\n    # - sourceLabels: [__name__]\r\n    #   separator: ;\r\n    #   regex: container_(network_tcp_usage_total|network_udp_usage_total|tasks_state|cpu_load_average_10s)\r\n    #   replacement: $1\r\n    #   action: drop\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    ## metrics_path is required to match upstream rules and charts\r\n    relabelings:\r\n      - action: replace\r\n        sourceLabels: [__metrics_path__]\r\n        targetLabel: metrics_path\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n    #  foo: bar\r\n\r\n## Component scraping the kube controller manager\r\n##\r\nkubeControllerManager:\r\n  enabled: true\r\n\r\n  ## If your kube controller manager is not deployed as a pod, specify IPs it can be found on\r\n  ##\r\n  endpoints: []\r\n  # - 10.141.4.22\r\n  # - 10.141.4.23\r\n  # - 10.141.4.24\r\n\r\n  ## If using kubeControllerManager.endpoints only the port and targetPort are used\r\n  ##\r\n  service:\r\n    enabled: true\r\n    ## If null or unset, the value is determined dynamically based on target Kubernetes version due to change\r\n    ## of default port in Kubernetes 1.22.\r\n    ##\r\n    port: null\r\n    targetPort: null\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n    # selector:\r\n    #   component: kube-controller-manager\r\n\r\n  serviceMonitor:\r\n    enabled: true\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n\r\n    ## port: Name of the port the metrics will be scraped from\r\n    ##\r\n    port: http-metrics\r\n\r\n    jobLabel: jobLabel\r\n    selector: {}\r\n    #  matchLabels:\r\n    #    component: kube-controller-manager\r\n\r\n    ## Enable scraping kube-controller-manager over https.\r\n    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks.\r\n    ## If null or unset, the value is determined dynamically based on target Kubernetes version.\r\n    ##\r\n    https: null\r\n\r\n    # Skip TLS certificate validation when scraping\r\n    insecureSkipVerify: null\r\n\r\n    # Name of the server to use when validating TLS certificate\r\n    serverName: null\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n    #  foo: bar\r\n\r\n## Component scraping coreDns. Use either this or kubeDns\r\n##\r\ncoreDns:\r\n  enabled: true\r\n  service:\r\n    enabled: true\r\n    port: 9153\r\n    targetPort: 9153\r\n\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n    # selector:\r\n    #   k8s-app: kube-dns\r\n  serviceMonitor:\r\n    enabled: true\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n\r\n    ## port: Name of the port the metrics will be scraped from\r\n    ##\r\n    port: http-metrics\r\n\r\n    jobLabel: jobLabel\r\n    selector: {}\r\n    #  matchLabels:\r\n    #    k8s-app: kube-dns\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n    #  foo: bar\r\n\r\n## Component scraping kubeDns. Use either this or coreDns\r\n##\r\nkubeDns:\r\n  enabled: false\r\n  service:\r\n    dnsmasq:\r\n      port: 10054\r\n      targetPort: 10054\r\n    skydns:\r\n      port: 10055\r\n      targetPort: 10055\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n    # selector:\r\n    #   k8s-app: kube-dns\r\n  serviceMonitor:\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n\r\n    jobLabel: jobLabel\r\n    selector: {}\r\n    #  matchLabels:\r\n    #    k8s-app: kube-dns\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    dnsmasqMetricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    dnsmasqRelabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n    #  foo: bar\r\n\r\n## Component scraping etcd\r\n##\r\nkubeEtcd:\r\n  enabled: true\r\n\r\n  ## If your etcd is not deployed as a pod, specify IPs it can be found on\r\n  ##\r\n  endpoints: []\r\n  # - 10.141.4.22\r\n  # - 10.141.4.23\r\n  # - 10.141.4.24\r\n\r\n  ## Etcd service. If using kubeEtcd.endpoints only the port and targetPort are used\r\n  ##\r\n  service:\r\n    enabled: true\r\n    port: 2381\r\n    targetPort: 2381\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n    # selector:\r\n    #   component: etcd\r\n\r\n  ## Configure secure access to the etcd cluster by loading a secret into prometheus and\r\n  ## specifying security configuration below. For example, with a secret named etcd-client-cert\r\n  ##\r\n  ## serviceMonitor:\r\n  ##   scheme: https\r\n  ##   insecureSkipVerify: false\r\n  ##   serverName: localhost\r\n  ##   caFile: /etc/prometheus/secrets/etcd-client-cert/etcd-ca\r\n  ##   certFile: /etc/prometheus/secrets/etcd-client-cert/etcd-client\r\n  ##   keyFile: /etc/prometheus/secrets/etcd-client-cert/etcd-client-key\r\n  ##\r\n  serviceMonitor:\r\n    enabled: true\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n    scheme: http\r\n    insecureSkipVerify: false\r\n    serverName: \"\"\r\n    caFile: \"\"\r\n    certFile: \"\"\r\n    keyFile: \"\"\r\n\r\n    ## port: Name of the port the metrics will be scraped from\r\n    ##\r\n    port: http-metrics\r\n\r\n    jobLabel: jobLabel\r\n    selector: {}\r\n    #  matchLabels:\r\n    #    component: etcd\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n    #  foo: bar\r\n\r\n## Component scraping kube scheduler\r\n##\r\nkubeScheduler:\r\n  enabled: true\r\n\r\n  ## If your kube scheduler is not deployed as a pod, specify IPs it can be found on\r\n  ##\r\n  endpoints: []\r\n  # - 10.141.4.22\r\n  # - 10.141.4.23\r\n  # - 10.141.4.24\r\n\r\n  ## If using kubeScheduler.endpoints only the port and targetPort are used\r\n  ##\r\n  service:\r\n    enabled: true\r\n    ## If null or unset, the value is determined dynamically based on target Kubernetes version due to change\r\n    ## of default port in Kubernetes 1.23.\r\n    ##\r\n    port: null\r\n    targetPort: null\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n    # selector:\r\n    #   component: kube-scheduler\r\n\r\n  serviceMonitor:\r\n    enabled: true\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n    ## Enable scraping kube-scheduler over https.\r\n    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks.\r\n    ## If null or unset, the value is determined dynamically based on target Kubernetes version.\r\n    ##\r\n    https: null\r\n\r\n    ## port: Name of the port the metrics will be scraped from\r\n    ##\r\n    port: http-metrics\r\n\r\n    jobLabel: jobLabel\r\n    selector: {}\r\n    #  matchLabels:\r\n    #    component: kube-scheduler\r\n\r\n    ## Skip TLS certificate validation when scraping\r\n    insecureSkipVerify: null\r\n\r\n    ## Name of the server to use when validating TLS certificate\r\n    serverName: null\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n    #  foo: bar\r\n\r\n## Component scraping kube proxy\r\n##\r\nkubeProxy:\r\n  enabled: true\r\n\r\n  ## If your kube proxy is not deployed as a pod, specify IPs it can be found on\r\n  ##\r\n  endpoints: []\r\n  # - 10.141.4.22\r\n  # - 10.141.4.23\r\n  # - 10.141.4.24\r\n\r\n  service:\r\n    enabled: true\r\n    port: 10249\r\n    targetPort: 10249\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n    # selector:\r\n    #   k8s-app: kube-proxy\r\n\r\n  serviceMonitor:\r\n    enabled: true\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n\r\n    ## port: Name of the port the metrics will be scraped from\r\n    ##\r\n    port: http-metrics\r\n\r\n    jobLabel: jobLabel\r\n    selector: {}\r\n    #  matchLabels:\r\n    #    k8s-app: kube-proxy\r\n\r\n    ## Enable scraping kube-proxy over https.\r\n    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks\r\n    ##\r\n    https: false\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n    #  foo: bar\r\n\r\n## Component scraping kube state metrics\r\n##\r\nkubeStateMetrics:\r\n  enabled: true\r\n\r\n## Configuration for kube-state-metrics subchart\r\n##\r\nkube-state-metrics:\r\n  namespaceOverride: \"\"\r\n  rbac:\r\n    create: true\r\n  releaseLabel: true\r\n  prometheus:\r\n    monitor:\r\n      enabled: true\r\n\r\n      ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n      ##\r\n      interval: \"\"\r\n\r\n      ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n      ##\r\n      sampleLimit: 0\r\n\r\n      ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n      ##\r\n      targetLimit: 0\r\n\r\n      ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n      ##\r\n      labelLimit: 0\r\n\r\n      ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n      ##\r\n      labelNameLengthLimit: 0\r\n\r\n      ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n      ##\r\n      labelValueLengthLimit: 0\r\n\r\n      ## Scrape Timeout. If not set, the Prometheus default scrape timeout is used.\r\n      ##\r\n      scrapeTimeout: \"\"\r\n\r\n      ## proxyUrl: URL of a proxy that should be used for scraping.\r\n      ##\r\n      proxyUrl: \"\"\r\n\r\n      # Keep labels from scraped data, overriding server-side labels\r\n      ##\r\n      honorLabels: true\r\n\r\n      ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n      ##\r\n      metricRelabelings: []\r\n      # - action: keep\r\n      #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n      #   sourceLabels: [__name__]\r\n\r\n      ## RelabelConfigs to apply to samples before scraping\r\n      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n      ##\r\n      relabelings: []\r\n      # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n      #   separator: ;\r\n      #   regex: ^(.*)$\r\n      #   targetLabel: nodename\r\n      #   replacement: $1\r\n      #   action: replace\r\n\r\n  selfMonitor:\r\n    enabled: false\r\n\r\n## Deploy node exporter as a daemonset to all nodes\r\n##\r\nnodeExporter:\r\n  enabled: true\r\n  operatingSystems:\r\n    linux:\r\n      enabled: true\r\n    darwin:\r\n      enabled: true\r\n\r\n  ## ForceDeployDashboard Create dashboard configmap even if nodeExporter deployment has been disabled\r\n  ##\r\n  forceDeployDashboards: false\r\n\r\n## Configuration for prometheus-node-exporter subchart\r\n##\r\nprometheus-node-exporter:\r\n  namespaceOverride: \"\"\r\n  podLabels:\r\n    ## Add the 'node-exporter' label to be used by serviceMonitor to match standard common usage in rules and grafana dashboards\r\n    ##\r\n    jobLabel: node-exporter\r\n  releaseLabel: true\r\n  extraArgs:\r\n    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)\r\n    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$\r\n  service:\r\n    portName: http-metrics\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n    labels:\r\n      jobLabel: node-exporter\r\n\r\n  prometheus:\r\n    monitor:\r\n      enabled: true\r\n\r\n      jobLabel: jobLabel\r\n\r\n      ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n      ##\r\n      interval: \"\"\r\n\r\n      ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n      ##\r\n      sampleLimit: 0\r\n\r\n      ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n      ##\r\n      targetLimit: 0\r\n\r\n      ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n      ##\r\n      labelLimit: 0\r\n\r\n      ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n      ##\r\n      labelNameLengthLimit: 0\r\n\r\n      ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n      ##\r\n      labelValueLengthLimit: 0\r\n\r\n      ## How long until a scrape request times out. If not set, the Prometheus default scape timeout is used.\r\n      ##\r\n      scrapeTimeout: \"\"\r\n\r\n      ## proxyUrl: URL of a proxy that should be used for scraping.\r\n      ##\r\n      proxyUrl: \"\"\r\n\r\n      ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n      ##\r\n      metricRelabelings: []\r\n      # - sourceLabels: [__name__]\r\n      #   separator: ;\r\n      #   regex: ^node_mountstats_nfs_(event|operations|transport)_.+\r\n      #   replacement: $1\r\n      #   action: drop\r\n\r\n      ## RelabelConfigs to apply to samples before scraping\r\n      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n      ##\r\n      relabelings: []\r\n      # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n      #   separator: ;\r\n      #   regex: ^(.*)$\r\n      #   targetLabel: nodename\r\n      #   replacement: $1\r\n      #   action: replace\r\n  rbac:\r\n    ## If true, create PSPs for node-exporter\r\n    ##\r\n    pspEnabled: false\r\n\r\n## Manages Prometheus and Alertmanager components\r\n##\r\nprometheusOperator:\r\n  enabled: true\r\n\r\n  ## Use '{{ template \"kube-prometheus-stack.fullname\" . }}-operator' by default\r\n  fullnameOverride: \"\"\r\n\r\n  ## Number of old replicasets to retain ##\r\n  ## The default value is 10, 0 will garbage-collect old replicasets ##\r\n  revisionHistoryLimit: 10\r\n\r\n  ## Strategy of the deployment\r\n  ##\r\n  strategy: {}\r\n\r\n  ## Prometheus-Operator v0.39.0 and later support TLS natively.\r\n  ##\r\n  tls:\r\n    enabled: true\r\n    # Value must match version names from https://golang.org/pkg/crypto/tls/#pkg-constants\r\n    tlsMinVersion: VersionTLS13\r\n    # The default webhook port is 10250 in order to work out-of-the-box in GKE private clusters and avoid adding firewall rules.\r\n    internalPort: 10250\r\n\r\n  ## Liveness probe for the prometheusOperator deployment\r\n  ##\r\n  livenessProbe:\r\n    enabled: true\r\n    failureThreshold: 3\r\n    initialDelaySeconds: 0\r\n    periodSeconds: 10\r\n    successThreshold: 1\r\n    timeoutSeconds: 1\r\n  ## Readiness probe for the prometheusOperator deployment\r\n  ##\r\n  readinessProbe:\r\n    enabled: true\r\n    failureThreshold: 3\r\n    initialDelaySeconds: 0\r\n    periodSeconds: 10\r\n    successThreshold: 1\r\n    timeoutSeconds: 1\r\n\r\n  ## Admission webhook support for PrometheusRules resources added in Prometheus Operator 0.30 can be enabled to prevent incorrectly formatted\r\n  ## rules from making their way into prometheus and potentially preventing the container from starting\r\n  admissionWebhooks:\r\n    ## Valid values: Fail, Ignore, IgnoreOnInstallOnly\r\n    ## IgnoreOnInstallOnly - If Release.IsInstall returns \"true\", set \"Ignore\" otherwise \"Fail\"\r\n    failurePolicy: \"\"\r\n    ## The default timeoutSeconds is 10 and the maximum value is 30.\r\n    timeoutSeconds: 10\r\n    enabled: true\r\n    ## A PEM encoded CA bundle which will be used to validate the webhook's server certificate.\r\n    ## If unspecified, system trust roots on the apiserver are used.\r\n    caBundle: \"\"\r\n    ## If enabled, generate a self-signed certificate, then patch the webhook configurations with the generated data.\r\n    ## On chart upgrades (or if the secret exists) the cert will not be re-generated. You can use this to provide your own\r\n    ## certs ahead of time if you wish.\r\n    ##\r\n    annotations: {}\r\n    #   argocd.argoproj.io/hook: PreSync\r\n    #   argocd.argoproj.io/hook-delete-policy: HookSucceeded\r\n\r\n    namespaceSelector: {}\r\n    objectSelector: {}\r\n\r\n    mutatingWebhookConfiguration:\r\n      annotations: {}\r\n      #   argocd.argoproj.io/hook: PreSync\r\n\r\n    validatingWebhookConfiguration:\r\n      annotations: {}\r\n      #   argocd.argoproj.io/hook: PreSync\r\n\r\n    deployment:\r\n      enabled: false\r\n\r\n      ## Number of replicas\r\n      ##\r\n      replicas: 1\r\n\r\n      ## Strategy of the deployment\r\n      ##\r\n      strategy: {}\r\n\r\n      # Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\r\n      podDisruptionBudget: {}\r\n        # maxUnavailable: 1\r\n        # minAvailable: 1\r\n\r\n      ## Number of old replicasets to retain ##\r\n      ## The default value is 10, 0 will garbage-collect old replicasets ##\r\n      revisionHistoryLimit: 10\r\n\r\n      ## Prometheus-Operator v0.39.0 and later support TLS natively.\r\n      ##\r\n      tls:\r\n        enabled: true\r\n        # Value must match version names from https://golang.org/pkg/crypto/tls/#pkg-constants\r\n        tlsMinVersion: VersionTLS13\r\n        # The default webhook port is 10250 in order to work out-of-the-box in GKE private clusters and avoid adding firewall rules.\r\n        internalPort: 10250\r\n\r\n      ## Service account for Prometheus Operator Webhook to use.\r\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\r\n      ##\r\n      serviceAccount:\r\n        automountServiceAccountToken: false\r\n        create: true\r\n        name: \"\"\r\n\r\n      ## Configuration for Prometheus operator Webhook service\r\n      ##\r\n      service:\r\n        annotations: {}\r\n        labels: {}\r\n        clusterIP: \"\"\r\n        ipDualStack:\r\n          enabled: false\r\n          ipFamilies: [\"IPv6\", \"IPv4\"]\r\n          ipFamilyPolicy: \"PreferDualStack\"\r\n\r\n        ## Port to expose on each node\r\n        ## Only used if service.type is 'NodePort'\r\n        ##\r\n        nodePort: 31080\r\n\r\n        nodePortTls: 31443\r\n\r\n        ## Additional ports to open for Prometheus operator Webhook service\r\n        ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#multi-port-services\r\n        ##\r\n        additionalPorts: []\r\n\r\n        ## Loadbalancer IP\r\n        ## Only use if service.type is \"LoadBalancer\"\r\n        ##\r\n        loadBalancerIP: \"\"\r\n        loadBalancerSourceRanges: []\r\n\r\n        ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\r\n        ##\r\n        externalTrafficPolicy: Cluster\r\n\r\n        ## Service type\r\n        ## NodePort, ClusterIP, LoadBalancer\r\n        ##\r\n        type: ClusterIP\r\n\r\n        ## List of IP addresses at which the Prometheus server service is available\r\n        ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\r\n        ##\r\n        externalIPs: []\r\n\r\n      # ## Labels to add to the operator webhook deployment\r\n      # ##\r\n      labels: {}\r\n\r\n      ## Annotations to add to the operator webhook deployment\r\n      ##\r\n      annotations: {}\r\n\r\n      ## Labels to add to the operator webhook pod\r\n      ##\r\n      podLabels: {}\r\n\r\n      ## Annotations to add to the operator webhook pod\r\n      ##\r\n      podAnnotations: {}\r\n\r\n      ## Assign a PriorityClassName to pods if set\r\n      # priorityClassName: \"\"\r\n\r\n      ## Define Log Format\r\n      # Use logfmt (default) or json logging\r\n      # logFormat: logfmt\r\n\r\n      ## Decrease log verbosity to errors only\r\n      # logLevel: error\r\n\r\n      ## Prometheus-operator webhook image\r\n      ##\r\n      image:\r\n        registry: quay.io\r\n        repository: prometheus-operator/admission-webhook\r\n        # if not set appVersion field from Chart.yaml is used\r\n        tag: \"\"\r\n        sha: \"\"\r\n        pullPolicy: IfNotPresent\r\n\r\n      ## Define Log Format\r\n      # Use logfmt (default) or json logging\r\n      # logFormat: logfmt\r\n\r\n      ## Decrease log verbosity to errors only\r\n      # logLevel: error\r\n\r\n\r\n      ## Liveness probe\r\n      ##\r\n      livenessProbe:\r\n        enabled: true\r\n        failureThreshold: 3\r\n        initialDelaySeconds: 30\r\n        periodSeconds: 10\r\n        successThreshold: 1\r\n        timeoutSeconds: 1\r\n\r\n      ## Readiness probe\r\n      ##\r\n      readinessProbe:\r\n        enabled: true\r\n        failureThreshold: 3\r\n        initialDelaySeconds: 5\r\n        periodSeconds: 10\r\n        successThreshold: 1\r\n        timeoutSeconds: 1\r\n\r\n      ## Resource limits \u0026 requests\r\n      ##\r\n      resources: {}\r\n      # limits:\r\n      #   cpu: 200m\r\n      #   memory: 200Mi\r\n      # requests:\r\n      #   cpu: 100m\r\n      #   memory: 100Mi\r\n\r\n      # Required for use in managed kubernetes clusters (such as AWS EKS) with custom CNI (such as calico),\r\n      # because control-plane managed by AWS cannot communicate with pods' IP CIDR and admission webhooks are not working\r\n      ##\r\n      hostNetwork: false\r\n\r\n      ## Define which Nodes the Pods are scheduled on.\r\n      ## ref: https://kubernetes.io/docs/user-guide/node-selection/\r\n      ##\r\n      nodeSelector: {}\r\n\r\n      ## Tolerations for use with node taints\r\n      ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\r\n      ##\r\n      tolerations: []\r\n      # - key: \"key\"\r\n      #   operator: \"Equal\"\r\n      #   value: \"value\"\r\n      #   effect: \"NoSchedule\"\r\n\r\n      ## Assign custom affinity rules to the prometheus operator\r\n      ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\r\n      ##\r\n      affinity: {}\r\n        # nodeAffinity:\r\n        #   requiredDuringSchedulingIgnoredDuringExecution:\r\n        #     nodeSelectorTerms:\r\n        #     - matchExpressions:\r\n        #       - key: kubernetes.io/e2e-az-name\r\n        #         operator: In\r\n        #         values:\r\n        #         - e2e-az1\r\n      #         - e2e-az2\r\n      dnsConfig: {}\r\n        # nameservers:\r\n        #   - 1.2.3.4\r\n        # searches:\r\n        #   - ns1.svc.cluster-domain.example\r\n        #   - my.dns.search.suffix\r\n        # options:\r\n        #   - name: ndots\r\n        #     value: \"2\"\r\n        #   - name: edns0\r\n      securityContext:\r\n        fsGroup: 65534\r\n        runAsGroup: 65534\r\n        runAsNonRoot: true\r\n        runAsUser: 65534\r\n        seccompProfile:\r\n          type: RuntimeDefault\r\n\r\n      ## Container-specific security context configuration\r\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\r\n      ##\r\n      containerSecurityContext:\r\n        allowPrivilegeEscalation: false\r\n        readOnlyRootFilesystem: true\r\n        capabilities:\r\n          drop:\r\n            - ALL\r\n\r\n      ## If false then the user will opt out of automounting API credentials.\r\n      ##\r\n      automountServiceAccountToken: true\r\n\r\n    patch:\r\n      enabled: true\r\n      image:\r\n        registry: registry.k8s.io\r\n        repository: ingress-nginx/kube-webhook-certgen\r\n        tag: v20221220-controller-v1.5.1-58-g787ea74b6\r\n        sha: \"\"\r\n        pullPolicy: IfNotPresent\r\n      resources: {}\r\n      ## Provide a priority class name to the webhook patching job\r\n      ##\r\n      priorityClassName: \"\"\r\n      ttlSecondsAfterFinished: 60\r\n      annotations: {}\r\n      #   argocd.argoproj.io/hook: PreSync\r\n      #   argocd.argoproj.io/hook-delete-policy: HookSucceeded\r\n      podAnnotations: {}\r\n      nodeSelector: {}\r\n      affinity: {}\r\n      tolerations: []\r\n\r\n      ## SecurityContext holds pod-level security attributes and common container settings.\r\n      ## This defaults to non root user with uid 2000 and gid 2000. *v1.PodSecurityContext  false\r\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\r\n      ##\r\n      securityContext:\r\n        runAsGroup: 2000\r\n        runAsNonRoot: true\r\n        runAsUser: 2000\r\n        seccompProfile:\r\n          type: RuntimeDefault\r\n      ## Service account for Prometheus Operator Webhook Job Patch to use.\r\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\r\n      ##\r\n      serviceAccount:\r\n        create: true\r\n        automountServiceAccountToken: true\r\n\r\n    # Security context for create job container\r\n    createSecretJob:\r\n      securityContext:\r\n        allowPrivilegeEscalation: false\r\n        readOnlyRootFilesystem: true\r\n        capabilities:\r\n          drop:\r\n          - ALL\r\n\r\n      # Security context for patch job container\r\n    patchWebhookJob:\r\n      securityContext:\r\n        allowPrivilegeEscalation: false\r\n        readOnlyRootFilesystem: true\r\n        capabilities:\r\n          drop:\r\n          - ALL\r\n\r\n    # Use certmanager to generate webhook certs\r\n    certManager:\r\n      enabled: false\r\n      # self-signed root certificate\r\n      rootCert:\r\n        duration: \"\"  # default to be 5y\r\n      admissionCert:\r\n        duration: \"\"  # default to be 1y\r\n      # issuerRef:\r\n      #   name: \"issuer\"\r\n      #   kind: \"ClusterIssuer\"\r\n\r\n  ## Namespaces to scope the interaction of the Prometheus Operator and the apiserver (allow list).\r\n  ## This is mutually exclusive with denyNamespaces. Setting this to an empty object will disable the configuration\r\n  ##\r\n  namespaces: {}\r\n    # releaseNamespace: true\r\n    # additional:\r\n    # - kube-system\r\n\r\n  ## Namespaces not to scope the interaction of the Prometheus Operator (deny list).\r\n  ##\r\n  denyNamespaces: []\r\n\r\n  ## Filter namespaces to look for prometheus-operator custom resources\r\n  ##\r\n  alertmanagerInstanceNamespaces: []\r\n  alertmanagerConfigNamespaces: []\r\n  prometheusInstanceNamespaces: []\r\n  thanosRulerInstanceNamespaces: []\r\n\r\n  ## The clusterDomain value will be added to the cluster.peer option of the alertmanager.\r\n  ## Without this specified option cluster.peer will have value alertmanager-monitoring-alertmanager-0.alertmanager-operated:9094 (default value)\r\n  ## With this specified option cluster.peer will have value alertmanager-monitoring-alertmanager-0.alertmanager-operated.namespace.svc.cluster-domain:9094\r\n  ##\r\n  # clusterDomain: \"cluster.local\"\r\n\r\n  networkPolicy:\r\n    ## Enable creation of NetworkPolicy resources.\r\n    ##\r\n    enabled: false\r\n\r\n    ## Flavor of the network policy to use.\r\n    #  Can be:\r\n    #  * kubernetes for networking.k8s.io/v1/NetworkPolicy\r\n    #  * cilium     for cilium.io/v2/CiliumNetworkPolicy\r\n    flavor: kubernetes\r\n\r\n    # cilium:\r\n    #   egress:\r\n\r\n    ## match labels used in selector\r\n    # matchLabels: {}\r\n\r\n  ## Service account for Prometheus Operator to use.\r\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\r\n  ##\r\n  serviceAccount:\r\n    create: true\r\n    name: \"\"\r\n    automountServiceAccountToken: true\r\n\r\n  ## Configuration for Prometheus operator service\r\n  ##\r\n  service:\r\n    annotations: {}\r\n    labels: {}\r\n    clusterIP: \"\"\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n\r\n  ## Port to expose on each node\r\n  ## Only used if service.type is 'NodePort'\r\n  ##\r\n    nodePort: 30080\r\n\r\n    nodePortTls: 30443\r\n\r\n  ## Additional ports to open for Prometheus operator service\r\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#multi-port-services\r\n  ##\r\n    additionalPorts: []\r\n\r\n  ## Loadbalancer IP\r\n  ## Only use if service.type is \"LoadBalancer\"\r\n  ##\r\n    loadBalancerIP: \"\"\r\n    loadBalancerSourceRanges: []\r\n\r\n    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\r\n    ##\r\n    externalTrafficPolicy: Cluster\r\n\r\n  ## Service type\r\n  ## NodePort, ClusterIP, LoadBalancer\r\n  ##\r\n    type: ClusterIP\r\n\r\n    ## List of IP addresses at which the Prometheus server service is available\r\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\r\n    ##\r\n    externalIPs: []\r\n\r\n  # ## Labels to add to the operator deployment\r\n  # ##\r\n  labels: {}\r\n\r\n  ## Annotations to add to the operator deployment\r\n  ##\r\n  annotations: {}\r\n\r\n  ## Labels to add to the operator pod\r\n  ##\r\n  podLabels: {}\r\n\r\n  ## Annotations to add to the operator pod\r\n  ##\r\n  podAnnotations: {}\r\n\r\n  ## Assign a PriorityClassName to pods if set\r\n  # priorityClassName: \"\"\r\n\r\n  ## Define Log Format\r\n  # Use logfmt (default) or json logging\r\n  # logFormat: logfmt\r\n\r\n  ## Decrease log verbosity to errors only\r\n  # logLevel: error\r\n\r\n  kubeletService:\r\n    ## If true, the operator will create and maintain a service for scraping kubelets\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/helm/prometheus-operator/README.md\r\n    ##\r\n    enabled: true\r\n    namespace: kube-system\r\n    selector: \"\"\r\n    ## Use '{{ template \"kube-prometheus-stack.fullname\" . }}-kubelet' by default\r\n    name: \"\"\r\n\r\n  ## Create a servicemonitor for the operator\r\n  ##\r\n  serviceMonitor:\r\n    ## If true, create a serviceMonitor for prometheus operator\r\n    ##\r\n    selfMonitor: true\r\n\r\n    ## Labels for ServiceMonitor\r\n    additionalLabels: {}\r\n\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## Scrape timeout. If not set, the Prometheus default scrape timeout is used.\r\n    scrapeTimeout: \"\"\r\n\r\n    ## Metric relabel configs to apply to samples before ingestion.\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    #   relabel configs to apply to samples before ingestion.\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n  ## Resource limits \u0026 requests\r\n  ##\r\n  resources: {}\r\n  # limits:\r\n  #   cpu: 200m\r\n  #   memory: 200Mi\r\n  # requests:\r\n  #   cpu: 100m\r\n  #   memory: 100Mi\r\n\r\n  ## Operator Environment\r\n  ##  env:\r\n  ##    VARIABLE: value\r\n  env:\r\n    GOGC: \"30\"\r\n\r\n  # Required for use in managed kubernetes clusters (such as AWS EKS) with custom CNI (such as calico),\r\n  # because control-plane managed by AWS cannot communicate with pods' IP CIDR and admission webhooks are not working\r\n  ##\r\n  hostNetwork: false\r\n\r\n  ## Define which Nodes the Pods are scheduled on.\r\n  ## ref: https://kubernetes.io/docs/user-guide/node-selection/\r\n  ##\r\n  nodeSelector: {}\r\n\r\n  ## Tolerations for use with node taints\r\n  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\r\n  ##\r\n  tolerations: []\r\n  # - key: \"key\"\r\n  #   operator: \"Equal\"\r\n  #   value: \"value\"\r\n  #   effect: \"NoSchedule\"\r\n\r\n  ## Assign custom affinity rules to the prometheus operator\r\n  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\r\n  ##\r\n  affinity: {}\r\n    # nodeAffinity:\r\n    #   requiredDuringSchedulingIgnoredDuringExecution:\r\n    #     nodeSelectorTerms:\r\n    #     - matchExpressions:\r\n    #       - key: kubernetes.io/e2e-az-name\r\n    #         operator: In\r\n    #         values:\r\n    #         - e2e-az1\r\n    #         - e2e-az2\r\n  dnsConfig: {}\r\n    # nameservers:\r\n    #   - 1.2.3.4\r\n    # searches:\r\n    #   - ns1.svc.cluster-domain.example\r\n    #   - my.dns.search.suffix\r\n    # options:\r\n    #   - name: ndots\r\n    #     value: \"2\"\r\n  #   - name: edns0\r\n  securityContext:\r\n    fsGroup: 65534\r\n    runAsGroup: 65534\r\n    runAsNonRoot: true\r\n    runAsUser: 65534\r\n    seccompProfile:\r\n      type: RuntimeDefault\r\n\r\n  ## Container-specific security context configuration\r\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\r\n  ##\r\n  containerSecurityContext:\r\n    allowPrivilegeEscalation: false\r\n    readOnlyRootFilesystem: true\r\n    capabilities:\r\n      drop:\r\n      - ALL\r\n\r\n  # Enable vertical pod autoscaler support for prometheus-operator\r\n  verticalPodAutoscaler:\r\n    enabled: false\r\n\r\n    # Recommender responsible for generating recommendation for the object.\r\n    # List should be empty (then the default recommender will generate the recommendation)\r\n    # or contain exactly one recommender.\r\n    # recommenders:\r\n    # - name: custom-recommender-performance\r\n\r\n    # List of resources that the vertical pod autoscaler can control. Defaults to cpu and memory\r\n    controlledResources: []\r\n    # Specifies which resource values should be controlled: RequestsOnly or RequestsAndLimits.\r\n    # controlledValues: RequestsAndLimits\r\n\r\n    # Define the max allowed resources for the pod\r\n    maxAllowed: {}\r\n    # cpu: 200m\r\n    # memory: 100Mi\r\n    # Define the min allowed resources for the pod\r\n    minAllowed: {}\r\n    # cpu: 200m\r\n    # memory: 100Mi\r\n\r\n    updatePolicy:\r\n      # Specifies minimal number of replicas which need to be alive for VPA Updater to attempt pod eviction\r\n      # minReplicas: 1\r\n      # Specifies whether recommended updates are applied when a Pod is started and whether recommended updates\r\n      # are applied during the life of a Pod. Possible values are \"Off\", \"Initial\", \"Recreate\", and \"Auto\".\r\n      updateMode: Auto\r\n\r\n  ## Prometheus-operator image\r\n  ##\r\n  image:\r\n    registry: quay.io\r\n    repository: prometheus-operator/prometheus-operator\r\n    # if not set appVersion field from Chart.yaml is used\r\n    tag: \"\"\r\n    sha: \"\"\r\n    pullPolicy: IfNotPresent\r\n\r\n  ## Prometheus image to use for prometheuses managed by the operator\r\n  ##\r\n  # prometheusDefaultBaseImage: prometheus/prometheus\r\n\r\n  ## Prometheus image registry to use for prometheuses managed by the operator\r\n  ##\r\n  # prometheusDefaultBaseImageRegistry: quay.io\r\n\r\n  ## Alertmanager image to use for alertmanagers managed by the operator\r\n  ##\r\n  # alertmanagerDefaultBaseImage: prometheus/alertmanager\r\n\r\n  ## Alertmanager image registry to use for alertmanagers managed by the operator\r\n  ##\r\n  # alertmanagerDefaultBaseImageRegistry: quay.io\r\n\r\n  ## Prometheus-config-reloader\r\n  ##\r\n  prometheusConfigReloader:\r\n    image:\r\n      registry: quay.io\r\n      repository: prometheus-operator/prometheus-config-reloader\r\n      # if not set appVersion field from Chart.yaml is used\r\n      tag: \"\"\r\n      sha: \"\"\r\n\r\n    # add prometheus config reloader liveness and readiness probe. Default: false\r\n    enableProbe: false\r\n\r\n    # resource config for prometheusConfigReloader\r\n    resources: {}\r\n      # requests:\r\n      #   cpu: 200m\r\n      #   memory: 50Mi\r\n      # limits:\r\n      #   cpu: 200m\r\n      #   memory: 50Mi\r\n\r\n  ## Thanos side-car image when configured\r\n  ##\r\n  thanosImage:\r\n    registry: quay.io\r\n    repository: thanos/thanos\r\n    tag: v0.36.1\r\n    sha: \"\"\r\n\r\n  ## Set a Label Selector to filter watched prometheus and prometheusAgent\r\n  ##\r\n  prometheusInstanceSelector: \"\"\r\n\r\n  ## Set a Label Selector to filter watched alertmanager\r\n  ##\r\n  alertmanagerInstanceSelector: \"\"\r\n\r\n  ## Set a Label Selector to filter watched thanosRuler\r\n  thanosRulerInstanceSelector: \"\"\r\n\r\n  ## Set a Field Selector to filter watched secrets\r\n  ##\r\n  secretFieldSelector: \"type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1\"\r\n\r\n  ## If false then the user will opt out of automounting API credentials.\r\n  ##\r\n  automountServiceAccountToken: true\r\n\r\n  ## Additional volumes\r\n  ##\r\n  extraVolumes: []\r\n\r\n  ## Additional volume mounts\r\n  ##\r\n  extraVolumeMounts: []\r\n\r\n## Deploy a Prometheus instance\r\n##\r\nprometheus:\r\n  enabled: true\r\n\r\n  ## Toggle prometheus into agent mode\r\n  ## Note many of features described below (e.g. rules, query, alerting, remote read, thanos) will not work in agent mode.\r\n  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/designs/prometheus-agent.md\r\n  ##\r\n  agentMode: false\r\n\r\n  ## Annotations for Prometheus\r\n  ##\r\n  annotations: {}\r\n\r\n  ## Configure network policy for the prometheus\r\n  networkPolicy:\r\n    enabled: false\r\n\r\n    ## Flavor of the network policy to use.\r\n    #  Can be:\r\n    #  * kubernetes for networking.k8s.io/v1/NetworkPolicy\r\n    #  * cilium     for cilium.io/v2/CiliumNetworkPolicy\r\n    flavor: kubernetes\r\n\r\n    # cilium:\r\n    #   endpointSelector:\r\n    #   egress:\r\n    #   ingress:\r\n\r\n    # egress:\r\n    # - {}\r\n    # ingress:\r\n    # - {}\r\n    # podSelector:\r\n    #   matchLabels:\r\n    #     app: prometheus\r\n\r\n  ## Service account for Prometheuses to use.\r\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\r\n  ##\r\n  serviceAccount:\r\n    create: true\r\n    name: \"\"\r\n    annotations: {}\r\n    automountServiceAccountToken: true\r\n\r\n  # Service for thanos service discovery on sidecar\r\n  # Enable this can make Thanos Query can use\r\n  # `--store=dnssrv+_grpc._tcp.${kube-prometheus-stack.fullname}-thanos-discovery.${namespace}.svc.cluster.local` to discovery\r\n  # Thanos sidecar on prometheus nodes\r\n  # (Please remember to change ${kube-prometheus-stack.fullname} and ${namespace}. Not just copy and paste!)\r\n  thanosService:\r\n    enabled: false\r\n    annotations: {}\r\n    labels: {}\r\n\r\n    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\r\n    ##\r\n    externalTrafficPolicy: Cluster\r\n\r\n    ## Service type\r\n    ##\r\n    type: ClusterIP\r\n\r\n    ## Service dual stack\r\n    ##\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n\r\n    ## gRPC port config\r\n    portName: grpc\r\n    port: 10901\r\n    targetPort: \"grpc\"\r\n\r\n    ## HTTP port config (for metrics)\r\n    httpPortName: http\r\n    httpPort: 10902\r\n    targetHttpPort: \"http\"\r\n\r\n    ## ClusterIP to assign\r\n    # Default is to make this a headless service (\"None\")\r\n    clusterIP: \"None\"\r\n\r\n    ## Port to expose on each node, if service type is NodePort\r\n    ##\r\n    nodePort: 30901\r\n    httpNodePort: 30902\r\n\r\n  # ServiceMonitor to scrape Sidecar metrics\r\n  # Needs thanosService to be enabled as well\r\n  thanosServiceMonitor:\r\n    enabled: false\r\n    interval: \"\"\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n\r\n    ## scheme: HTTP scheme to use for scraping. Can be used with `tlsConfig` for example if using istio mTLS.\r\n    scheme: \"\"\r\n\r\n    ## tlsConfig: TLS configuration to use when scraping the endpoint. For example if using istio mTLS.\r\n    ## Of type: https://github.com/coreos/prometheus-operator/blob/main/Documentation/api.md#tlsconfig\r\n    tlsConfig: {}\r\n\r\n    bearerTokenFile:\r\n\r\n    ## Metric relabel configs to apply to samples before ingestion.\r\n    metricRelabelings: []\r\n\r\n    ## relabel configs to apply to samples before ingestion.\r\n    relabelings: []\r\n\r\n  # Service for external access to sidecar\r\n  # Enabling this creates a service to expose thanos-sidecar outside the cluster.\r\n  thanosServiceExternal:\r\n    enabled: false\r\n    annotations: {}\r\n    labels: {}\r\n    loadBalancerIP: \"\"\r\n    loadBalancerSourceRanges: []\r\n\r\n    ## gRPC port config\r\n    portName: grpc\r\n    port: 10901\r\n    targetPort: \"grpc\"\r\n\r\n    ## HTTP port config (for metrics)\r\n    httpPortName: http\r\n    httpPort: 10902\r\n    targetHttpPort: \"http\"\r\n\r\n    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\r\n    ##\r\n    externalTrafficPolicy: Cluster\r\n\r\n    ## Service type\r\n    ##\r\n    type: LoadBalancer\r\n\r\n    ## Port to expose on each node\r\n    ##\r\n    nodePort: 30901\r\n    httpNodePort: 30902\r\n\r\n  ## Configuration for Prometheus service\r\n  ##\r\n  service:\r\n    annotations: {}\r\n    labels: {}\r\n    clusterIP: \"\"\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n\r\n    ## Port for Prometheus Service to listen on\r\n    ##\r\n    port: 9090\r\n\r\n    ## To be used with a proxy extraContainer port\r\n    targetPort: 9090\r\n\r\n    ## Port for Prometheus Reloader to listen on\r\n    ##\r\n    reloaderWebPort: 8080\r\n\r\n    ## List of IP addresses at which the Prometheus server service is available\r\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\r\n    ##\r\n    externalIPs: []\r\n\r\n    ## Port to expose on each node\r\n    ## Only used if service.type is 'NodePort'\r\n    ##\r\n    nodePort: 30090\r\n\r\n    ## Loadbalancer IP\r\n    ## Only use if service.type is \"LoadBalancer\"\r\n    loadBalancerIP: \"\"\r\n    loadBalancerSourceRanges: []\r\n\r\n    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\r\n    ##\r\n    externalTrafficPolicy: Cluster\r\n\r\n    ## Service type\r\n    ##\r\n    type: ClusterIP\r\n\r\n    ## Additional ports to open for Prometheus service\r\n    ##\r\n    additionalPorts: []\r\n    # additionalPorts:\r\n    # - name: oauth-proxy\r\n    #   port: 8081\r\n    #   targetPort: 8081\r\n    # - name: oauth-metrics\r\n    #   port: 8082\r\n    #   targetPort: 8082\r\n\r\n    ## Consider that all endpoints are considered \"ready\" even if the Pods themselves are not\r\n    ## Ref: https://kubernetes.io/docs/reference/kubernetes-api/service-resources/service-v1/#ServiceSpec\r\n    publishNotReadyAddresses: false\r\n\r\n    ## If you want to make sure that connections from a particular client are passed to the same Pod each time\r\n    ## Accepts 'ClientIP' or 'None'\r\n    ##\r\n    sessionAffinity: None\r\n\r\n    ## If you want to modify the ClientIP sessionAffinity timeout\r\n    ## The value must be \u003e0 \u0026\u0026 \u003c=86400(for 1 day) if ServiceAffinity == \"ClientIP\"\r\n    ##\r\n    sessionAffinityConfig:\r\n      clientIP:\r\n        timeoutSeconds: 10800\r\n\r\n  ## Configuration for creating a separate Service for each statefulset Prometheus replica\r\n  ##\r\n  servicePerReplica:\r\n    enabled: false\r\n    annotations: {}\r\n\r\n    ## Port for Prometheus Service per replica to listen on\r\n    ##\r\n    port: 9090\r\n\r\n    ## To be used with a proxy extraContainer port\r\n    targetPort: 9090\r\n\r\n    ## Port to expose on each node\r\n    ## Only used if servicePerReplica.type is 'NodePort'\r\n    ##\r\n    nodePort: 30091\r\n\r\n    ## Loadbalancer source IP ranges\r\n    ## Only used if servicePerReplica.type is \"LoadBalancer\"\r\n    loadBalancerSourceRanges: []\r\n\r\n    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\r\n    ##\r\n    externalTrafficPolicy: Cluster\r\n\r\n    ## Service type\r\n    ##\r\n    type: ClusterIP\r\n\r\n    ## Service dual stack\r\n    ##\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n\r\n  ## Configure pod disruption budgets for Prometheus\r\n  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget\r\n  ##\r\n  podDisruptionBudget:\r\n    enabled: false\r\n    minAvailable: 1\r\n    maxUnavailable: \"\"\r\n\r\n  # Ingress exposes thanos sidecar outside the cluster\r\n  thanosIngress:\r\n    enabled: false\r\n\r\n    # For Kubernetes \u003e= 1.18 you should specify the ingress-controller via the field ingressClassName\r\n    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\r\n    # ingressClassName: nginx\r\n\r\n    annotations: {}\r\n    labels: {}\r\n    servicePort: 10901\r\n\r\n    ## Port to expose on each node\r\n    ## Only used if service.type is 'NodePort'\r\n    ##\r\n    nodePort: 30901\r\n\r\n    ## Hosts must be provided if Ingress is enabled.\r\n    ##\r\n    hosts: []\r\n      # - thanos-gateway.domain.com\r\n\r\n    ## Paths to use for ingress rules\r\n    ##\r\n    paths: []\r\n    # - /\r\n\r\n    ## For Kubernetes \u003e= 1.18 you should specify the pathType (determines how Ingress paths should be matched)\r\n    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types\r\n    # pathType: ImplementationSpecific\r\n\r\n    ## TLS configuration for Thanos Ingress\r\n    ## Secret must be manually created in the namespace\r\n    ##\r\n    tls: []\r\n    # - secretName: thanos-gateway-tls\r\n    #   hosts:\r\n    #   - thanos-gateway.domain.com\r\n    #\r\n\r\n  ## ExtraSecret can be used to store various data in an extra secret\r\n  ## (use it for example to store hashed basic auth credentials)\r\n  extraSecret:\r\n    ## if not set, name will be auto generated\r\n    # name: \"\"\r\n    annotations: {}\r\n    data: {}\r\n  #   auth: |\r\n  #     foo:$apr1$OFG3Xybp$ckL0FHDAkoXYIlH9.cysT0\r\n  #     someoneelse:$apr1$DMZX2Z4q$6SbQIfyuLQd.xmo/P0m2c.\r\n\r\n  ingress:\r\n    enabled: false\r\n\r\n    # For Kubernetes \u003e= 1.18 you should specify the ingress-controller via the field ingressClassName\r\n    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\r\n    # ingressClassName: nginx\r\n\r\n    annotations: {}\r\n    labels: {}\r\n\r\n    ## Redirect ingress to an additional defined port on the service\r\n    # servicePort: 8081\r\n\r\n    ## Hostnames.\r\n    ## Must be provided if Ingress is enabled.\r\n    ##\r\n    # hosts:\r\n    #   - prometheus.domain.com\r\n    hosts: []\r\n\r\n    ## Paths to use for ingress rules - one path should match the prometheusSpec.routePrefix\r\n    ##\r\n    paths: []\r\n    # - /\r\n\r\n    ## For Kubernetes \u003e= 1.18 you should specify the pathType (determines how Ingress paths should be matched)\r\n    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types\r\n    # pathType: ImplementationSpecific\r\n\r\n    ## TLS configuration for Prometheus Ingress\r\n    ## Secret must be manually created in the namespace\r\n    ##\r\n    tls: []\r\n      # - secretName: prometheus-general-tls\r\n      #   hosts:\r\n      #     - prometheus.example.com\r\n\r\n  ## Configuration for creating an Ingress that will map to each Prometheus replica service\r\n  ## prometheus.servicePerReplica must be enabled\r\n  ##\r\n  ingressPerReplica:\r\n    enabled: false\r\n\r\n    # For Kubernetes \u003e= 1.18 you should specify the ingress-controller via the field ingressClassName\r\n    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\r\n    # ingressClassName: nginx\r\n\r\n    annotations: {}\r\n    labels: {}\r\n\r\n    ## Final form of the hostname for each per replica ingress is\r\n    ## {{ ingressPerReplica.hostPrefix }}-{{ $replicaNumber }}.{{ ingressPerReplica.hostDomain }}\r\n    ##\r\n    ## Prefix for the per replica ingress that will have `-$replicaNumber`\r\n    ## appended to the end\r\n    hostPrefix: \"\"\r\n    ## Domain that will be used for the per replica ingress\r\n    hostDomain: \"\"\r\n\r\n    ## Paths to use for ingress rules\r\n    ##\r\n    paths: []\r\n    # - /\r\n\r\n    ## For Kubernetes \u003e= 1.18 you should specify the pathType (determines how Ingress paths should be matched)\r\n    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types\r\n    # pathType: ImplementationSpecific\r\n\r\n    ## Secret name containing the TLS certificate for Prometheus per replica ingress\r\n    ## Secret must be manually created in the namespace\r\n    tlsSecretName: \"\"\r\n\r\n    ## Separated secret for each per replica Ingress. Can be used together with cert-manager\r\n    ##\r\n    tlsSecretPerReplica:\r\n      enabled: false\r\n      ## Final form of the secret for each per replica ingress is\r\n      ## {{ tlsSecretPerReplica.prefix }}-{{ $replicaNumber }}\r\n      ##\r\n      prefix: \"prometheus\"\r\n\r\n  ## Configure additional options for default pod security policy for Prometheus\r\n  ## ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\r\n  podSecurityPolicy:\r\n    allowedCapabilities: []\r\n    allowedHostPaths: []\r\n    volumes: []\r\n\r\n  serviceMonitor:\r\n    ## If true, create a serviceMonitor for prometheus\r\n    ##\r\n    selfMonitor: true\r\n\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## scheme: HTTP scheme to use for scraping. Can be used with `tlsConfig` for example if using istio mTLS.\r\n    scheme: \"\"\r\n\r\n    ## tlsConfig: TLS configuration to use when scraping the endpoint. For example if using istio mTLS.\r\n    ## Of type: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#tlsconfig\r\n    tlsConfig: {}\r\n\r\n    bearerTokenFile:\r\n\r\n    ## Metric relabel configs to apply to samples before ingestion.\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    #   relabel configs to apply to samples before ingestion.\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## Additional Endpoints\r\n    ##\r\n    additionalEndpoints: []\r\n    # - port: oauth-metrics\r\n    #   path: /metrics\r\n\r\n  ## Settings affecting prometheusSpec\r\n  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#prometheusspec\r\n  ##\r\n  prometheusSpec:\r\n    ## Statefulset's persistent volume claim retention policy\r\n    ## pvcDeleteOnStsDelete and pvcDeleteOnStsScale determine whether\r\n    ## statefulset's PVCs are deleted (true) or retained (false) on scaling down\r\n    ## and deleting statefulset, respectively. Requires 1.27.0+.\r\n    ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention\r\n    persistentVolumeClaimRetentionPolicy: {}\r\n    #  whenDeleted: Retain\r\n    #  whenScaled: Retain\r\n\r\n    ## If true, pass --storage.tsdb.max-block-duration=2h to prometheus. This is already done if using Thanos\r\n    ##\r\n    ## AutomountServiceAccountToken indicates whether a service account token should be automatically mounted in the pod,\r\n    ## If the field isnt set, the operator mounts the service account token by default.\r\n    ## Warning: be aware that by default, Prometheus requires the service account token for Kubernetes service discovery,\r\n    ## It is possible to use strategic merge patch to project the service account token into the prometheus container.\r\n    automountServiceAccountToken: true\r\n\r\n    disableCompaction: false\r\n    ## APIServerConfig\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#apiserverconfig\r\n    ##\r\n    apiserverConfig: {}\r\n\r\n    ## Allows setting additional arguments for the Prometheus container\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#monitoring.coreos.com/v1.Prometheus\r\n    additionalArgs: []\r\n\r\n    ## Interval between consecutive scrapes.\r\n    ## Defaults to 30s.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/release-0.44/pkg/prometheus/promcfg.go#L180-L183\r\n    ##\r\n    scrapeInterval: \"\"\r\n\r\n    ## Number of seconds to wait for target to respond before erroring\r\n    ##\r\n    scrapeTimeout: \"\"\r\n\r\n    ## List of scrape classes to expose to scraping objects such as\r\n    ## PodMonitors, ServiceMonitors, Probes and ScrapeConfigs.\r\n    ##\r\n    scrapeClasses: []\r\n    # - name: istio-mtls\r\n    #   default: false\r\n    #   tlsConfig:\r\n    #     caFile: /etc/prometheus/secrets/istio.default/root-cert.pem\r\n    #     certFile: /etc/prometheus/secrets/istio.default/cert-chain.pem\r\n\r\n    ## Interval between consecutive evaluations.\r\n    ##\r\n    evaluationInterval: \"\"\r\n\r\n    ## ListenLocal makes the Prometheus server listen on loopback, so that it does not bind against the Pod IP.\r\n    ##\r\n    listenLocal: false\r\n\r\n    ## EnableAdminAPI enables Prometheus the administrative HTTP API which includes functionality such as deleting time series.\r\n    ## This is disabled by default.\r\n    ## ref: https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis\r\n    ##\r\n    enableAdminAPI: false\r\n\r\n    ## Sets version of Prometheus overriding the Prometheus version as derived\r\n    ## from the image tag. Useful in cases where the tag does not follow semver v2.\r\n    version: \"\"\r\n\r\n    ## WebTLSConfig defines the TLS parameters for HTTPS\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#webtlsconfig\r\n    web: {}\r\n\r\n    ## Exemplars related settings that are runtime reloadable.\r\n    ## It requires to enable the exemplar storage feature to be effective.\r\n    exemplars: \"\"\r\n      ## Maximum number of exemplars stored in memory for all series.\r\n      ## If not set, Prometheus uses its default value.\r\n      ## A value of zero or less than zero disables the storage.\r\n      # maxSize: 100000\r\n\r\n    # EnableFeatures API enables access to Prometheus disabled features.\r\n    # ref: https://prometheus.io/docs/prometheus/latest/disabled_features/\r\n    enableFeatures: []\r\n    # - exemplar-storage\r\n\r\n    ## Image of Prometheus.\r\n    ##\r\n    image:\r\n      registry: quay.io\r\n      repository: prometheus/prometheus\r\n      tag: v2.54.1\r\n      sha: \"\"\r\n\r\n    ## Tolerations for use with node taints\r\n    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\r\n    ##\r\n    tolerations: []\r\n    #  - key: \"key\"\r\n    #    operator: \"Equal\"\r\n    #    value: \"value\"\r\n    #    effect: \"NoSchedule\"\r\n\r\n    ## If specified, the pod's topology spread constraints.\r\n    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\r\n    ##\r\n    topologySpreadConstraints: []\r\n    # - maxSkew: 1\r\n    #   topologyKey: topology.kubernetes.io/zone\r\n    #   whenUnsatisfiable: DoNotSchedule\r\n    #   labelSelector:\r\n    #     matchLabels:\r\n    #       app: prometheus\r\n\r\n    ## Alertmanagers to which alerts will be sent\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#alertmanagerendpoints\r\n    ##\r\n    ## Default configuration will connect to the alertmanager deployed as part of this release\r\n    ##\r\n    alertingEndpoints: []\r\n    # - name: \"\"\r\n    #   namespace: \"\"\r\n    #   port: http\r\n    #   scheme: http\r\n    #   pathPrefix: \"\"\r\n    #   tlsConfig: {}\r\n    #   bearerTokenFile: \"\"\r\n    #   apiVersion: v2\r\n\r\n    ## External labels to add to any time series or alerts when communicating with external systems\r\n    ##\r\n    externalLabels: {}\r\n\r\n    ## enable --web.enable-remote-write-receiver flag on prometheus-server\r\n    ##\r\n    enableRemoteWriteReceiver: false\r\n\r\n    ## Name of the external label used to denote replica name\r\n    ##\r\n    replicaExternalLabelName: \"\"\r\n\r\n    ## If true, the Operator won't add the external label used to denote replica name\r\n    ##\r\n    replicaExternalLabelNameClear: false\r\n\r\n    ## Name of the external label used to denote Prometheus instance name\r\n    ##\r\n    prometheusExternalLabelName: \"\"\r\n\r\n    ## If true, the Operator won't add the external label used to denote Prometheus instance name\r\n    ##\r\n    prometheusExternalLabelNameClear: false\r\n\r\n    ## External URL at which Prometheus will be reachable.\r\n    ##\r\n    externalUrl: \"\"\r\n\r\n    ## Define which Nodes the Pods are scheduled on.\r\n    ## ref: https://kubernetes.io/docs/user-guide/node-selection/\r\n    ##\r\n    nodeSelector: {}\r\n\r\n    ## Secrets is a list of Secrets in the same namespace as the Prometheus object, which shall be mounted into the Prometheus Pods.\r\n    ## The Secrets are mounted into /etc/prometheus/secrets/. Secrets changes after initial creation of a Prometheus object are not\r\n    ## reflected in the running Pods. To change the secrets mounted into the Prometheus Pods, the object must be deleted and recreated\r\n    ## with the new list of secrets.\r\n    ##\r\n    secrets: []\r\n\r\n    ## ConfigMaps is a list of ConfigMaps in the same namespace as the Prometheus object, which shall be mounted into the Prometheus Pods.\r\n    ## The ConfigMaps are mounted into /etc/prometheus/configmaps/.\r\n    ##\r\n    configMaps: []\r\n\r\n    ## QuerySpec defines the query command line flags when starting Prometheus.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#queryspec\r\n    ##\r\n    query: {}\r\n\r\n    ## If nil, select own namespace. Namespaces to be selected for PrometheusRules discovery.\r\n    ruleNamespaceSelector: {}\r\n    ## Example which selects PrometheusRules in namespaces with label \"prometheus\" set to \"somelabel\"\r\n    # ruleNamespaceSelector:\r\n    #   matchLabels:\r\n    #     prometheus: somelabel\r\n\r\n    ## If true, a nil or {} value for prometheus.prometheusSpec.ruleSelector will cause the\r\n    ## prometheus resource to be created with selectors based on values in the helm deployment,\r\n    ## which will also match the PrometheusRule resources created\r\n    ##\r\n    ruleSelectorNilUsesHelmValues: true\r\n\r\n    ## PrometheusRules to be selected for target discovery.\r\n    ## If {}, select all PrometheusRules\r\n    ##\r\n    ruleSelector: {}\r\n    ## Example which select all PrometheusRules resources\r\n    ## with label \"prometheus\" with values any of \"example-rules\" or \"example-rules-2\"\r\n    # ruleSelector:\r\n    #   matchExpressions:\r\n    #     - key: prometheus\r\n    #       operator: In\r\n    #       values:\r\n    #         - example-rules\r\n    #         - example-rules-2\r\n    #\r\n    ## Example which select all PrometheusRules resources with label \"role\" set to \"example-rules\"\r\n    # ruleSelector:\r\n    #   matchLabels:\r\n    #     role: example-rules\r\n\r\n    ## If true, a nil or {} value for prometheus.prometheusSpec.serviceMonitorSelector will cause the\r\n    ## prometheus resource to be created with selectors based on values in the helm deployment,\r\n    ## which will also match the servicemonitors created\r\n    ##\r\n    serviceMonitorSelectorNilUsesHelmValues: true\r\n\r\n    ## ServiceMonitors to be selected for target discovery.\r\n    ## If {}, select all ServiceMonitors\r\n    ##\r\n    serviceMonitorSelector: {}\r\n    ## Example which selects ServiceMonitors with label \"prometheus\" set to \"somelabel\"\r\n    # serviceMonitorSelector:\r\n    #   matchLabels:\r\n    #     prometheus: somelabel\r\n\r\n    ## Namespaces to be selected for ServiceMonitor discovery.\r\n    ##\r\n    serviceMonitorNamespaceSelector: {}\r\n    ## Example which selects ServiceMonitors in namespaces with label \"prometheus\" set to \"somelabel\"\r\n    # serviceMonitorNamespaceSelector:\r\n    #   matchLabels:\r\n    #     prometheus: somelabel\r\n\r\n    ## If true, a nil or {} value for prometheus.prometheusSpec.podMonitorSelector will cause the\r\n    ## prometheus resource to be created with selectors based on values in the helm deployment,\r\n    ## which will also match the podmonitors created\r\n    ##\r\n    podMonitorSelectorNilUsesHelmValues: true\r\n\r\n    ## PodMonitors to be selected for target discovery.\r\n    ## If {}, select all PodMonitors\r\n    ##\r\n    podMonitorSelector: {}\r\n    ## Example which selects PodMonitors with label \"prometheus\" set to \"somelabel\"\r\n    # podMonitorSelector:\r\n    #   matchLabels:\r\n    #     prometheus: somelabel\r\n\r\n    ## If nil, select own namespace. Namespaces to be selected for PodMonitor discovery.\r\n    podMonitorNamespaceSelector: {}\r\n    ## Example which selects PodMonitor in namespaces with label \"prometheus\" set to \"somelabel\"\r\n    # podMonitorNamespaceSelector:\r\n    #   matchLabels:\r\n    #     prometheus: somelabel\r\n\r\n    ## If true, a nil or {} value for prometheus.prometheusSpec.probeSelector will cause the\r\n    ## prometheus resource to be created with selectors based on values in the helm deployment,\r\n    ## which will also match the probes created\r\n    ##\r\n    probeSelectorNilUsesHelmValues: true\r\n\r\n    ## Probes to be selected for target discovery.\r\n    ## If {}, select all Probes\r\n    ##\r\n    probeSelector: {}\r\n    ## Example which selects Probes with label \"prometheus\" set to \"somelabel\"\r\n    # probeSelector:\r\n    #   matchLabels:\r\n    #     prometheus: somelabel\r\n\r\n    ## If nil, select own namespace. Namespaces to be selected for Probe discovery.\r\n    probeNamespaceSelector: {}\r\n    ## Example which selects Probe in namespaces with label \"prometheus\" set to \"somelabel\"\r\n    # probeNamespaceSelector:\r\n    #   matchLabels:\r\n    #     prometheus: somelabel\r\n\r\n    ## If true, a nil or {} value for prometheus.prometheusSpec.scrapeConfigSelector will cause the\r\n    ## prometheus resource to be created with selectors based on values in the helm deployment,\r\n    ## which will also match the scrapeConfigs created\r\n    ##\r\n    scrapeConfigSelectorNilUsesHelmValues: true\r\n\r\n    ## scrapeConfigs to be selected for target discovery.\r\n    ## If {}, select all scrapeConfigs\r\n    ##\r\n    scrapeConfigSelector: {}\r\n    ## Example which selects scrapeConfigs with label \"prometheus\" set to \"somelabel\"\r\n    # scrapeConfigSelector:\r\n    #   matchLabels:\r\n    #     prometheus: somelabel\r\n\r\n    ## If nil, select own namespace. Namespaces to be selected for scrapeConfig discovery.\r\n    scrapeConfigNamespaceSelector: {}\r\n    ## Example which selects scrapeConfig in namespaces with label \"prometheus\" set to \"somelabel\"\r\n    # scrapeConfigNamespaceSelector:\r\n    #   matchLabels:\r\n    #     prometheus: somelabel\r\n\r\n    ## How long to retain metrics\r\n    ##\r\n    retention: 10d\r\n\r\n    ## Maximum size of metrics\r\n    ##\r\n    retentionSize: \"\"\r\n\r\n    ## Allow out-of-order/out-of-bounds samples ingested into Prometheus for a specified duration\r\n    ## See https://prometheus.io/docs/prometheus/latest/configuration/configuration/#tsdb\r\n    tsdb:\r\n      outOfOrderTimeWindow: 0s\r\n\r\n    ## Enable compression of the write-ahead log using Snappy.\r\n    ##\r\n    walCompression: true\r\n\r\n    ## If true, the Operator won't process any Prometheus configuration changes\r\n    ##\r\n    paused: false\r\n\r\n    ## Number of replicas of each shard to deploy for a Prometheus deployment.\r\n    ## Number of replicas multiplied by shards is the total number of Pods created.\r\n    ##\r\n    replicas: 1\r\n\r\n    ## EXPERIMENTAL: Number of shards to distribute targets onto.\r\n    ## Number of replicas multiplied by shards is the total number of Pods created.\r\n    ## Note that scaling down shards will not reshard data onto remaining instances, it must be manually moved.\r\n    ## Increasing shards will not reshard data either but it will continue to be available from the same instances.\r\n    ## To query globally use Thanos sidecar and Thanos querier or remote write data to a central location.\r\n    ## Sharding is done on the content of the `__address__` target meta-label.\r\n    ##\r\n    shards: 1\r\n\r\n    ## Log level for Prometheus be configured in\r\n    ##\r\n    logLevel: info\r\n\r\n    ## Log format for Prometheus be configured in\r\n    ##\r\n    logFormat: logfmt\r\n\r\n    ## Prefix used to register routes, overriding externalUrl route.\r\n    ## Useful for proxies that rewrite URLs.\r\n    ##\r\n    routePrefix: /\r\n\r\n    ## Standard object's metadata. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata\r\n    ## Metadata Labels and Annotations gets propagated to the prometheus pods.\r\n    ##\r\n    podMetadata: {}\r\n    # labels:\r\n    #   app: prometheus\r\n    #   k8s-app: prometheus\r\n\r\n    ## Pod anti-affinity can prevent the scheduler from placing Prometheus replicas on the same node.\r\n    ## The default value \"soft\" means that the scheduler should *prefer* to not schedule two replica pods onto the same node but no guarantee is provided.\r\n    ## The value \"hard\" means that the scheduler is *required* to not schedule two replica pods onto the same node.\r\n    ## The value \"\" will disable pod anti-affinity so that no anti-affinity rules will be configured.\r\n    podAntiAffinity: \"\"\r\n\r\n    ## If anti-affinity is enabled sets the topologyKey to use for anti-affinity.\r\n    ## This can be changed to, for example, failure-domain.beta.kubernetes.io/zone\r\n    ##\r\n    podAntiAffinityTopologyKey: kubernetes.io/hostname\r\n\r\n    ## Assign custom affinity rules to the prometheus instance\r\n    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\r\n    ##\r\n    affinity: {}\r\n    # nodeAffinity:\r\n    #   requiredDuringSchedulingIgnoredDuringExecution:\r\n    #     nodeSelectorTerms:\r\n    #     - matchExpressions:\r\n    #       - key: kubernetes.io/e2e-az-name\r\n    #         operator: In\r\n    #         values:\r\n    #         - e2e-az1\r\n    #         - e2e-az2\r\n\r\n    ## The remote_read spec configuration for Prometheus.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#remotereadspec\r\n    remoteRead: []\r\n    # - url: http://remote1/read\r\n    ## additionalRemoteRead is appended to remoteRead\r\n    additionalRemoteRead: []\r\n\r\n    ## The remote_write spec configuration for Prometheus.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#remotewritespec\r\n    remoteWrite: []\r\n    # - url: http://remote1/push\r\n    ## additionalRemoteWrite is appended to remoteWrite\r\n    additionalRemoteWrite: []\r\n\r\n    ## Enable/Disable Grafana dashboards provisioning for prometheus remote write feature\r\n    remoteWriteDashboards: false\r\n\r\n    ## Resource limits \u0026 requests\r\n    ##\r\n    resources: {}\r\n    # requests:\r\n    #   memory: 400Mi\r\n\r\n    ## Prometheus StorageSpec for persistent data\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md\r\n    ##\r\n    storageSpec: {}\r\n    ## Using PersistentVolumeClaim\r\n    ##\r\n    #  volumeClaimTemplate:\r\n    #    spec:\r\n    #      storageClassName: gluster\r\n    #      accessModes: [\"ReadWriteOnce\"]\r\n    #      resources:\r\n    #        requests:\r\n    #          storage: 50Gi\r\n    #    selector: {}\r\n\r\n    ## Using tmpfs volume\r\n    ##\r\n    #  emptyDir:\r\n    #    medium: Memory\r\n\r\n    # Additional volumes on the output StatefulSet definition.\r\n    volumes: []\r\n\r\n    # Additional VolumeMounts on the output StatefulSet definition.\r\n    volumeMounts: []\r\n\r\n    ## AdditionalScrapeConfigs allows specifying additional Prometheus scrape configurations. Scrape configurations\r\n    ## are appended to the configurations generated by the Prometheus Operator. Job configurations must have the form\r\n    ## as specified in the official Prometheus documentation:\r\n    ## https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config. As scrape configs are\r\n    ## appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility\r\n    ## to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible\r\n    ## scrape configs are going to break Prometheus after the upgrade.\r\n    ## AdditionalScrapeConfigs can be defined as a list or as a templated string.\r\n    ##\r\n    ## The scrape configuration example below will find master nodes, provided they have the name .*mst.*, relabel the\r\n    ## port to 2379 and allow etcd scraping provided it is running on all Kubernetes master nodes\r\n    ##\r\n    additionalScrapeConfigs: []\r\n    # - job_name: kube-etcd\r\n    #   kubernetes_sd_configs:\r\n    #     - role: node\r\n    #   scheme: https\r\n    #   tls_config:\r\n    #     ca_file:   /etc/prometheus/secrets/etcd-client-cert/etcd-ca\r\n    #     cert_file: /etc/prometheus/secrets/etcd-client-cert/etcd-client\r\n    #     key_file:  /etc/prometheus/secrets/etcd-client-cert/etcd-client-key\r\n    #   relabel_configs:\r\n    #   - action: labelmap\r\n    #     regex: __meta_kubernetes_node_label_(.+)\r\n    #   - source_labels: [__address__]\r\n    #     action: replace\r\n    #     targetLabel: __address__\r\n    #     regex: ([^:;]+):(\\d+)\r\n    #     replacement: ${1}:2379\r\n    #   - source_labels: [__meta_kubernetes_node_name]\r\n    #     action: keep\r\n    #     regex: .*mst.*\r\n    #   - source_labels: [__meta_kubernetes_node_name]\r\n    #     action: replace\r\n    #     targetLabel: node\r\n    #     regex: (.*)\r\n    #     replacement: ${1}\r\n    #   metric_relabel_configs:\r\n    #   - regex: (kubernetes_io_hostname|failure_domain_beta_kubernetes_io_region|beta_kubernetes_io_os|beta_kubernetes_io_arch|beta_kubernetes_io_instance_type|failure_domain_beta_kubernetes_io_zone)\r\n    #     action: labeldrop\r\n    #\r\n    ## If scrape config contains a repetitive section, you may want to use a template.\r\n    ## In the following example, you can see how to define `gce_sd_configs` for multiple zones\r\n    # additionalScrapeConfigs: |\r\n    #  - job_name: \"node-exporter\"\r\n    #    gce_sd_configs:\r\n    #    {{range $zone := .Values.gcp_zones}}\r\n    #    - project: \"project1\"\r\n    #      zone: \"{{$zone}}\"\r\n    #      port: 9100\r\n    #    {{end}}\r\n    #    relabel_configs:\r\n    #    ...\r\n\r\n\r\n    ## If additional scrape configurations are already deployed in a single secret file you can use this section.\r\n    ## Expected values are the secret name and key\r\n    ## Cannot be used with additionalScrapeConfigs\r\n    additionalScrapeConfigsSecret: {}\r\n      # enabled: false\r\n      # name:\r\n      # key:\r\n\r\n    ## additionalPrometheusSecretsAnnotations allows to add annotations to the kubernetes secret. This can be useful\r\n    ## when deploying via spinnaker to disable versioning on the secret, strategy.spinnaker.io/versioned: 'false'\r\n    additionalPrometheusSecretsAnnotations: {}\r\n\r\n    ## AdditionalAlertManagerConfigs allows for manual configuration of alertmanager jobs in the form as specified\r\n    ## in the official Prometheus documentation https://prometheus.io/docs/prometheus/latest/configuration/configuration/#\u003calertmanager_config\u003e.\r\n    ## AlertManager configurations specified are appended to the configurations generated by the Prometheus Operator.\r\n    ## As AlertManager configs are appended, the user is responsible to make sure it is valid. Note that using this\r\n    ## feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release\r\n    ## notes to ensure that no incompatible AlertManager configs are going to break Prometheus after the upgrade.\r\n    ##\r\n    additionalAlertManagerConfigs: []\r\n    # - consul_sd_configs:\r\n    #   - server: consul.dev.test:8500\r\n    #     scheme: http\r\n    #     datacenter: dev\r\n    #     tag_separator: ','\r\n    #     services:\r\n    #       - metrics-prometheus-alertmanager\r\n\r\n    ## If additional alertmanager configurations are already deployed in a single secret, or you want to manage\r\n    ## them separately from the helm deployment, you can use this section.\r\n    ## Expected values are the secret name and key\r\n    ## Cannot be used with additionalAlertManagerConfigs\r\n    additionalAlertManagerConfigsSecret: {}\r\n      # name:\r\n      # key:\r\n      # optional: false\r\n\r\n    ## AdditionalAlertRelabelConfigs allows specifying Prometheus alert relabel configurations. Alert relabel configurations specified are appended\r\n    ## to the configurations generated by the Prometheus Operator. Alert relabel configurations specified must have the form as specified in the\r\n    ## official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#alert_relabel_configs.\r\n    ## As alert relabel configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the\r\n    ## possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible alert relabel\r\n    ## configs are going to break Prometheus after the upgrade.\r\n    ##\r\n    additionalAlertRelabelConfigs: []\r\n    # - separator: ;\r\n    #   regex: prometheus_replica\r\n    #   replacement: $1\r\n    #   action: labeldrop\r\n\r\n    ## If additional alert relabel configurations are already deployed in a single secret, or you want to manage\r\n    ## them separately from the helm deployment, you can use this section.\r\n    ## Expected values are the secret name and key\r\n    ## Cannot be used with additionalAlertRelabelConfigs\r\n    additionalAlertRelabelConfigsSecret: {}\r\n      # name:\r\n      # key:\r\n\r\n    ## SecurityContext holds pod-level security attributes and common container settings.\r\n    ## This defaults to non root user with uid 1000 and gid 2000.\r\n    ## https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md\r\n    ##\r\n    securityContext:\r\n      runAsGroup: 2000\r\n      runAsNonRoot: true\r\n      runAsUser: 1000\r\n      fsGroup: 2000\r\n      seccompProfile:\r\n        type: RuntimeDefault\r\n\r\n    ## Priority class assigned to the Pods\r\n    ##\r\n    priorityClassName: \"\"\r\n\r\n    ## Thanos configuration allows configuring various aspects of a Prometheus server in a Thanos environment.\r\n    ## This section is experimental, it may change significantly without deprecation notice in any release.\r\n    ## This is experimental and may change significantly without backward compatibility in any release.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#thanosspec\r\n    ##\r\n    thanos: {}\r\n      # secretProviderClass:\r\n      #   provider: gcp\r\n      #   parameters:\r\n      #     secrets: |\r\n      #       - resourceName: \"projects/$PROJECT_ID/secrets/testsecret/versions/latest\"\r\n      #         fileName: \"objstore.yaml\"\r\n      ## ObjectStorageConfig configures object storage in Thanos.\r\n      # objectStorageConfig:\r\n      #   # use existing secret, if configured, objectStorageConfig.secret will not be used\r\n      #   existingSecret: {}\r\n      #     # name: \"\"\r\n      #     # key: \"\"\r\n      #   # will render objectStorageConfig secret data and configure it to be used by Thanos custom resource,\r\n      #   # ignored when prometheusspec.thanos.objectStorageConfig.existingSecret is set\r\n      #   # https://thanos.io/tip/thanos/storage.md/#s3\r\n      #   secret: {}\r\n      #     # type: S3\r\n      #     # config:\r\n      #     #   bucket: \"\"\r\n      #     #   endpoint: \"\"\r\n      #     #   region: \"\"\r\n      #     #   access_key: \"\"\r\n      #     #   secret_key: \"\"\r\n\r\n    ## Containers allows injecting additional containers. This is meant to allow adding an authentication proxy to a Prometheus pod.\r\n    ## if using proxy extraContainer update targetPort with proxy container port\r\n    containers: []\r\n    # containers:\r\n    # - name: oauth-proxy\r\n    #   image: quay.io/oauth2-proxy/oauth2-proxy:v7.5.1\r\n    #   args:\r\n    #   - --upstream=http://127.0.0.1:9090\r\n    #   - --http-address=0.0.0.0:8081\r\n    #   - --metrics-address=0.0.0.0:8082\r\n    #   - ...\r\n    #   ports:\r\n    #   - containerPort: 8081\r\n    #     name: oauth-proxy\r\n    #     protocol: TCP\r\n    #   - containerPort: 8082\r\n    #     name: oauth-metrics\r\n    #     protocol: TCP\r\n    #   resources: {}\r\n\r\n    ## InitContainers allows injecting additional initContainers. This is meant to allow doing some changes\r\n    ## (permissions, dir tree) on mounted volumes before starting prometheus\r\n    initContainers: []\r\n\r\n    ## PortName to use for Prometheus.\r\n    ##\r\n    portName: \"http-web\"\r\n\r\n    ## ArbitraryFSAccessThroughSMs configures whether configuration based on a service monitor can access arbitrary files\r\n    ## on the file system of the Prometheus container e.g. bearer token files.\r\n    arbitraryFSAccessThroughSMs: false\r\n\r\n    ## OverrideHonorLabels if set to true overrides all user configured honor_labels. If HonorLabels is set in ServiceMonitor\r\n    ## or PodMonitor to true, this overrides honor_labels to false.\r\n    overrideHonorLabels: false\r\n\r\n    ## OverrideHonorTimestamps allows to globally enforce honoring timestamps in all scrape configs.\r\n    overrideHonorTimestamps: false\r\n\r\n    ## When ignoreNamespaceSelectors is set to true, namespaceSelector from all PodMonitor, ServiceMonitor and Probe objects will be ignored,\r\n    ## they will only discover targets within the namespace of the PodMonitor, ServiceMonitor and Probe object,\r\n    ## and servicemonitors will be installed in the default service namespace.\r\n    ## Defaults to false.\r\n    ignoreNamespaceSelectors: false\r\n\r\n    ## EnforcedNamespaceLabel enforces adding a namespace label of origin for each alert and metric that is user created.\r\n    ## The label value will always be the namespace of the object that is being created.\r\n    ## Disabled by default\r\n    enforcedNamespaceLabel: \"\"\r\n\r\n    ## PrometheusRulesExcludedFromEnforce - list of prometheus rules to be excluded from enforcing of adding namespace labels.\r\n    ## Works only if enforcedNamespaceLabel set to true. Make sure both ruleNamespace and ruleName are set for each pair\r\n    ## Deprecated, use `excludedFromEnforcement` instead\r\n    prometheusRulesExcludedFromEnforce: []\r\n\r\n    ## ExcludedFromEnforcement - list of object references to PodMonitor, ServiceMonitor, Probe and PrometheusRule objects\r\n    ## to be excluded from enforcing a namespace label of origin.\r\n    ## Works only if enforcedNamespaceLabel set to true.\r\n    ## See https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#objectreference\r\n    excludedFromEnforcement: []\r\n\r\n    ## QueryLogFile specifies the file to which PromQL queries are logged. Note that this location must be writable,\r\n    ## and can be persisted using an attached volume. Alternatively, the location can be set to a stdout location such\r\n    ## as /dev/stdout to log querie information to the default Prometheus log stream. This is only available in versions\r\n    ## of Prometheus \u003e= 2.16.0. For more details, see the Prometheus docs (https://prometheus.io/docs/guides/query-log/)\r\n    queryLogFile: false\r\n\r\n    # Use to set global sample_limit for Prometheus. This act as default SampleLimit for ServiceMonitor or/and PodMonitor.\r\n    # Set to 'false' to disable global sample_limit. or set to a number to override the default value.\r\n    sampleLimit: false\r\n\r\n    # EnforcedKeepDroppedTargetsLimit defines on the number of targets dropped by relabeling that will be kept in memory.\r\n    # The value overrides any spec.keepDroppedTargets set by ServiceMonitor, PodMonitor, Probe objects unless spec.keepDroppedTargets\r\n    # is greater than zero and less than spec.enforcedKeepDroppedTargets. 0 means no limit.\r\n    enforcedKeepDroppedTargets: 0\r\n\r\n    ## EnforcedSampleLimit defines global limit on number of scraped samples that will be accepted. This overrides any SampleLimit\r\n    ## set per ServiceMonitor or/and PodMonitor. It is meant to be used by admins to enforce the SampleLimit to keep overall\r\n    ## number of samples/series under the desired limit. Note that if SampleLimit is lower that value will be taken instead.\r\n    enforcedSampleLimit: false\r\n\r\n    ## EnforcedTargetLimit defines a global limit on the number of scraped targets. This overrides any TargetLimit set\r\n    ## per ServiceMonitor or/and PodMonitor. It is meant to be used by admins to enforce the TargetLimit to keep the overall\r\n    ## number of targets under the desired limit. Note that if TargetLimit is lower, that value will be taken instead, except\r\n    ## if either value is zero, in which case the non-zero value will be used. If both values are zero, no limit is enforced.\r\n    enforcedTargetLimit: false\r\n\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. If more than this number of labels are present\r\n    ## post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus versions\r\n    ## 2.27.0 and newer.\r\n    enforcedLabelLimit: false\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. If a label name is longer than this number\r\n    ## post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus versions\r\n    ## 2.27.0 and newer.\r\n    enforcedLabelNameLengthLimit: false\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. If a label value is longer than this\r\n    ## number post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus\r\n    ## versions 2.27.0 and newer.\r\n    enforcedLabelValueLengthLimit: false\r\n\r\n    ## AllowOverlappingBlocks enables vertical compaction and vertical query merge in Prometheus. This is still experimental\r\n    ## in Prometheus so it may change in any upcoming release.\r\n    allowOverlappingBlocks: false\r\n\r\n    ## Minimum number of seconds for which a newly created pod should be ready without any of its container crashing for it to\r\n    ## be considered available. Defaults to 0 (pod will be considered available as soon as it is ready).\r\n    minReadySeconds: 0\r\n\r\n    # Required for use in managed kubernetes clusters (such as AWS EKS) with custom CNI (such as calico),\r\n    # because control-plane managed by AWS cannot communicate with pods' IP CIDR and admission webhooks are not working\r\n    # Use the host's network namespace if true. Make sure to understand the security implications if you want to enable it.\r\n    # When hostNetwork is enabled, this will set dnsPolicy to ClusterFirstWithHostNet automatically.\r\n    hostNetwork: false\r\n\r\n    # HostAlias holds the mapping between IP and hostnames that will be injected\r\n    # as an entry in the pods hosts file.\r\n    hostAliases: []\r\n    #  - ip: 10.10.0.100\r\n    #    hostnames:\r\n    #      - a1.app.local\r\n    #      - b1.app.local\r\n\r\n    ## TracingConfig configures tracing in Prometheus.\r\n    ## See https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#prometheustracingconfig\r\n    tracingConfig: {}\r\n\r\n    ## Defines the service discovery role used to discover targets from ServiceMonitor objects and Alertmanager endpoints.\r\n    ## If set, the value should be either Endpoints or EndpointSlice. If unset, the operator assumes the Endpoints role.\r\n    serviceDiscoveryRole: \"\"\r\n\r\n    ## Additional configuration which is not covered by the properties above. (passed through tpl)\r\n    additionalConfig: {}\r\n\r\n    ## Additional configuration which is not covered by the properties above.\r\n    ## Useful, if you need advanced templating inside alertmanagerSpec.\r\n    ## Otherwise, use prometheus.prometheusSpec.additionalConfig (passed through tpl)\r\n    additionalConfigString: \"\"\r\n\r\n    ## Defines the maximum time that the `prometheus` container's startup probe\r\n    ## will wait before being considered failed. The startup probe will return\r\n    ## success after the WAL replay is complete. If set, the value should be\r\n    ## greater than 60 (seconds). Otherwise it will be equal to 900 seconds (15\r\n    ## minutes).\r\n    maximumStartupDurationSeconds: 0\r\n\r\n  additionalRulesForClusterRole: []\r\n  #  - apiGroups: [ \"\" ]\r\n  #    resources:\r\n  #      - nodes/proxy\r\n  #    verbs: [ \"get\", \"list\", \"watch\" ]\r\n\r\n  additionalServiceMonitors: []\r\n  ## Name of the ServiceMonitor to create\r\n  ##\r\n  # - name: \"\"\r\n\r\n    ## Additional labels to set used for the ServiceMonitorSelector. Together with standard labels from\r\n    ## the chart\r\n    ##\r\n    # additionalLabels: {}\r\n\r\n    ## Service label for use in assembling a job name of the form \u003clabel value\u003e-\u003cport\u003e\r\n    ## If no label is specified, the service name is used.\r\n    ##\r\n    # jobLabel: \"\"\r\n\r\n    ## labels to transfer from the kubernetes service to the target\r\n    ##\r\n    # targetLabels: []\r\n\r\n    ## labels to transfer from the kubernetes pods to the target\r\n    ##\r\n    # podTargetLabels: []\r\n\r\n    ## Label selector for services to which this ServiceMonitor applies\r\n    ##\r\n    # selector: {}\r\n\r\n    ## Namespaces from which services are selected\r\n    ##\r\n    # namespaceSelector:\r\n      ## Match any namespace\r\n      ##\r\n      # any: false\r\n\r\n      ## Explicit list of namespace names to select\r\n      ##\r\n      # matchNames: []\r\n\r\n    ## Endpoints of the selected service to be monitored\r\n    ##\r\n    # endpoints: []\r\n      ## Name of the endpoint's service port\r\n      ## Mutually exclusive with targetPort\r\n      # - port: \"\"\r\n\r\n      ## Name or number of the endpoint's target port\r\n      ## Mutually exclusive with port\r\n      # - targetPort: \"\"\r\n\r\n      ## File containing bearer token to be used when scraping targets\r\n      ##\r\n      #   bearerTokenFile: \"\"\r\n\r\n      ## Interval at which metrics should be scraped\r\n      ##\r\n      #   interval: 30s\r\n\r\n      ## HTTP path to scrape for metrics\r\n      ##\r\n      #   path: /metrics\r\n\r\n      ## HTTP scheme to use for scraping\r\n      ##\r\n      #   scheme: http\r\n\r\n      ## TLS configuration to use when scraping the endpoint\r\n      ##\r\n      #   tlsConfig:\r\n\r\n          ## Path to the CA file\r\n          ##\r\n          # caFile: \"\"\r\n\r\n          ## Path to client certificate file\r\n          ##\r\n          # certFile: \"\"\r\n\r\n          ## Skip certificate verification\r\n          ##\r\n          # insecureSkipVerify: false\r\n\r\n          ## Path to client key file\r\n          ##\r\n          # keyFile: \"\"\r\n\r\n          ## Server name used to verify host name\r\n          ##\r\n          # serverName: \"\"\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    # metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    # relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n  additionalPodMonitors: []\r\n  ## Name of the PodMonitor to create\r\n  ##\r\n  # - name: \"\"\r\n\r\n    ## Additional labels to set used for the PodMonitorSelector. Together with standard labels from\r\n    ## the chart\r\n    ##\r\n    # additionalLabels: {}\r\n\r\n    ## Pod label for use in assembling a job name of the form \u003clabel value\u003e-\u003cport\u003e\r\n    ## If no label is specified, the pod endpoint name is used.\r\n    ##\r\n    # jobLabel: \"\"\r\n\r\n    ## Label selector for pods to which this PodMonitor applies\r\n    ##\r\n    # selector: {}\r\n\r\n    ## PodTargetLabels transfers labels on the Kubernetes Pod onto the target.\r\n    ##\r\n    # podTargetLabels: {}\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    # sampleLimit: 0\r\n\r\n    ## Namespaces from which pods are selected\r\n    ##\r\n    # namespaceSelector:\r\n      ## Match any namespace\r\n      ##\r\n      # any: false\r\n\r\n      ## Explicit list of namespace names to select\r\n      ##\r\n      # matchNames: []\r\n\r\n    ## Endpoints of the selected pods to be monitored\r\n    ## https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#podmetricsendpoint\r\n    ##\r\n    # podMetricsEndpoints: []\r\n\r\n## Configuration for thanosRuler\r\n## ref: https://thanos.io/tip/components/rule.md/\r\n##\r\nthanosRuler:\r\n\r\n  ## Deploy thanosRuler\r\n  ##\r\n  enabled: false\r\n\r\n  ## Annotations for ThanosRuler\r\n  ##\r\n  annotations: {}\r\n\r\n  ## Service account for ThanosRuler to use.\r\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\r\n  ##\r\n  serviceAccount:\r\n    create: true\r\n    name: \"\"\r\n    annotations: {}\r\n\r\n  ## Configure pod disruption budgets for ThanosRuler\r\n  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget\r\n  ##\r\n  podDisruptionBudget:\r\n    enabled: false\r\n    minAvailable: 1\r\n    maxUnavailable: \"\"\r\n\r\n  ingress:\r\n    enabled: false\r\n\r\n    # For Kubernetes \u003e= 1.18 you should specify the ingress-controller via the field ingressClassName\r\n    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\r\n    # ingressClassName: nginx\r\n\r\n    annotations: {}\r\n\r\n    labels: {}\r\n\r\n    ## Hosts must be provided if Ingress is enabled.\r\n    ##\r\n    hosts: []\r\n      # - thanosruler.domain.com\r\n\r\n    ## Paths to use for ingress rules - one path should match the thanosruler.routePrefix\r\n    ##\r\n    paths: []\r\n    # - /\r\n\r\n    ## For Kubernetes \u003e= 1.18 you should specify the pathType (determines how Ingress paths should be matched)\r\n    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types\r\n    # pathType: ImplementationSpecific\r\n\r\n    ## TLS configuration for ThanosRuler Ingress\r\n    ## Secret must be manually created in the namespace\r\n    ##\r\n    tls: []\r\n    # - secretName: thanosruler-general-tls\r\n    #   hosts:\r\n    #   - thanosruler.example.com\r\n\r\n  ## Configuration for ThanosRuler service\r\n  ##\r\n  service:\r\n    annotations: {}\r\n    labels: {}\r\n    clusterIP: \"\"\r\n    ipDualStack:\r\n      enabled: false\r\n      ipFamilies: [\"IPv6\", \"IPv4\"]\r\n      ipFamilyPolicy: \"PreferDualStack\"\r\n\r\n    ## Port for ThanosRuler Service to listen on\r\n    ##\r\n    port: 10902\r\n    ## To be used with a proxy extraContainer port\r\n    ##\r\n    targetPort: 10902\r\n    ## Port to expose on each node\r\n    ## Only used if service.type is 'NodePort'\r\n    ##\r\n    nodePort: 30905\r\n    ## List of IP addresses at which the Prometheus server service is available\r\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\r\n    ##\r\n\r\n    ## Additional ports to open for ThanosRuler service\r\n    additionalPorts: []\r\n\r\n    externalIPs: []\r\n    loadBalancerIP: \"\"\r\n    loadBalancerSourceRanges: []\r\n\r\n    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\r\n    ##\r\n    externalTrafficPolicy: Cluster\r\n\r\n    ## Service type\r\n    ##\r\n    type: ClusterIP\r\n\r\n  ## Configuration for creating a ServiceMonitor for the ThanosRuler service\r\n  ##\r\n  serviceMonitor:\r\n    ## If true, create a serviceMonitor for thanosRuler\r\n    ##\r\n    selfMonitor: true\r\n\r\n    ## Scrape interval. If not set, the Prometheus default scrape interval is used.\r\n    ##\r\n    interval: \"\"\r\n\r\n    ## Additional labels\r\n    ##\r\n    additionalLabels: {}\r\n\r\n    ## SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.\r\n    ##\r\n    sampleLimit: 0\r\n\r\n    ## TargetLimit defines a limit on the number of scraped targets that will be accepted.\r\n    ##\r\n    targetLimit: 0\r\n\r\n    ## Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelNameLengthLimit: 0\r\n\r\n    ## Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.\r\n    ##\r\n    labelValueLengthLimit: 0\r\n\r\n    ## proxyUrl: URL of a proxy that should be used for scraping.\r\n    ##\r\n    proxyUrl: \"\"\r\n\r\n    ## scheme: HTTP scheme to use for scraping. Can be used with `tlsConfig` for example if using istio mTLS.\r\n    scheme: \"\"\r\n\r\n    ## tlsConfig: TLS configuration to use when scraping the endpoint. For example if using istio mTLS.\r\n    ## Of type: https://github.com/coreos/prometheus-operator/blob/main/Documentation/api.md#tlsconfig\r\n    tlsConfig: {}\r\n\r\n    bearerTokenFile:\r\n\r\n    ## MetricRelabelConfigs to apply to samples after scraping, but before ingestion.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    metricRelabelings: []\r\n    # - action: keep\r\n    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'\r\n    #   sourceLabels: [__name__]\r\n\r\n    ## RelabelConfigs to apply to samples before scraping\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig\r\n    ##\r\n    relabelings: []\r\n    # - sourceLabels: [__meta_kubernetes_pod_node_name]\r\n    #   separator: ;\r\n    #   regex: ^(.*)$\r\n    #   targetLabel: nodename\r\n    #   replacement: $1\r\n    #   action: replace\r\n\r\n    ## Additional Endpoints\r\n    ##\r\n    additionalEndpoints: []\r\n    # - port: oauth-metrics\r\n    #   path: /metrics\r\n\r\n  ## Settings affecting thanosRulerpec\r\n  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#thanosrulerspec\r\n  ##\r\n  thanosRulerSpec:\r\n    ## Standard object's metadata. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata\r\n    ## Metadata Labels and Annotations gets propagated to the ThanosRuler pods.\r\n    ##\r\n    podMetadata: {}\r\n\r\n    ## Image of ThanosRuler\r\n    ##\r\n    image:\r\n      registry: quay.io\r\n      repository: thanos/thanos\r\n      tag: v0.36.1\r\n      sha: \"\"\r\n\r\n    ## Namespaces to be selected for PrometheusRules discovery.\r\n    ## If nil, select own namespace. Namespaces to be selected for ServiceMonitor discovery.\r\n    ## See https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#namespaceselector for usage\r\n    ##\r\n    ruleNamespaceSelector: {}\r\n\r\n    ## If true, a nil or {} value for thanosRuler.thanosRulerSpec.ruleSelector will cause the\r\n    ## prometheus resource to be created with selectors based on values in the helm deployment,\r\n    ## which will also match the PrometheusRule resources created\r\n    ##\r\n    ruleSelectorNilUsesHelmValues: true\r\n\r\n    ## PrometheusRules to be selected for target discovery.\r\n    ## If {}, select all PrometheusRules\r\n    ##\r\n    ruleSelector: {}\r\n    ## Example which select all PrometheusRules resources\r\n    ## with label \"prometheus\" with values any of \"example-rules\" or \"example-rules-2\"\r\n    # ruleSelector:\r\n    #   matchExpressions:\r\n    #     - key: prometheus\r\n    #       operator: In\r\n    #       values:\r\n    #         - example-rules\r\n    #         - example-rules-2\r\n    #\r\n    ## Example which select all PrometheusRules resources with label \"role\" set to \"example-rules\"\r\n    # ruleSelector:\r\n    #   matchLabels:\r\n    #     role: example-rules\r\n\r\n    ## Define Log Format\r\n    # Use logfmt (default) or json logging\r\n    logFormat: logfmt\r\n\r\n    ## Log level for ThanosRuler to be configured with.\r\n    ##\r\n    logLevel: info\r\n\r\n    ## Size is the expected size of the thanosRuler cluster. The controller will eventually make the size of the\r\n    ## running cluster equal to the expected size.\r\n    replicas: 1\r\n\r\n    ## Time duration ThanosRuler shall retain data for. Default is '24h', and must match the regular expression\r\n    ## [0-9]+(ms|s|m|h) (milliseconds seconds minutes hours).\r\n    ##\r\n    retention: 24h\r\n\r\n    ## Interval between consecutive evaluations.\r\n    ##\r\n    evaluationInterval: \"\"\r\n\r\n    ## Storage is the definition of how storage will be used by the ThanosRuler instances.\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md\r\n    ##\r\n    storage: {}\r\n    # volumeClaimTemplate:\r\n    #   spec:\r\n    #     storageClassName: gluster\r\n    #     accessModes: [\"ReadWriteOnce\"]\r\n    #     resources:\r\n    #       requests:\r\n    #         storage: 50Gi\r\n    #   selector: {}\r\n\r\n    ## AlertmanagerConfig define configuration for connecting to alertmanager.\r\n    ## Only available with Thanos v0.10.0 and higher. Maps to the alertmanagers.config Thanos Ruler arg.\r\n    alertmanagersConfig:\r\n      # use existing secret, if configured, alertmanagersConfig.secret will not be used\r\n      existingSecret: {}\r\n        # name: \"\"\r\n        # key: \"\"\r\n      # will render render alertmanagersConfig secret data and configure it to be used by Thanos Ruler custom resource, ignored when alertmanagersConfig.existingSecret is set\r\n      # https://thanos.io/tip/components/rule.md/#alertmanager\r\n      secret: {}\r\n        # alertmanagers:\r\n        # - api_version: v2\r\n        #   http_config:\r\n        #     basic_auth:\r\n        #       username: some_user\r\n        #       password: some_pass\r\n        #   static_configs:\r\n        #     - alertmanager.thanos.io\r\n        #   scheme: http\r\n        #   timeout: 10s\r\n\r\n    ## DEPRECATED. Define URLs to send alerts to Alertmanager. For Thanos v0.10.0 and higher, alertmanagersConfig should be used instead.\r\n    ## Note: this field will be ignored if alertmanagersConfig is specified. Maps to the alertmanagers.url Thanos Ruler arg.\r\n    # alertmanagersUrl:\r\n\r\n    ## The external URL the Thanos Ruler instances will be available under. This is necessary to generate correct URLs. This is necessary if Thanos Ruler is not served from root of a DNS name. string false\r\n    ##\r\n    externalPrefix:\r\n\r\n    ## If true, http://{{ template \"kube-prometheus-stack.thanosRuler.name\" . }}.{{ template \"kube-prometheus-stack.namespace\" . }}:{{ .Values.thanosRuler.service.port }}\r\n    ## will be used as value for externalPrefix\r\n    externalPrefixNilUsesHelmValues: true\r\n\r\n    ## The route prefix ThanosRuler registers HTTP handlers for. This is useful, if using ExternalURL and a proxy is rewriting HTTP routes of a request, and the actual ExternalURL is still true,\r\n    ## but the server serves requests under a different route prefix. For example for use with kubectl proxy.\r\n    ##\r\n    routePrefix: /\r\n\r\n    ## ObjectStorageConfig configures object storage in Thanos\r\n    objectStorageConfig:\r\n      # use existing secret, if configured, objectStorageConfig.secret will not be used\r\n      existingSecret: {}\r\n        # name: \"\"\r\n        # key: \"\"\r\n      # will render objectStorageConfig secret data and configure it to be used by Thanos Ruler custom resource, ignored when objectStorageConfig.existingSecret is set\r\n      # https://thanos.io/tip/thanos/storage.md/#s3\r\n      secret: {}\r\n        # type: S3\r\n        # config:\r\n        #   bucket: \"\"\r\n        #   endpoint: \"\"\r\n        #   region: \"\"\r\n        #   access_key: \"\"\r\n        #   secret_key: \"\"\r\n\r\n    ## Labels by name to drop before sending to alertmanager\r\n    ## Maps to the --alert.label-drop flag of thanos ruler.\r\n    alertDropLabels: []\r\n\r\n    ## QueryEndpoints defines Thanos querier endpoints from which to query metrics.\r\n    ## Maps to the --query flag of thanos ruler.\r\n    queryEndpoints: []\r\n\r\n    ## Define configuration for connecting to thanos query instances. If this is defined, the queryEndpoints field will be ignored.\r\n    ## Maps to the query.config CLI argument. Only available with thanos v0.11.0 and higher.\r\n    queryConfig:\r\n      # use existing secret, if configured, queryConfig.secret will not be used\r\n      existingSecret: {}\r\n        # name: \"\"\r\n        # key: \"\"\r\n      # render queryConfig secret data and configure it to be used by Thanos Ruler custom resource, ignored when queryConfig.existingSecret is set\r\n      # https://thanos.io/tip/components/rule.md/#query-api\r\n      secret: {}\r\n        # - http_config:\r\n        #     basic_auth:\r\n        #       username: some_user\r\n        #       password: some_pass\r\n        #   static_configs:\r\n        #     - URL\r\n        #   scheme: http\r\n        #   timeout: 10s\r\n\r\n    ## Labels configure the external label pairs to ThanosRuler. A default replica\r\n    ## label `thanos_ruler_replica` will be always added as a label with the value\r\n    ## of the pod's name and it will be dropped in the alerts.\r\n    labels: {}\r\n\r\n    ## If set to true all actions on the underlying managed objects are not going to be performed, except for delete actions.\r\n    ##\r\n    paused: false\r\n\r\n    ## Allows setting additional arguments for the ThanosRuler container\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#thanosruler\r\n    ##\r\n    additionalArgs: []\r\n      # - name: remote-write.config\r\n      #   value: |-\r\n      #     \"remote_write\":\r\n      #     - \"name\": \"receiver-0\"\r\n      #       \"remote_timeout\": \"30s\"\r\n      #       \"url\": \"http://thanos-receiver-0.thanos-receiver:8081/api/v1/receive\"\r\n\r\n    ## Define which Nodes the Pods are scheduled on.\r\n    ## ref: https://kubernetes.io/docs/user-guide/node-selection/\r\n    ##\r\n    nodeSelector: {}\r\n\r\n    ## Define resources requests and limits for single Pods.\r\n    ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\r\n    ##\r\n    resources: {}\r\n    # requests:\r\n    #   memory: 400Mi\r\n\r\n    ## Pod anti-affinity can prevent the scheduler from placing Prometheus replicas on the same node.\r\n    ## The default value \"soft\" means that the scheduler should *prefer* to not schedule two replica pods onto the same node but no guarantee is provided.\r\n    ## The value \"hard\" means that the scheduler is *required* to not schedule two replica pods onto the same node.\r\n    ## The value \"\" will disable pod anti-affinity so that no anti-affinity rules will be configured.\r\n    ##\r\n    podAntiAffinity: \"\"\r\n\r\n    ## If anti-affinity is enabled sets the topologyKey to use for anti-affinity.\r\n    ## This can be changed to, for example, failure-domain.beta.kubernetes.io/zone\r\n    ##\r\n    podAntiAffinityTopologyKey: kubernetes.io/hostname\r\n\r\n    ## Assign custom affinity rules to the thanosRuler instance\r\n    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\r\n    ##\r\n    affinity: {}\r\n    # nodeAffinity:\r\n    #   requiredDuringSchedulingIgnoredDuringExecution:\r\n    #     nodeSelectorTerms:\r\n    #     - matchExpressions:\r\n    #       - key: kubernetes.io/e2e-az-name\r\n    #         operator: In\r\n    #         values:\r\n    #         - e2e-az1\r\n    #         - e2e-az2\r\n\r\n    ## If specified, the pod's tolerations.\r\n    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\r\n    ##\r\n    tolerations: []\r\n    # - key: \"key\"\r\n    #   operator: \"Equal\"\r\n    #   value: \"value\"\r\n    #   effect: \"NoSchedule\"\r\n\r\n    ## If specified, the pod's topology spread constraints.\r\n    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\r\n    ##\r\n    topologySpreadConstraints: []\r\n    # - maxSkew: 1\r\n    #   topologyKey: topology.kubernetes.io/zone\r\n    #   whenUnsatisfiable: DoNotSchedule\r\n    #   labelSelector:\r\n    #     matchLabels:\r\n    #       app: thanos-ruler\r\n\r\n    ## SecurityContext holds pod-level security attributes and common container settings.\r\n    ## This defaults to non root user with uid 1000 and gid 2000. *v1.PodSecurityContext  false\r\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\r\n    ##\r\n    securityContext:\r\n      runAsGroup: 2000\r\n      runAsNonRoot: true\r\n      runAsUser: 1000\r\n      fsGroup: 2000\r\n      seccompProfile:\r\n        type: RuntimeDefault\r\n\r\n    ## ListenLocal makes the ThanosRuler server listen on loopback, so that it does not bind against the Pod IP.\r\n    ## Note this is only for the ThanosRuler UI, not the gossip communication.\r\n    ##\r\n    listenLocal: false\r\n\r\n    ## Containers allows injecting additional containers. This is meant to allow adding an authentication proxy to an ThanosRuler pod.\r\n    ##\r\n    containers: []\r\n\r\n    # Additional volumes on the output StatefulSet definition.\r\n    volumes: []\r\n\r\n    # Additional VolumeMounts on the output StatefulSet definition.\r\n    volumeMounts: []\r\n\r\n    ## InitContainers allows injecting additional initContainers. This is meant to allow doing some changes\r\n    ## (permissions, dir tree) on mounted volumes before starting prometheus\r\n    initContainers: []\r\n\r\n    ## Priority class assigned to the Pods\r\n    ##\r\n    priorityClassName: \"\"\r\n\r\n    ## PortName to use for ThanosRuler.\r\n    ##\r\n    portName: \"web\"\r\n\r\n    ## WebTLSConfig defines the TLS parameters for HTTPS\r\n    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#thanosrulerwebspec\r\n    web: {}\r\n\r\n    ## Additional configuration which is not covered by the properties above. (passed through tpl)\r\n    additionalConfig: {}\r\n\r\n    ## Additional configuration which is not covered by the properties above.\r\n    ## Useful, if you need advanced templating\r\n    additionalConfigString: \"\"\r\n\r\n  ## ExtraSecret can be used to store various data in an extra secret\r\n  ## (use it for example to store hashed basic auth credentials)\r\n  extraSecret:\r\n    ## if not set, name will be auto generated\r\n    # name: \"\"\r\n    annotations: {}\r\n    data: {}\r\n  #   auth: |\r\n  #     foo:$apr1$OFG3Xybp$ckL0FHDAkoXYIlH9.cysT0\r\n  #     someoneelse:$apr1$DMZX2Z4q$6SbQIfyuLQd.xmo/P0m2c.\r\n\r\n## Setting to true produces cleaner resource names, but requires a data migration because the name of the persistent volume changes. Therefore this should only be set once on initial installation.\r\n##\r\ncleanPrometheusOperatorObjectNames: false\r\n\r\n## Extra manifests to deploy as an array\r\nextraManifests: []\r\n  # - apiVersion: v1\r\n  #   kind: ConfigMap\r\n  #   metadata:\r\n  #   labels:\r\n  #     name: prometheus-extra\r\n  #   data:\r\n  #     extra-data: \"value\"\r\n"
            ],
            "verify": false,
            "version": "45.7.1",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "repository_password"
              }
            ]
          ],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main",
            "kubernetes_namespace.kube-namespace",
            "time_sleep.wait_for_kubernetes"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kubernetes_namespace",
      "name": "kube-namespace",
      "provider": "provider[\"registry.terraform.io/hashicorp/kubernetes\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "prometheus",
            "metadata": [
              {
                "annotations": {},
                "generate_name": "",
                "generation": 0,
                "labels": {},
                "name": "prometheus",
                "resource_version": "1355",
                "uid": "a5a5d059-0c73-4590-a866-a8aabc6b97ff"
              }
            ],
            "timeouts": null,
            "wait_for_default_service_account": false
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiZGVsZXRlIjozMDAwMDAwMDAwMDB9fQ==",
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main",
            "time_sleep.wait_for_kubernetes"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "null_resource",
      "name": "apply_cert_manager",
      "provider": "provider[\"registry.terraform.io/hashicorp/null\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "7934489778352561804",
            "triggers": null
          },
          "sensitive_attributes": [],
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "null_resource",
      "name": "apply_certificate",
      "provider": "provider[\"registry.terraform.io/hashicorp/null\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "695779974043490242",
            "triggers": null
          },
          "sensitive_attributes": [],
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main",
            "null_resource.apply_cert_manager"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "null_resource",
      "name": "apply_socks_shop_manifests",
      "provider": "provider[\"registry.terraform.io/hashicorp/null\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "3632288056777662735",
            "triggers": null
          },
          "sensitive_attributes": [],
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "random_password",
      "name": "sp_password",
      "provider": "provider[\"registry.terraform.io/hashicorp/random\"]",
      "instances": [
        {
          "schema_version": 3,
          "attributes": {
            "bcrypt_hash": "$2a$10$cy/TfXVBipm.iIEHXJPRB.xbIwncr9J3mj6oanvrJLPTYsyx3ywWm",
            "id": "none",
            "keepers": null,
            "length": 32,
            "lower": true,
            "min_lower": 0,
            "min_numeric": 0,
            "min_special": 0,
            "min_upper": 0,
            "number": true,
            "numeric": true,
            "override_special": null,
            "result": "S%FUY*ZgVlfzo6OJt6s{obd-Tp7@-sx_",
            "special": true,
            "upper": true
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "result"
              }
            ],
            [
              {
                "type": "get_attr",
                "value": "bcrypt_hash"
              }
            ]
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "time_sleep",
      "name": "wait_for_cert_manager",
      "provider": "provider[\"registry.terraform.io/hashicorp/time\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "create_duration": "20s",
            "destroy_duration": null,
            "id": "2024-09-16T14:19:04Z",
            "triggers": null
          },
          "sensitive_attributes": [],
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main",
            "null_resource.apply_cert_manager"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "time_sleep",
      "name": "wait_for_kubernetes",
      "provider": "provider[\"registry.terraform.io/hashicorp/time\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "create_duration": "20s",
            "destroy_duration": null,
            "id": "2024-09-16T14:03:25Z",
            "triggers": null
          },
          "sensitive_attributes": [],
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "time_sleep",
      "name": "wait_for_socks_shop_manifests",
      "provider": "provider[\"registry.terraform.io/hashicorp/time\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "create_duration": "20s",
            "destroy_duration": null,
            "id": "2024-09-16T14:04:07Z",
            "triggers": null
          },
          "sensitive_attributes": [],
          "dependencies": [
            "azurerm_kubernetes_cluster.main",
            "azurerm_resource_group.main",
            "null_resource.apply_socks_shop_manifests"
          ]
        }
      ]
    }
  ],
  "check_results": null
}
